{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecutionTime": {
     "end_time": "2021-01-21T16:19:23.341847Z",
     "start_time": "2021-01-21T16:19:01.285416Z"
    },
    "provenance": [
     {
      "end_time": "2021-01-18T13:36:04.691Z",
      "execution_time": "2.39s",
      "outputs": [],
      "source": "!awk '/^[>;]/ { if (seq) { print seq }; seq=\"\"; print } /^[^>;]/ { seq = seq $0 } END { print seq }' ../../B.fasta | awk -F , 'NF == 10' | sed 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' > ../../B.csv",
      "start_time": "2021-01-18T13:36:02.305Z"
     },
     {
      "end_time": "2021-01-18T13:42:44.853Z",
      "execution_time": "4.73s",
      "outputs": [],
      "source": "!awk '/^[>;]/ { if (seq) { print seq }; seq=\"\"; print } /^[^>;]/ { seq = seq $0 } END { print seq }' ../../B.fasta > ../../B.tmp \n#!sed 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' > ../../B.csv\n!sed -i 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' ../../B.tmp\n!awk -F , 'NF == 10' <../../B.tmp > B.csv",
      "start_time": "2021-01-18T13:42:40.125Z"
     },
     {
      "end_time": "2021-01-18T13:43:00.650Z",
      "execution_time": "4.72s",
      "outputs": [],
      "source": "!awk '/^[>;]/ { if (seq) { print seq }; seq=\"\"; print } /^[^>;]/ { seq = seq $0 } END { print seq }' ../../B.fasta > ../../B.tmp \n#!sed 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' > ../../B.csv\n!sed -i 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' ../../B.tmp\n!awk -F , 'NF == 10' <../../B.tmp > B.csv",
      "start_time": "2021-01-18T13:42:55.929Z"
     },
     {
      "end_time": "2021-01-18T13:44:45.857Z",
      "execution_time": "4.81s",
      "outputs": [],
      "source": "!awk '/^[>;]/ { if (seq) { print seq }; seq=\"\"; print } /^[^>;]/ { seq = seq $0 } END { print seq }' ../../B.fasta > ../../B.tmp \n#!sed 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' > ../../B.csv\n!sed -i 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' ../../B.tmp\n!awk -F , 'NF == 10' <../../B.tmp > B.csv",
      "start_time": "2021-01-18T13:44:41.044Z"
     },
     {
      "end_time": "2021-01-18T13:45:31.424Z",
      "execution_time": "4.80s",
      "outputs": [],
      "source": "!awk '/^[>;]/ { if (seq) { print seq }; seq=\"\"; print } /^[^>;]/ { seq = seq $0 } END { print seq }' ../../B.fasta > ../../B.tmp \n#!sed 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' > ../../B.csv\n!sed -i 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' ../../B.tmp\n!awk -F , 'NF == 10' <../../B.tmp > ../../B.csv",
      "start_time": "2021-01-18T13:45:26.624Z"
     },
     {
      "end_time": "2021-01-18T17:25:37.289Z",
      "execution_time": "4.75s",
      "outputs": [],
      "source": "!awk '/^[>;]/ { if (seq) { print seq }; seq=\"\"; print } /^[^>;]/ { seq = seq $0 } END { print seq }' ../../B.fasta > ../../B.tmp \n#!sed 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' > ../../B.csv\n!sed -i 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' ../../B.tmp\n!awk -F , 'NF == 10' <../../B.tmp > ../../B.csv",
      "start_time": "2021-01-18T17:25:32.543Z"
     },
     {
      "end_time": "2021-01-18T17:28:03.314Z",
      "execution_time": "4.90s",
      "outputs": [],
      "source": "!awk '/^[>;]/ { if (seq) { print seq }; seq=\"\"; print } /^[^>;]/ { seq = seq $0 } END { print seq }' ../../B.fasta > ../../B.tmp \n#!sed 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' > ../../B.csv\n!sed -i 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' ../../B.tmp\n!awk -F , 'NF == 10' <../../B.tmp > ../../B.csv",
      "start_time": "2021-01-18T17:27:58.414Z"
     },
     {
      "end_time": "2021-01-18T17:49:27.331Z",
      "execution_time": "22.8s",
      "outputs": [],
      "source": "!awk '/^[>;]/ { if (seq) { print seq }; seq=\"\"; print } /^[^>;]/ { seq = seq $0 } END { print seq }' ../../A.fasta > ../../A.tmp \n#!sed 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' > ../../B.csv\n!sed -i 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' ../../A.tmp\n!awk -F , 'NF == 10' <../../A.tmp > ../../A.csv",
      "start_time": "2021-01-18T17:49:04.569Z"
     },
     {
      "end_time": "2021-01-19T09:28:47.152Z",
      "execution_time": "23.0s",
      "outputs": [],
      "source": "!awk '/^[>;]/ { if (seq) { print seq }; seq=\"\"; print } /^[^>;]/ { seq = seq $0 } END { print seq }' ../../A.fasta > ../../A.tmp \n#!sed 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' > ../../B.csv\n!sed -i 's/ /_/g;N;s/\\n/,/g;s/|/,/g' ../../A.tmp\n!awk -F , 'NF == 10' <../../A.tmp > ../../A.csv",
      "start_time": "2021-01-19T09:28:24.177Z"
     },
     {
      "end_time": "2021-01-19T13:16:16.639Z",
      "execution_time": "23.4s",
      "outputs": [],
      "source": "!awk '/^[>;]/ { if (seq) { print seq }; seq=\"\"; print } /^[^>;]/ { seq = seq $0 } END { print seq }' ../../A.fasta > ../../A.tmp \n#!sed 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' > ../../B.csv\n!sed -i 's/ /_/g;N;s/\\n/,/g;s/|/,/g' ../../A.tmp\n!awk -F , 'NF == 10' <../../A.tmp > ../../A.csv",
      "start_time": "2021-01-19T13:15:53.242Z"
     },
     {
      "end_time": "2021-01-19T15:05:13.031Z",
      "execution_time": "14.6s",
      "outputs": [],
      "source": "!awk '/^[>;]/ { if (seq) { print seq }; seq=\"\"; print } /^[^>;]/ { seq = seq $0 } END { print seq }' ../../B.fasta > ../../B.tmp \n#!sed 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' > ../../B.csv\n!sed -i 's/ /_/g;N;s/\\n/,/g;s/|/,/g' ../../B.tmp\n!awk -F , 'NF == 10' <../../A.tmp > ../../B.csv",
      "start_time": "2021-01-19T15:04:58.408Z"
     },
     {
      "end_time": "2021-01-19T15:14:16.747Z",
      "execution_time": "4.68s",
      "outputs": [],
      "source": "!awk '/^[>;]/ { if (seq) { print seq }; seq=\"\"; print } /^[^>;]/ { seq = seq $0 } END { print seq }' ../../B.fasta > ../../B.tmp \n#!sed 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' > ../../B.csv\n!sed -i 's/ /_/g;N;s/\\n/,/g;s/|/,/g' ../../B.tmp\n!awk -F , 'NF == 10' <../../B.tmp > ../../B.csv",
      "start_time": "2021-01-19T15:14:12.063Z"
     },
     {
      "end_time": "2021-01-19T16:29:10.353Z",
      "execution_time": "24.3s",
      "outputs": [],
      "source": "!awk '/^[>;]/ { if (seq) { print seq }; seq=\"\"; print } /^[^>;]/ { seq = seq $0 } END { print seq }' ../../A.fasta > ../../A.tmp \n#!sed 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' > ../../B.csv\n!sed -i 's/ /_/g;N;s/\\n/,/g;s/|/,/g' ../../A.tmp\n!awk -F , 'NF == 10' <../../A.tmp > ../../A.csv",
      "start_time": "2021-01-19T16:28:46.053Z"
     },
     {
      "end_time": "2021-01-19T17:09:33.154Z",
      "execution_time": "23.0s",
      "outputs": [],
      "source": "!awk '/^[>;]/ { if (seq) { print seq }; seq=\"\"; print } /^[^>;]/ { seq = seq $0 } END { print seq }' ../../A.fasta > ../../A.tmp \n#!sed 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' > ../../B.csv\n!sed -i 's/ /_/g;N;s/\\n/,/g;s/|/,/g' ../../A.tmp\n!awk -F , 'NF == 10' <../../A.tmp > ../../A.csv",
      "start_time": "2021-01-19T17:09:10.181Z"
     },
     {
      "end_time": "2021-01-19T18:15:05.681Z",
      "execution_time": "4.78s",
      "outputs": [],
      "source": "!awk '/^[>;]/ { if (seq) { print seq }; seq=\"\"; print } /^[^>;]/ { seq = seq $0 } END { print seq }' ../../B.fasta > ../../B.tmp \n#!sed 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' > ../../B.csv\n!sed -i 's/ /_/g;N;s/\\n/,/g;s/|/,/g' ../../B.tmp\n!awk -F , 'NF == 10' <../../B.tmp > ../../B.csv",
      "start_time": "2021-01-19T18:15:00.904Z"
     },
     {
      "end_time": "2021-01-19T18:27:32.050Z",
      "execution_time": "23.5s",
      "outputs": [],
      "source": "!awk '/^[>;]/ { if (seq) { print seq }; seq=\"\"; print } /^[^>;]/ { seq = seq $0 } END { print seq }' ../../A.fasta > ../../A.tmp \n#!sed 's/ /_/g;N;s/\\n/,/g;s/|/,/g;s/>//g' > ../../B.csv\n!sed -i 's/ /_/g;N;s/\\n/,/g;s/|/,/g' ../../A.tmp\n!awk -F , 'NF == 10' <../../A.tmp > ../../A.csv",
      "start_time": "2021-01-19T18:27:08.564Z"
     },
     {
      "end_time": "2021-01-20T17:39:24.800Z",
      "execution_time": "4.82s",
      "outputs": [],
      "source": "!awk '/^[>;]/ { if (seq) { print seq }; seq=\"\"; print } /^[^>;]/ { seq = seq $0 } END { print seq }' ../../B.fasta > ../../B.tmp \n!sed -i 's/ /_/g;N;s/\\n/,/g;s/|/,/g' ../../B.tmp\n!awk -F , 'NF == 10' <../../B.tmp > ../../B.csv",
      "start_time": "2021-01-20T17:39:19.978Z"
     },
     {
      "end_time": "2021-01-21T15:24:23.111Z",
      "execution_time": "4.68s",
      "outputs": [],
      "source": "!awk '/^[>;]/ { if (seq) { print seq }; seq=\"\"; print } /^[^>;]/ { seq = seq $0 } END { print seq }' ../../B.fasta > ../../B.tmp \n!sed -i 's/ /_/g;N;s/\\n/,/g;s/|/,/g' ../../B.tmp\n!awk -F , 'NF == 10' <../../B.tmp > ../../B.csv",
      "start_time": "2021-01-21T15:24:18.430Z"
     },
     {
      "end_time": "2021-01-21T16:19:23.341Z",
      "execution_time": "22.1s",
      "outputs": [],
      "source": "!awk '/^[>;]/ { if (seq) { print seq }; seq=\"\"; print } /^[^>;]/ { seq = seq $0 } END { print seq }' ../../A.fasta > ../../A.tmp \n!sed -i 's/ /_/g;N;s/\\n/,/g;s/|/,/g' ../../A.tmp\n!awk -F , 'NF == 10' <../../A.tmp > ../../A.csv",
      "start_time": "2021-01-21T16:19:01.285Z"
     }
    ]
   },
   "outputs": [],
   "source": [
    "!awk '/^[>;]/ { if (seq) { print seq }; seq=\"\"; print } /^[^>;]/ { seq = seq $0 } END { print seq }' ../../A.fasta > ../../A.tmp \n",
    "!sed -i 's/ /_/g;N;s/\\n/,/g;s/|/,/g' ../../A.tmp\n",
    "!awk -F , 'NF == 10' <../../A.tmp > ../../A.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecutionTime": {
     "end_time": "2021-01-22T10:58:28.237256Z",
     "start_time": "2021-01-22T10:58:26.465063Z"
    },
    "provenance": [
     {
      "end_time": "Unknown",
      "execution_time": "Unknown",
      "outputs": [],
      "source": "import functools as ft\nimport numpy as np\nimport pandas as pd\nimport multiprocessing as mp\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport difflib\nimport scipy.spatial.distance as ssd",
      "start_time": "Unknown"
     },
     {
      "end_time": "2021-01-15T08:57:18.616Z",
      "execution_time": "1.90s",
      "outputs": [],
      "source": "import functools as ft\nimport numpy as np\nimport pandas as pd\nimport multiprocessing as mp\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport difflib\nimport scipy.spatial.distance as ssd",
      "start_time": "2021-01-15T08:57:16.717Z"
     },
     {
      "end_time": "2021-01-15T08:58:42.143Z",
      "execution_time": "1.56s",
      "outputs": [],
      "source": "import functools as ft\nimport numpy as np\nimport pandas as pd\nimport multiprocessing as mp\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport difflib\nimport scipy.spatial.distance as ssd",
      "start_time": "2021-01-15T08:58:40.580Z"
     },
     {
      "end_time": "2021-01-15T09:00:21.985Z",
      "execution_time": "6ms",
      "outputs": [],
      "source": "import functools as ft\nimport numpy as np\nimport pandas as pd\nimport multiprocessing as mp\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport difflib\nimport scipy.spatial.distance as ssd",
      "start_time": "2021-01-15T09:00:21.979Z"
     },
     {
      "end_time": "2021-01-17T17:13:58.363Z",
      "execution_time": "1.83s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time ",
      "start_time": "2021-01-17T17:13:56.528Z"
     },
     {
      "end_time": "2021-01-17T17:15:09.350Z",
      "execution_time": "1.61s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time ",
      "start_time": "2021-01-17T17:15:07.741Z"
     },
     {
      "end_time": "2021-01-17T17:17:20.813Z",
      "execution_time": "1.53s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time ",
      "start_time": "2021-01-17T17:17:19.284Z"
     },
     {
      "end_time": "2021-01-17T17:24:00.228Z",
      "execution_time": "1.54s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time ",
      "start_time": "2021-01-17T17:23:58.684Z"
     },
     {
      "end_time": "2021-01-17T17:49:45.894Z",
      "execution_time": "6ms",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd",
      "start_time": "2021-01-17T17:49:45.888Z"
     },
     {
      "end_time": "2021-01-17T18:16:39.749Z",
      "execution_time": "10ms",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom memory_profiler import memory_usage",
      "start_time": "2021-01-17T18:16:39.739Z"
     },
     {
      "end_time": "2021-01-17T18:21:52.651Z",
      "execution_time": "5ms",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom memory_profiler import memory_usage",
      "start_time": "2021-01-17T18:21:52.646Z"
     },
     {
      "end_time": "2021-01-17T18:36:36.150Z",
      "execution_time": "1.55s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom memory_profiler import memory_usage",
      "start_time": "2021-01-17T18:36:34.601Z"
     },
     {
      "end_time": "2021-01-18T08:35:24.238Z",
      "execution_time": "1.89s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom memory_profiler import memory_usage",
      "start_time": "2021-01-18T08:35:22.348Z"
     },
     {
      "end_time": "2021-01-18T11:19:58.961Z",
      "execution_time": "6ms",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom memory_profiler import memory_usage",
      "start_time": "2021-01-18T11:19:58.955Z"
     },
     {
      "end_time": "2021-01-18T11:54:06.310Z",
      "execution_time": "6ms",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom memory_profiler import memory_usage",
      "start_time": "2021-01-18T11:54:06.304Z"
     },
     {
      "end_time": "2021-01-18T11:54:37.447Z",
      "execution_time": "1.53s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom memory_profiler import memory_usage",
      "start_time": "2021-01-18T11:54:35.913Z"
     },
     {
      "end_time": "2021-01-18T13:36:06.899Z",
      "execution_time": "6ms",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom memory_profiler import memory_usage",
      "start_time": "2021-01-18T13:36:06.893Z"
     },
     {
      "end_time": "2021-01-18T13:46:04.796Z",
      "execution_time": "1.62s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom memory_profiler import memory_usage",
      "start_time": "2021-01-18T13:46:03.173Z"
     },
     {
      "end_time": "2021-01-18T13:47:30.771Z",
      "execution_time": "1.54s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom memory_profiler import memory_usage",
      "start_time": "2021-01-18T13:47:29.227Z"
     },
     {
      "end_time": "2021-01-18T16:54:39.565Z",
      "execution_time": "4ms",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom memory_profiler import memory_usage",
      "start_time": "2021-01-18T16:54:39.561Z"
     },
     {
      "end_time": "2021-01-18T16:55:00.382Z",
      "execution_time": "1.59s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom memory_profiler import memory_usage",
      "start_time": "2021-01-18T16:54:58.789Z"
     },
     {
      "end_time": "2021-01-18T17:25:41.393Z",
      "execution_time": "1.55s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom memory_profiler import memory_usage",
      "start_time": "2021-01-18T17:25:39.841Z"
     },
     {
      "end_time": "2021-01-18T17:28:05.696Z",
      "execution_time": "1.54s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom memory_profiler import memory_usage",
      "start_time": "2021-01-18T17:28:04.151Z"
     },
     {
      "end_time": "2021-01-18T17:49:31.597Z",
      "execution_time": "1.54s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom memory_profiler import memory_usage",
      "start_time": "2021-01-18T17:49:30.054Z"
     },
     {
      "end_time": "2021-01-19T13:16:21.520Z",
      "execution_time": "2.12s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom memory_profiler import memory_usage",
      "start_time": "2021-01-19T13:16:19.403Z"
     },
     {
      "end_time": "2021-01-19T15:05:14.618Z",
      "execution_time": "7ms",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom memory_profiler import memory_usage",
      "start_time": "2021-01-19T15:05:14.611Z"
     },
     {
      "end_time": "2021-01-19T15:14:20.650Z",
      "execution_time": "1.76s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom memory_profiler import memory_usage",
      "start_time": "2021-01-19T15:14:18.890Z"
     },
     {
      "end_time": "2021-01-19T16:29:10.359Z",
      "execution_time": "4ms",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom memory_profiler import memory_usage",
      "start_time": "2021-01-19T16:29:10.355Z"
     },
     {
      "end_time": "2021-01-19T17:29:27.705Z",
      "execution_time": "1.70s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\n#from memory_profiler import memory_usage",
      "start_time": "2021-01-19T17:29:26.004Z"
     },
     {
      "end_time": "2021-01-19T17:33:24.394Z",
      "execution_time": "36ms",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom Bio.Align.Applications import MafftCommandline\n#from memory_profiler import memory_usage",
      "start_time": "2021-01-19T17:33:24.358Z"
     },
     {
      "end_time": "2021-01-19T18:15:06.835Z",
      "execution_time": "8ms",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom Bio.Align.Applications import MafftCommandline\n#from memory_profiler import memory_usage",
      "start_time": "2021-01-19T18:15:06.827Z"
     },
     {
      "end_time": "2021-01-19T18:27:37.393Z",
      "execution_time": "1.72s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom Bio.Align.Applications import MafftCommandline\n#from memory_profiler import memory_usage",
      "start_time": "2021-01-19T18:27:35.676Z"
     },
     {
      "end_time": "2021-01-20T17:39:28.358Z",
      "execution_time": "1.88s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom Bio.Align.Applications import MafftCommandline\n#from memory_profiler import memory_usage",
      "start_time": "2021-01-20T17:39:26.480Z"
     },
     {
      "end_time": "2021-01-20T17:43:41.570Z",
      "execution_time": "1.61s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom Bio.Align.Applications import MafftCommandline\n#from memory_profiler import memory_usage",
      "start_time": "2021-01-20T17:43:39.956Z"
     },
     {
      "end_time": "2021-01-21T15:24:26.029Z",
      "execution_time": "1.84s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom Bio.Align.Applications import MafftCommandline\n#from memory_profiler import memory_usage",
      "start_time": "2021-01-21T15:24:24.193Z"
     },
     {
      "end_time": "2021-01-21T16:19:35.226Z",
      "execution_time": "1.55s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom Bio.Align.Applications import MafftCommandline\n#from memory_profiler import memory_usage",
      "start_time": "2021-01-21T16:19:33.680Z"
     },
     {
      "end_time": "2021-01-21T22:36:57.077Z",
      "execution_time": "1.58s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom Bio.Align.Applications import MafftCommandline\n#from memory_profiler import memory_usage",
      "start_time": "2021-01-21T22:36:55.498Z"
     },
     {
      "end_time": "2021-01-22T10:58:28.237Z",
      "execution_time": "1.77s",
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport sys\nimport re\nimport csv\nimport collections as co\nimport itertools as it\nimport umap\nimport hdbscan\nimport time \nimport scipy.spatial.distance as ssd\nfrom Bio.Align.Applications import MafftCommandline\n#from memory_profiler import memory_usage",
      "start_time": "2021-01-22T10:58:26.465Z"
     }
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import csv\n",
    "import collections as co\n",
    "import itertools as it\n",
    "import umap\n",
    "import hdbscan\n",
    "import time \n",
    "import scipy.spatial.distance as ssd\n",
    "from Bio.Align.Applications import MafftCommandline\n",
    "#from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecutionTime": {
     "end_time": "2021-01-21T16:19:37.876948Z",
     "start_time": "2021-01-21T16:19:37.733948Z"
    },
    "provenance": [
     {
      "end_time": "Unknown",
      "execution_time": "Unknown",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    #def __init__(self, procs = 8, k = 7, convert = 0, row = 0, index = [], exist = co.defaultdict(int)):\n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.subtype = np.empty((self.row, 1, ),dtype = \"object\")\n        self.index = np.empty(self.row, dtype = \"object\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n        #self.row = sum(1 for l in open(infile))\n        #data = pd.read_csv(infile, chunksize = 10000, sep = ',', na_filter = False, header = None)\n        #for chunk in data:\n            #for line, info, read in chunk.itertuples(index=True, name=None):\n        \n        for line, info, subtype, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.index = np.empty(self.row, dtype = \"object\")\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        self.subtype = np.empty((self.row, 1, ), dtype = \"object\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        #data = pd.read_csv(infile, chunksize = 10000, sep = ',', na_filter = False, header = None)\n        #for chunk in data:\n            #for line, info, read in chunk.itertuples(index=True, name=None):\n        \n        for line, info, subtype, read in infile.itertuples(index=True, name=None): \n                \n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.index[line] = info\n            self.matrix[line] = vector\n            self.subtype[line] = subtype\n\n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    def get_index(self):\n        \n        return(self.index)\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_subtype(self):\n        \n        return(self.subtype)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "Unknown"
     },
     {
      "end_time": "2021-01-15T08:57:19.841Z",
      "execution_time": "187ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    #def __init__(self, procs = 8, k = 7, convert = 0, row = 0, index = [], exist = co.defaultdict(int)):\n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.subtype = np.empty((self.row, 1, ),dtype = \"object\")\n        self.index = np.empty(self.row, dtype = \"object\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n        #self.row = sum(1 for l in open(infile))\n        #data = pd.read_csv(infile, chunksize = 10000, sep = ',', na_filter = False, header = None)\n        #for chunk in data:\n            #for line, info, read in chunk.itertuples(index=True, name=None):\n        \n        for line, info, subtype, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.index = np.empty(self.row, dtype = \"object\")\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        self.subtype = np.empty((self.row, 1, ), dtype = \"object\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        #data = pd.read_csv(infile, chunksize = 10000, sep = ',', na_filter = False, header = None)\n        #for chunk in data:\n            #for line, info, read in chunk.itertuples(index=True, name=None):\n        \n        for line, info, subtype, read in infile.itertuples(index=True, name=None): \n                \n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.index[line] = info\n            self.matrix[line] = vector\n            self.subtype[line] = subtype\n\n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    def get_index(self):\n        \n        return(self.index)\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_subtype(self):\n        \n        return(self.subtype)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-15T08:57:19.654Z"
     },
     {
      "end_time": "2021-01-15T09:00:23.526Z",
      "execution_time": "185ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    #def __init__(self, procs = 8, k = 7, convert = 0, row = 0, index = [], exist = co.defaultdict(int)):\n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.subtype = np.empty((self.row, 1, ),dtype = \"object\")\n        self.index = np.empty(self.row, dtype = \"object\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n        #self.row = sum(1 for l in open(infile))\n        #data = pd.read_csv(infile, chunksize = 10000, sep = ',', na_filter = False, header = None)\n        #for chunk in data:\n            #for line, info, read in chunk.itertuples(index=True, name=None):\n        \n        for line, info, subtype, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.index = np.empty(self.row, dtype = \"object\")\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        self.subtype = np.empty((self.row, 1, ), dtype = \"object\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        #data = pd.read_csv(infile, chunksize = 10000, sep = ',', na_filter = False, header = None)\n        #for chunk in data:\n            #for line, info, read in chunk.itertuples(index=True, name=None):\n        \n        for line, info, subtype, read in infile.itertuples(index=True, name=None): \n                \n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.index[line] = info\n            self.matrix[line] = vector\n            self.subtype[line] = subtype\n\n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    def get_index(self):\n        \n        return(self.index)\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_subtype(self):\n        \n        return(self.subtype)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-15T09:00:23.341Z"
     },
     {
      "end_time": "2021-01-17T17:13:59.315Z",
      "execution_time": "147ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    #def __init__(self, procs = 8, k = 7, convert = 0, row = 0, index = [], exist = co.defaultdict(int)):\n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n        #self.row = sum(1 for l in open(infile))\n        #data = pd.read_csv(infile, chunksize = 10000, sep = ',', na_filter = False, header = None)\n        #for chunk in data:\n            #for line, info, read in chunk.itertuples(index=True, name=None):\n        \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        #data = pd.read_csv(infile, chunksize = 10000, sep = ',', na_filter = False, header = None)\n        #for chunk in data:\n            #for line, info, read in chunk.itertuples(index=True, name=None):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                \n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-17T17:13:59.168Z"
     },
     {
      "end_time": "2021-01-17T17:15:10.931Z",
      "execution_time": "149ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    #def __init__(self, procs = 8, k = 7, convert = 0, row = 0, index = [], exist = co.defaultdict(int)):\n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n        #self.row = sum(1 for l in open(infile))\n        #data = pd.read_csv(infile, chunksize = 10000, sep = ',', na_filter = False, header = None)\n        #for chunk in data:\n            #for line, info, read in chunk.itertuples(index=True, name=None):\n        \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        #data = pd.read_csv(infile, chunksize = 10000, sep = ',', na_filter = False, header = None)\n        #for chunk in data:\n            #for line, info, read in chunk.itertuples(index=True, name=None):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                \n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-17T17:15:10.782Z"
     },
     {
      "end_time": "2021-01-17T17:17:21.455Z",
      "execution_time": "161ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    #def __init__(self, procs = 8, k = 7, convert = 0, row = 0, index = [], exist = co.defaultdict(int)):\n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n        #self.row = sum(1 for l in open(infile))\n        #data = pd.read_csv(infile, chunksize = 10000, sep = ',', na_filter = False, header = None)\n        #for chunk in data:\n            #for line, info, read in chunk.itertuples(index=True, name=None):\n        \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        #data = pd.read_csv(infile, chunksize = 10000, sep = ',', na_filter = False, header = None)\n        #for chunk in data:\n            #for line, info, read in chunk.itertuples(index=True, name=None):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                \n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-17T17:17:21.294Z"
     },
     {
      "end_time": "2021-01-17T17:19:17.615Z",
      "execution_time": "160ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    #def __init__(self, procs = 8, k = 7, convert = 0, row = 0, index = [], exist = co.defaultdict(int)):\n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n         \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        #data = pd.read_csv(infile, chunksize = 10000, sep = ',', na_filter = False, header = None)\n        #for chunk in data:\n            #for line, info, read in chunk.itertuples(index=True, name=None):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                \n            print(read)\n                \n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-17T17:19:17.455Z"
     },
     {
      "end_time": "2021-01-17T17:20:46.568Z",
      "execution_time": "160ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    #def __init__(self, procs = 8, k = 7, convert = 0, row = 0, index = [], exist = co.defaultdict(int)):\n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n         \n        for line, read in infile.itertuples(index=True, name=None):\n\n            print('hello')\n            \n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        #data = pd.read_csv(infile, chunksize = 10000, sep = ',', na_filter = False, header = None)\n        #for chunk in data:\n            #for line, info, read in chunk.itertuples(index=True, name=None):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                \n            print(read)\n                \n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-17T17:20:46.408Z"
     },
     {
      "end_time": "2021-01-17T17:22:59.275Z",
      "execution_time": "159ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    #def __init__(self, procs = 8, k = 7, convert = 0, row = 0, index = [], exist = co.defaultdict(int)):\n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        #data = pd.read_csv(infile, chunksize = 10000, sep = ',', na_filter = False, header = None)\n        #for chunk in data:\n            #for line, info, read in chunk.itertuples(index=True, name=None):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                \n            print(read)\n                \n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-17T17:22:59.116Z"
     },
     {
      "end_time": "2021-01-17T17:24:01.067Z",
      "execution_time": "146ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    #def __init__(self, procs = 8, k = 7, convert = 0, row = 0, index = [], exist = co.defaultdict(int)):\n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        #data = pd.read_csv(infile, chunksize = 10000, sep = ',', na_filter = False, header = None)\n        #for chunk in data:\n            #for line, info, read in chunk.itertuples(index=True, name=None):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-17T17:24:00.921Z"
     },
     {
      "end_time": "2021-01-17T18:21:53.884Z",
      "execution_time": "148ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    #def __init__(self, procs = 8, k = 7, convert = 0, row = 0, index = [], exist = co.defaultdict(int)):\n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        #data = pd.read_csv(infile, chunksize = 10000, sep = ',', na_filter = False, header = None)\n        #for chunk in data:\n            #for line, info, read in chunk.itertuples(index=True, name=None):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-17T18:21:53.736Z"
     },
     {
      "end_time": "2021-01-17T18:36:37.171Z",
      "execution_time": "148ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    #def __init__(self, procs = 8, k = 7, convert = 0, row = 0, index = [], exist = co.defaultdict(int)):\n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        #data = pd.read_csv(infile, chunksize = 10000, sep = ',', na_filter = False, header = None)\n        #for chunk in data:\n            #for line, info, read in chunk.itertuples(index=True, name=None):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                #seq = self.translate(re.sub('[^ACGT]+', '', read))\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                #seq = re.sub('[^ACGT]+', '', read)\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-17T18:36:37.023Z"
     },
     {
      "end_time": "2021-01-18T11:20:00.605Z",
      "execution_time": "142ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-18T11:20:00.463Z"
     },
     {
      "end_time": "2021-01-18T11:54:07.641Z",
      "execution_time": "157ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-18T11:54:07.484Z"
     },
     {
      "end_time": "2021-01-18T11:54:38.062Z",
      "execution_time": "138ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-18T11:54:37.924Z"
     },
     {
      "end_time": "2021-01-18T13:36:11.351Z",
      "execution_time": "153ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-18T13:36:11.198Z"
     },
     {
      "end_time": "2021-01-18T13:46:04.935Z",
      "execution_time": "138ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-18T13:46:04.797Z"
     },
     {
      "end_time": "2021-01-18T13:47:31.501Z",
      "execution_time": "143ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-18T13:47:31.358Z"
     },
     {
      "end_time": "2021-01-18T16:55:01.264Z",
      "execution_time": "140ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-18T16:55:01.124Z"
     },
     {
      "end_time": "2021-01-18T17:25:43.096Z",
      "execution_time": "145ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-18T17:25:42.951Z"
     },
     {
      "end_time": "2021-01-18T17:28:05.842Z",
      "execution_time": "145ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-18T17:28:05.697Z"
     },
     {
      "end_time": "2021-01-18T17:49:34.379Z",
      "execution_time": "142ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-18T17:49:34.237Z"
     },
     {
      "end_time": "2021-01-19T13:16:22.595Z",
      "execution_time": "142ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-19T13:16:22.453Z"
     },
     {
      "end_time": "2021-01-19T15:05:15.831Z",
      "execution_time": "156ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-19T15:05:15.675Z"
     },
     {
      "end_time": "2021-01-19T15:14:20.792Z",
      "execution_time": "140ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-19T15:14:20.652Z"
     },
     {
      "end_time": "2021-01-19T16:29:10.513Z",
      "execution_time": "152ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-19T16:29:10.361Z"
     },
     {
      "end_time": "2021-01-19T17:29:28.420Z",
      "execution_time": "152ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-19T17:29:28.268Z"
     },
     {
      "end_time": "2021-01-19T17:33:25.531Z",
      "execution_time": "140ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-19T17:33:25.391Z"
     },
     {
      "end_time": "2021-01-19T18:15:07.988Z",
      "execution_time": "147ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-19T18:15:07.841Z"
     },
     {
      "end_time": "2021-01-19T18:27:38.890Z",
      "execution_time": "146ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-19T18:27:38.744Z"
     },
     {
      "end_time": "2021-01-20T17:39:29.095Z",
      "execution_time": "171ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-20T17:39:28.924Z"
     },
     {
      "end_time": "2021-01-20T17:43:42.192Z",
      "execution_time": "147ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-20T17:43:42.045Z"
     },
     {
      "end_time": "2021-01-21T15:24:26.171Z",
      "execution_time": "141ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-21T15:24:26.030Z"
     },
     {
      "end_time": "2021-01-21T16:19:37.876Z",
      "execution_time": "143ms",
      "outputs": [],
      "source": "class vectorizer(object):\n    \n    def __init__(self, k = 7, convert = 0):\n    \n        self.k = k\n        self.convert = convert\n        self.exist = co.defaultdict(int) \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.row = 0\n        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n        self.amino = co.defaultdict(str, {\n            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n        })\n                \n    def translate(self, read):\n    \n        chain = ''\n\n        for i in range(len(read) - 2):\n            trip = read[i:i+3]\n            chain += self.amino[trip]\n\n        return(chain)\n    \n    \n    def adjust_to_data(self, infile):\n    \n        self.row = infile.shape[0]\n            \n        for line, read in infile.itertuples(index=True, name=None):\n\n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    self.exist[kmer] = 0\n\n            else:\n                seq = read\n                del read\n\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        self.exist[kmer] = 0\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            self.exist[kmer] = 0\n            \n        self.keys = list(self.exist.keys())\n        self.col = len(self.keys)\n        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n        \n        del seq\n    \n    def calculate_frequence(self, infile):\n        \n        for line, read in infile.itertuples(index=True, name=None): \n                 \n            if self.convert == 1:\n                seq = self.translate(read)\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                for i in range(num):\n                    kmer = seq[i:i+self.k]\n                    counts[kmer] += 1\n\n            else:\n                seq = read\n                del read\n\n                counts = self.exist.copy()\n                num = len(seq) - self.k + 1\n\n                if re.match('^[ACGT]*$', seq): \n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        counts[kmer] += 1\n                else:\n                    for i in range(num):\n                        kmer = seq[i:i+self.k]\n                        if re.match('^[ACGT]*$', kmer): \n                            counts[kmer] += 1\n\n            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n\n            self.matrix[line] = vector\n            \n            counts.clear()\n            del vector\n            del seq\n            del counts\n    \n    \n    def get_keys(self):\n        \n        return(self.keys)\n    \n    \n    def get_matrix(self):\n        \n        return(self.matrix)",
      "start_time": "2021-01-21T16:19:37.733Z"
     }
    ]
   },
   "outputs": [],
   "source": [
    "class vectorizer(object):\n",
    "    \n",
    "    def __init__(self, k = 7, convert = 0):\n",
    "    \n",
    "        self.k = k\n",
    "        self.convert = convert\n",
    "        self.exist = co.defaultdict(int) \n",
    "        self.keys = list(self.exist.keys())\n",
    "        self.col = len(self.keys)\n",
    "        self.row = 0\n",
    "        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n",
    "        self.amino = co.defaultdict(str, {\n",
    "            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n",
    "            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n",
    "            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n",
    "            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n",
    "            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n",
    "            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n",
    "            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n",
    "            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n",
    "            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n",
    "            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n",
    "            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n",
    "            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n",
    "            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n",
    "            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n",
    "            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n",
    "            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n",
    "        })\n",
    "                \n",
    "    def translate(self, read):\n",
    "    \n",
    "        chain = ''\n",
    "\n",
    "        for i in range(len(read) - 2):\n",
    "            trip = read[i:i+3]\n",
    "            chain += self.amino[trip]\n",
    "\n",
    "        return(chain)\n",
    "    \n",
    "    \n",
    "    def adjust_to_data(self, infile):\n",
    "    \n",
    "        self.row = infile.shape[0]\n",
    "            \n",
    "        for line, read in infile.itertuples(index=True, name=None):\n",
    "\n",
    "            if self.convert == 1:\n",
    "                seq = self.translate(read)\n",
    "                del read\n",
    "\n",
    "                num = len(seq) - self.k + 1\n",
    "\n",
    "                for i in range(num):\n",
    "                    kmer = seq[i:i+self.k]\n",
    "                    self.exist[kmer] = 0\n",
    "\n",
    "            else:\n",
    "                seq = read\n",
    "                del read\n",
    "\n",
    "                num = len(seq) - self.k + 1\n",
    "\n",
    "                if re.match('^[ACGT]*$', seq): \n",
    "                    for i in range(num):\n",
    "                        kmer = seq[i:i+self.k]\n",
    "                        self.exist[kmer] = 0\n",
    "                else:\n",
    "                    for i in range(num):\n",
    "                        kmer = seq[i:i+self.k]\n",
    "                        if re.match('^[ACGT]*$', kmer): \n",
    "                            self.exist[kmer] = 0\n",
    "            \n",
    "        self.keys = list(self.exist.keys())\n",
    "        self.col = len(self.keys)\n",
    "        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n",
    "        \n",
    "        del seq\n",
    "    \n",
    "    def calculate_frequence(self, infile):\n",
    "        \n",
    "        for line, read in infile.itertuples(index=True, name=None): \n",
    "                 \n",
    "            if self.convert == 1:\n",
    "                seq = self.translate(read)\n",
    "                del read\n",
    "\n",
    "                counts = self.exist.copy()\n",
    "                num = len(seq) - self.k + 1\n",
    "\n",
    "                for i in range(num):\n",
    "                    kmer = seq[i:i+self.k]\n",
    "                    counts[kmer] += 1\n",
    "\n",
    "            else:\n",
    "                seq = read\n",
    "                del read\n",
    "\n",
    "                counts = self.exist.copy()\n",
    "                num = len(seq) - self.k + 1\n",
    "\n",
    "                if re.match('^[ACGT]*$', seq): \n",
    "                    for i in range(num):\n",
    "                        kmer = seq[i:i+self.k]\n",
    "                        counts[kmer] += 1\n",
    "                else:\n",
    "                    for i in range(num):\n",
    "                        kmer = seq[i:i+self.k]\n",
    "                        if re.match('^[ACGT]*$', kmer): \n",
    "                            counts[kmer] += 1\n",
    "\n",
    "            vector = np.array(list(counts.values()), dtype = \"float32\")/num\n",
    "\n",
    "            self.matrix[line] = vector\n",
    "            \n",
    "            counts.clear()\n",
    "            del vector\n",
    "            del seq\n",
    "            del counts\n",
    "    \n",
    "    \n",
    "    def get_keys(self):\n",
    "        \n",
    "        return(self.keys)\n",
    "    \n",
    "    \n",
    "    def get_matrix(self):\n",
    "        \n",
    "        return(self.matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecutionTime": {
     "end_time": "2021-01-21T16:19:45.412294Z",
     "start_time": "2021-01-21T16:19:45.072352Z"
    },
    "provenance": [
     {
      "end_time": "Unknown",
      "execution_time": "Unknown",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = 'Input/A.csv'   \n    setfile = 'Input/settings.csv'\n    worldfile = 'Input/cities.csv'\n    outpath = 'Output/'\n    #outfile = 'output.csv'\n    \n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    parameter = settings.loc[4].to_list()\n\n    print(\"Finished.\")\n\n    start_table = time.perf_counter()\n\n    print(\"Creating SQL tables.\", end = ' ')\n\n    tables = extractor()\n    tables.fill_dicts(worldfile)\n    tables.input_sequences(infile, 8)\n    \n    intab = tables.get_dataframe([0, 5, 13], ['accession', 'subtype', 'genome'], ['accession'])\n    intab.reset_index(level=['accession'], inplace=True)\n    genomes = tables.get_dataframe([0, 13], ['accession', 'genome'], ['accession'])\n    header = tables.get_dataframe([0, 1, 2], ['accession', 'strain', 'segment'], ['accession'])\n    strains = tables.get_dataframe([1, 6, 7, 8, 9, 10, 11], ['strain', 'species', 'city', 'subcountry', 'country', 'year', 'host'], ['strain'])\n    \n    print(\"Finished.\")\n    \n    stop_table = time.perf_counter()\n    \n    print(f\"Table creation done in {stop_table - start_table:0.4f} seconds.\")\n    \n    \n    start_clust = time.perf_counter()\n\n    print(\"Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(intab)\n    freq_nt.calculate_frequence(intab)\n\n    matrix_nt = freq_nt.get_matrix()\n    index_nt = freq_nt.get_index()   \n    subtype_nt = freq_nt.get_subtype()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\"Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(intab)\n    freq_aa.calculate_frequence(intab)\n\n    matrix_aa = freq_aa.get_matrix()\n    index_aa = freq_aa.get_index()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix_aa_ind = pd.DataFrame(matrix_aa_red, index = index_aa)\n    matrix_nt_ind = pd.DataFrame(matrix_nt_red, index = index_nt)\n\n    matrix = pd.concat([matrix_nt_ind, matrix_aa_ind], axis=1, copy = False, ignore_index = True) #falsches Ergebnis? checken ob ignore_index = Fehler\n\n    print(\"Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\"Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), index = index_nt, columns = ['cluster', 'centroid'])\n    subtype = pd.DataFrame(subtype_nt, index = index_nt, columns = ['subtype'])\n    clusters = pd.concat([blank, subtype], axis=1, copy = False)\n\n    num = clusters['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n    \n    for i in range(num):\n\n        query = clusters[clusters.cluster == i]\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n                \n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters.update(centroids)\n    #clusters.sort_values(by=['cluster', 'subtype']).to_csv(outfile, index=True, header=True, sep=',')\n    \n    informations = pd.concat([header, clusters], axis=1, copy = False)\n    informations.sort_values(by=['cluster', 'subtype']).to_csv(outpath + 'informations.csv', index_label='accession', index=True, header=True, sep=',')\n    strains.to_csv(outpath + 'strains.csv', index_label='strain', index=True, header=True, sep=',')\n    genomes.to_csv(outpath + 'genomes.csv', index_label='accession', index=True, header=True, sep=',')\n    \n    print(\"Finished.\")\n    \n    stop_clust = time.perf_counter()\n    print(f\"Clustering done in {stop_clust - start_clust:0.4f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\"{str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\"Mean of inner cluster distance mean {overall_mean/num}\")\n    print(f\"{exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\"{exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n    print(f\"Overall running time {(stop_clust - start_clust)+(stop_table - start_table):0.4f} seconds.\")",
      "start_time": "Unknown"
     },
     {
      "end_time": "2021-01-15T08:57:20.373Z",
      "execution_time": "218ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = 'Input/B_HA.csv'   \n    setfile = 'Input/settings.csv'\n    worldfile = 'Input/cities.csv'\n    outpath = 'Output/'\n    #outfile = 'output.csv'\n    \n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    parameter = settings.loc[4].to_list()\n\n    print(\"Finished.\")\n\n    start_table = time.perf_counter()\n\n    print(\"Creating SQL tables.\", end = ' ')\n\n    tables = extractor()\n    tables.fill_dicts(worldfile)\n    tables.input_sequences(infile, 8)\n    \n    intab = tables.get_dataframe([0, 5, 13], ['accession', 'subtype', 'genome'], ['accession'])\n    intab.reset_index(level=['accession'], inplace=True)\n    genomes = tables.get_dataframe([0, 13], ['accession', 'genome'], ['accession'])\n    header = tables.get_dataframe([0, 1, 2], ['accession', 'strain', 'segment'], ['accession'])\n    strains = tables.get_dataframe([1, 6, 7, 8, 9, 10, 11], ['strain', 'species', 'city', 'subcountry', 'country', 'year', 'host'], ['strain'])\n    \n    print(\"Finished.\")\n    \n    stop_table = time.perf_counter()\n    \n    print(f\"Table creation done in {stop_table - start_table:0.4f} seconds.\")\n    \n    \n    start_clust = time.perf_counter()\n\n    print(\"Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(intab)\n    freq_nt.calculate_frequence(intab)\n\n    matrix_nt = freq_nt.get_matrix()\n    index_nt = freq_nt.get_index()   \n    subtype_nt = freq_nt.get_subtype()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\"Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(intab)\n    freq_aa.calculate_frequence(intab)\n\n    matrix_aa = freq_aa.get_matrix()\n    index_aa = freq_aa.get_index()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix_aa_ind = pd.DataFrame(matrix_aa_red, index = index_aa)\n    matrix_nt_ind = pd.DataFrame(matrix_nt_red, index = index_nt)\n\n    matrix = pd.concat([matrix_nt_ind, matrix_aa_ind], axis=1, copy = False, ignore_index = True) #falsches Ergebnis? checken ob ignore_index = Fehler\n\n    print(\"Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\"Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), index = index_nt, columns = ['cluster', 'centroid'])\n    subtype = pd.DataFrame(subtype_nt, index = index_nt, columns = ['subtype'])\n    clusters = pd.concat([blank, subtype], axis=1, copy = False)\n\n    num = clusters['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n    \n    for i in range(num):\n\n        query = clusters[clusters.cluster == i]\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n                \n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters.update(centroids)\n    #clusters.sort_values(by=['cluster', 'subtype']).to_csv(outfile, index=True, header=True, sep=',')\n    \n    informations = pd.concat([header, clusters], axis=1, copy = False)\n    informations.sort_values(by=['cluster', 'subtype']).to_csv(outpath + 'informations.csv', index_label='accession', index=True, header=True, sep=',')\n    strains.to_csv(outpath + 'strains.csv', index_label='strain', index=True, header=True, sep=',')\n    genomes.to_csv(outpath + 'genomes.csv', index_label='accession', index=True, header=True, sep=',')\n    \n    print(\"Finished.\")\n    \n    stop_clust = time.perf_counter()\n    print(f\"Clustering done in {stop_clust - start_clust:0.4f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\"{str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\"Mean of inner cluster distance mean {overall_mean/num}\")\n    print(f\"{exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\"{exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n    print(f\"Overall running time {(stop_clust - start_clust)+(stop_table - start_table):0.4f} seconds.\")",
      "start_time": "2021-01-15T08:57:20.155Z"
     },
     {
      "end_time": "2021-01-15T09:00:24.040Z",
      "execution_time": "218ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = 'Input/A_HA.csv'   \n    setfile = 'Input/settings.csv'\n    worldfile = 'Input/cities.csv'\n    outpath = 'Output/'\n    #outfile = 'output.csv'\n    \n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    parameter = settings.loc[4].to_list()\n\n    print(\"Finished.\")\n\n    start_table = time.perf_counter()\n\n    print(\"Creating SQL tables.\", end = ' ')\n\n    tables = extractor()\n    tables.fill_dicts(worldfile)\n    tables.input_sequences(infile, 8)\n    \n    intab = tables.get_dataframe([0, 5, 13], ['accession', 'subtype', 'genome'], ['accession'])\n    intab.reset_index(level=['accession'], inplace=True)\n    genomes = tables.get_dataframe([0, 13], ['accession', 'genome'], ['accession'])\n    header = tables.get_dataframe([0, 1, 2], ['accession', 'strain', 'segment'], ['accession'])\n    strains = tables.get_dataframe([1, 6, 7, 8, 9, 10, 11], ['strain', 'species', 'city', 'subcountry', 'country', 'year', 'host'], ['strain'])\n    \n    print(\"Finished.\")\n    \n    stop_table = time.perf_counter()\n    \n    print(f\"Table creation done in {stop_table - start_table:0.4f} seconds.\")\n    \n    \n    start_clust = time.perf_counter()\n\n    print(\"Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(intab)\n    freq_nt.calculate_frequence(intab)\n\n    matrix_nt = freq_nt.get_matrix()\n    index_nt = freq_nt.get_index()   \n    subtype_nt = freq_nt.get_subtype()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\"Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(intab)\n    freq_aa.calculate_frequence(intab)\n\n    matrix_aa = freq_aa.get_matrix()\n    index_aa = freq_aa.get_index()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix_aa_ind = pd.DataFrame(matrix_aa_red, index = index_aa)\n    matrix_nt_ind = pd.DataFrame(matrix_nt_red, index = index_nt)\n\n    matrix = pd.concat([matrix_nt_ind, matrix_aa_ind], axis=1, copy = False, ignore_index = True) #falsches Ergebnis? checken ob ignore_index = Fehler\n\n    print(\"Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\"Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), index = index_nt, columns = ['cluster', 'centroid'])\n    subtype = pd.DataFrame(subtype_nt, index = index_nt, columns = ['subtype'])\n    clusters = pd.concat([blank, subtype], axis=1, copy = False)\n\n    num = clusters['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n    \n    for i in range(num):\n\n        query = clusters[clusters.cluster == i]\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n                \n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters.update(centroids)\n    #clusters.sort_values(by=['cluster', 'subtype']).to_csv(outfile, index=True, header=True, sep=',')\n    \n    informations = pd.concat([header, clusters], axis=1, copy = False)\n    informations.sort_values(by=['cluster', 'subtype']).to_csv(outpath + 'informations.csv', index_label='accession', index=True, header=True, sep=',')\n    strains.to_csv(outpath + 'strains.csv', index_label='strain', index=True, header=True, sep=',')\n    genomes.to_csv(outpath + 'genomes.csv', index_label='accession', index=True, header=True, sep=',')\n    \n    print(\"Finished.\")\n    \n    stop_clust = time.perf_counter()\n    print(f\"Clustering done in {stop_clust - start_clust:0.4f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\"{str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\"Mean of inner cluster distance mean {overall_mean/num}\")\n    print(f\"{exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\"{exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n    print(f\"Overall running time {(stop_clust - start_clust)+(stop_table - start_table):0.4f} seconds.\")",
      "start_time": "2021-01-15T09:00:23.822Z"
     },
     {
      "end_time": "2021-01-17T17:14:00.204Z",
      "execution_time": "164ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = 'Input/A_HA.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n    \n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    parameter = settings.loc[4].to_list()\n    \n    upload = pd.read_csv('Input/A.csv', sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    subset = upload.query('segment == 4').reset_index()\n    \n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n    \n    start_clust = time.perf_counter()\n\n    print(\"Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\"Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n    \n    print(\"Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\"Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n    \n    for i in range(num):\n\n        query = clusters[clusters.cluster == i]\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n                \n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters.update(centroids)\n    clusters.sort_values(by=['cluster', 'subtype']).to_csv(outfile, index=True, header=True, sep=',')\n    \n    print(\"Finished.\")\n    \n    stop_clust = time.perf_counter()\n    print(f\"Clustering done in {stop_clust - start_clust:0.4f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\"{str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\"Mean of inner cluster distance mean {overall_mean/num}\")\n    print(f\"{exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\"{exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")",
      "start_time": "2021-01-17T17:14:00.040Z"
     },
     {
      "end_time": "2021-01-17T17:15:11.679Z",
      "execution_time": "151ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = 'Input/B_HA.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n    \n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    parameter = settings.loc[4].to_list()\n    \n    upload = pd.read_csv('Input/A.csv', sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    subset = upload.query('segment == 4').reset_index()\n    \n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n    \n    start_clust = time.perf_counter()\n\n    print(\"Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\"Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n    \n    print(\"Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\"Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n    \n    for i in range(num):\n\n        query = clusters[clusters.cluster == i]\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n                \n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters.update(centroids)\n    clusters.sort_values(by=['cluster', 'subtype']).to_csv(outfile, index=True, header=True, sep=',')\n    \n    print(\"Finished.\")\n    \n    stop_clust = time.perf_counter()\n    print(f\"Clustering done in {stop_clust - start_clust:0.4f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\"{str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\"Mean of inner cluster distance mean {overall_mean/num}\")\n    print(f\"{exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\"{exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")",
      "start_time": "2021-01-17T17:15:11.528Z"
     },
     {
      "end_time": "2021-01-17T17:17:22.333Z",
      "execution_time": "155ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = 'Input/B_HA.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n    \n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    parameter = settings.loc[4].to_list()\n    \n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    subset = upload.query('segment == 4').reset_index()\n    \n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n    \n    print(\"Finished.\")\n    \n    start_clust = time.perf_counter()\n\n    print(\"Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\"Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n    \n    print(\"Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\"Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n    \n    for i in range(num):\n\n        query = clusters[clusters.cluster == i]\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n                \n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters.update(centroids)\n    clusters.sort_values(by=['cluster', 'subtype']).to_csv(outfile, index=True, header=True, sep=',')\n    \n    print(\"Finished.\")\n    \n    stop_clust = time.perf_counter()\n    print(f\"Clustering done in {stop_clust - start_clust:0.4f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\"{str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\"Mean of inner cluster distance mean {overall_mean/num}\")\n    print(f\"{exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\"{exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")",
      "start_time": "2021-01-17T17:17:22.178Z"
     },
     {
      "end_time": "2021-01-17T17:19:18.008Z",
      "execution_time": "153ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = 'Input/B_HA.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n    \n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    parameter = settings.loc[4].to_list()\n    \n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    subset = upload.query('segment == 4').reset_index()\n    \n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n    \n    print(\"Finished.\")\n    \n    start_clust = time.perf_counter()\n\n    print(\"Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\"Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n    \n    print(\"Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\"Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n    \n    for i in range(num):\n\n        query = clusters[clusters.cluster == i]\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n                \n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters.update(centroids)\n    clusters.sort_values(by=['cluster', 'subtype']).to_csv(outfile, index=True, header=True, sep=',')\n    \n    print(\"Finished.\")\n    \n    stop_clust = time.perf_counter()\n    print(f\"Clustering done in {stop_clust - start_clust:0.4f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\"{str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\"Mean of inner cluster distance mean {overall_mean/num}\")\n    print(f\"{exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\"{exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")",
      "start_time": "2021-01-17T17:19:17.855Z"
     },
     {
      "end_time": "2021-01-17T17:20:46.978Z",
      "execution_time": "159ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = 'Input/B_HA.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n    \n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    parameter = settings.loc[4].to_list()\n    \n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    subset = upload.query('segment == 4').reset_index()\n    \n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n    \n    print(\"Finished.\")\n    \n    start_clust = time.perf_counter()\n\n    print(\"Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\"Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n    \n    print(\"Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\"Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n    \n    for i in range(num):\n\n        query = clusters[clusters.cluster == i]\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n                \n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters.update(centroids)\n    clusters.sort_values(by=['cluster', 'subtype']).to_csv(outfile, index=True, header=True, sep=',')\n    \n    print(\"Finished.\")\n    \n    stop_clust = time.perf_counter()\n    print(f\"Clustering done in {stop_clust - start_clust:0.4f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\"{str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\"Mean of inner cluster distance mean {overall_mean/num}\")\n    print(f\"{exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\"{exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")",
      "start_time": "2021-01-17T17:20:46.819Z"
     },
     {
      "end_time": "2021-01-17T17:21:26.183Z",
      "execution_time": "154ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = 'Input/B_HA.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n    \n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    parameter = settings.loc[4].to_list()\n    \n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    subset = upload.query('segment == 4').reset_index()\n    \n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n    \n    print(\"Finished.\")\n    \n    start_clust = time.perf_counter()\n\n    print(\"Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    print(sequence)\n    \n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\"Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n    \n    print(\"Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\"Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n    \n    for i in range(num):\n\n        query = clusters[clusters.cluster == i]\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n                \n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters.update(centroids)\n    clusters.sort_values(by=['cluster', 'subtype']).to_csv(outfile, index=True, header=True, sep=',')\n    \n    print(\"Finished.\")\n    \n    stop_clust = time.perf_counter()\n    print(f\"Clustering done in {stop_clust - start_clust:0.4f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\"{str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\"Mean of inner cluster distance mean {overall_mean/num}\")\n    print(f\"{exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\"{exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")",
      "start_time": "2021-01-17T17:21:26.029Z"
     },
     {
      "end_time": "2021-01-17T17:21:48.669Z",
      "execution_time": "295ms",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nNucleotide k-mer frequency calculation. Empty DataFrame\nColumns: [genome]\nIndex: []\n"
       },
       {
        "ename": "UnboundLocalError",
        "evalue": "local variable 'seq' referenced before assignment",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-13-1abdee311c75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mfreq_nt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mfreq_nt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_to_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mfreq_nt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_frequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m<ipython-input-8-4ba4d11f7e41>\u001b[0m in \u001b[0;36madjust_to_data\u001b[0;34m(self, infile)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mdel\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_frequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'seq' referenced before assignment"
        ]
       }
      ],
      "source": "#def main():\n\nprint(\"Read input and settings file.\", end = ' ')\n\ninfile = 'Input/B_HA.csv'   \nsetfile = 'Input/settings.csv'\noutpath = 'Output/'\n\nsettings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\nparameter = settings.loc[4].to_list()\n\nupload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\nupload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\nsubset = upload.query('segment == 4').reset_index()\n\nsequence = subset[['genome']].copy()\naccession = subset[['accession']].copy()\nsubtype = subset[['subtype']].copy()\n\nprint(\"Finished.\")\n\nstart_clust = time.perf_counter()\n\nprint(\"Nucleotide k-mer frequency calculation.\", end = ' ')\n\nprint(sequence)\n\nfreq_nt = vectorizer(k = parameter[0].item(), convert = 0)\nfreq_nt.adjust_to_data(sequence)\nfreq_nt.calculate_frequence(sequence)\n\nmatrix_nt = freq_nt.get_matrix()\nkeys_nt = freq_nt.get_keys()\n\ndel freq_nt\n\nprint(\"Finished.\")\n\nprint(\"Running UMAP for dimension reduction.\", end = ' ')\n\nmatrix_nt_red = umap.UMAP(\n    n_neighbors = parameter[1].item(),\n    min_dist = parameter[2].item(),\n    n_components = parameter[3].item(),\n    random_state = parameter[4].item(),\n    metric = parameter[5],\n).fit_transform(matrix_nt)\n\ndel matrix_nt\n\nprint(\"Finished.\")\n\nprint(\"Aminoacid k-mer frequency calculation.\", end = ' ')\n\nfreq_aa = vectorizer(k = parameter[6].item(), convert = 1)\nfreq_aa.adjust_to_data(sequence)\nfreq_aa.calculate_frequence(sequence)\n\nmatrix_aa = freq_aa.get_matrix()\nkeys_aa = freq_aa.get_keys()\n\ndel freq_aa\n\nprint(\"Finished.\")\n\nprint(\"Running UMAP for dimension reduction.\", end = ' ')\n\nmatrix_aa_red = umap.UMAP(\n    n_neighbors = parameter[7].item(),\n    min_dist = parameter[8].item(),\n    n_components = parameter[9].item(),\n    random_state = parameter[10].item(),\n    metric = parameter[11],\n).fit_transform(matrix_aa)\n\ndel matrix_aa\n\nprint(\"Finished.\")\n\nmatrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\nprint(\"Running HDBscan for clustering.\", end = ' ')\n\nmatrix_clust = hdbscan.HDBSCAN(\n    min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n    min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n    cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n    alpha = parameter[15].item(), #don't mess with this\n).fit(matrix)\n\nprint(\"Finished.\")\n\nprint(\"Centroid extraction.\", end = ' ')\n\nclusterlabel = matrix_clust.labels_\n\nblank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\nclusters = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\nnum = clusters['cluster'].max()+1\nvalues = ['true']*num\naccessions = []\nexclude = []\ninclude = []\noverall_mean=0\nsubs = co.defaultdict(list)\n\nfor i in range(num):\n\n    query = clusters[clusters.cluster == i]\n    match = query.index.values.tolist()\n    sub = matrix.filter(items = match, axis=0)\n    dist = ssd.cdist(sub, sub, metric = parameter[16])\n    inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n    accessions.append(inner_mean.idxmin())\n    overall_mean = overall_mean + inner_mean.mean()\n\n    for sub in query['subtype'].tolist():\n        if re.match('^[H][0-9]+N[0-9]+$', sub): \n            subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n            subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n        else:\n            subs['X'].append('X0')\n            subs['X'].append('X0')\n\n    if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n        exclude.append(2)\n        if 'X' not in subs.keys():\n            include.append(2)\n    elif len(set(subs['H'])) == 1:\n        exclude.append(1)\n        if 'X' not in subs.keys():\n            include.append(1)\n    elif len(set(subs['N'])) == 1:\n        exclude.append(0)\n        if 'X' not in subs.keys():\n            include.append(0)\n\n    subs.clear()\n\ncentroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\nclusters.update(centroids)\nclusters.sort_values(by=['cluster', 'subtype']).to_csv(outfile, index=True, header=True, sep=',')\n\nprint(\"Finished.\")\n\nstop_clust = time.perf_counter()\nprint(f\"Clustering done in {stop_clust - start_clust:0.4f} seconds.\")\ndiagnostic = co.Counter(clusterlabel)\nprint(f\"{str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\nprint(f\"Mean of inner cluster distance mean {overall_mean/num}\")\nprint(f\"{exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\nprint(f\"{exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")",
      "start_time": "2021-01-17T17:21:48.374Z"
     },
     {
      "end_time": "2021-01-17T17:24:02.194Z",
      "execution_time": "163ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = 'Input/B_HA.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    parameter = settings.loc[4].to_list()\n\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    subset = upload.query('segment == 1').reset_index()\n\n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n\n    print(\"Finished.\")\n\n    start_clust = time.perf_counter()\n\n    print(\"Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    print(sequence)\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\"Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n    print(\"Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\"Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n\n    for i in range(num):\n\n        query = clusters[clusters.cluster == i]\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n\n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters.update(centroids)\n    clusters.sort_values(by=['cluster', 'subtype']).to_csv(outfile, index=True, header=True, sep=',')\n\n    print(\"Finished.\")\n\n    stop_clust = time.perf_counter()\n    print(f\"Clustering done in {stop_clust - start_clust:0.4f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\"{str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\"Mean of inner cluster distance mean {overall_mean/num}\")\n    print(f\"{exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\"{exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")",
      "start_time": "2021-01-17T17:24:02.031Z"
     },
     {
      "end_time": "2021-01-17T17:31:35.044Z",
      "execution_time": "2m 22s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nNucleotide k-mer frequency calculation. Finished.\nRunning UMAP for dimension reduction. Finished.\nAminoacid k-mer frequency calculation. Finished.\nRunning UMAP for dimension reduction. Finished.\nRunning HDBscan for clustering. Finished.\nCentroid extraction. "
       },
       {
        "ename": "NameError",
        "evalue": "name 'ssd' is not defined",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-6-9e87fee015d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mssd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0minner_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0maccessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mNameError\u001b[0m: name 'ssd' is not defined"
        ]
       }
      ],
      "source": "#def main():\n\nprint(\"Read input and settings file.\", end = ' ')\n\ninfile = 'Input/B_HA.csv'   \nsetfile = 'Input/settings.csv'\noutpath = 'Output/'\n\nsettings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\nparameter = settings.loc[4].to_list()\n\nupload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\nupload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\nsubset = upload.query('segment == 1').reset_index()\n\nsequence = subset[['genome']].copy()\naccession = subset[['accession']].copy()\nsubtype = subset[['subtype']].copy()\n\nprint(\"Finished.\")\n\nstart_clust = time.perf_counter()\n\nprint(\"Nucleotide k-mer frequency calculation.\", end = ' ')\n\nfreq_nt = vectorizer(k = parameter[0].item(), convert = 0)\nfreq_nt.adjust_to_data(sequence)\nfreq_nt.calculate_frequence(sequence)\n\nmatrix_nt = freq_nt.get_matrix()\nkeys_nt = freq_nt.get_keys()\n\ndel freq_nt\n\nprint(\"Finished.\")\n\nprint(\"Running UMAP for dimension reduction.\", end = ' ')\n\nmatrix_nt_red = umap.UMAP(\n    n_neighbors = parameter[1].item(),\n    min_dist = parameter[2].item(),\n    n_components = parameter[3].item(),\n    random_state = parameter[4].item(),\n    metric = parameter[5],\n).fit_transform(matrix_nt)\n\ndel matrix_nt\n\nprint(\"Finished.\")\n\nprint(\"Aminoacid k-mer frequency calculation.\", end = ' ')\n\nfreq_aa = vectorizer(k = parameter[6].item(), convert = 1)\nfreq_aa.adjust_to_data(sequence)\nfreq_aa.calculate_frequence(sequence)\n\nmatrix_aa = freq_aa.get_matrix()\nkeys_aa = freq_aa.get_keys()\n\ndel freq_aa\n\nprint(\"Finished.\")\n\nprint(\"Running UMAP for dimension reduction.\", end = ' ')\n\nmatrix_aa_red = umap.UMAP(\n    n_neighbors = parameter[7].item(),\n    min_dist = parameter[8].item(),\n    n_components = parameter[9].item(),\n    random_state = parameter[10].item(),\n    metric = parameter[11],\n).fit_transform(matrix_aa)\n\ndel matrix_aa\n\nprint(\"Finished.\")\n\nmatrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\nprint(\"Running HDBscan for clustering.\", end = ' ')\n\nmatrix_clust = hdbscan.HDBSCAN(\n    min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n    min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n    cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n    alpha = parameter[15].item(), #don't mess with this\n).fit(matrix)\n\nprint(\"Finished.\")\n\nprint(\"Centroid extraction.\", end = ' ')\n\nclusterlabel = matrix_clust.labels_\n\nblank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\nclusters = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\nnum = clusters['cluster'].max()+1\nvalues = ['true']*num\naccessions = []\nexclude = []\ninclude = []\noverall_mean=0\nsubs = co.defaultdict(list)\n\nfor i in range(num):\n\n    query = clusters[clusters.cluster == i]\n    match = query.index.values.tolist()\n    sub = matrix.filter(items = match, axis=0)\n    dist = ssd.cdist(sub, sub, metric = parameter[16])\n    inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n    accessions.append(inner_mean.idxmin())\n    overall_mean = overall_mean + inner_mean.mean()\n\n    for sub in query['subtype'].tolist():\n        if re.match('^[H][0-9]+N[0-9]+$', sub): \n            subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n            subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n        else:\n            subs['X'].append('X0')\n            subs['X'].append('X0')\n\n    if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n        exclude.append(2)\n        if 'X' not in subs.keys():\n            include.append(2)\n    elif len(set(subs['H'])) == 1:\n        exclude.append(1)\n        if 'X' not in subs.keys():\n            include.append(1)\n    elif len(set(subs['N'])) == 1:\n        exclude.append(0)\n        if 'X' not in subs.keys():\n            include.append(0)\n\n    subs.clear()\n\ncentroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\nclusters.update(centroids)\nclusters.sort_values(by=['cluster', 'subtype']).to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n\nprint(\"Finished.\")\n\nstop_clust = time.perf_counter()\nprint(f\"Clustering done in {stop_clust - start_clust:0.4f} seconds.\")\ndiagnostic = co.Counter(clusterlabel)\nprint(f\"{str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\nprint(f\"Mean of inner cluster distance mean {overall_mean/num}\")\nprint(f\"{exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\nprint(f\"{exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")",
      "start_time": "2021-01-17T17:29:13.330Z"
     },
     {
      "end_time": "2021-01-17T17:51:51.327Z",
      "execution_time": "153ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = 'Input/A.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    parameter = settings.loc[4].to_list()\n\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    subset = upload.query('segment == 1').reset_index()\n\n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n\n    print(\"Finished.\")\n\n    start_clust = time.perf_counter()\n\n    print(\"Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\"Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n    print(\"Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\"Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n\n    for i in range(num):\n\n        query = clusters[clusters.cluster == i]\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n\n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters.update(centroids)\n    clusters.sort_values(by=['cluster', 'subtype']).to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n\n    print(\"Finished.\")\n\n    stop_clust = time.perf_counter()\n    print(f\"Clustering done in {stop_clust - start_clust:0.4f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\"{str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\"Mean of inner cluster distance mean {overall_mean/num}\")\n    print(f\"{exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\"{exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")",
      "start_time": "2021-01-17T17:51:51.174Z"
     },
     {
      "end_time": "2021-01-17T18:21:54.850Z",
      "execution_time": "236ms",
      "outputs": [
       {
        "ename": "SyntaxError",
        "evalue": "invalid syntax (<ipython-input-20-40480b8c0d08>, line 17)",
        "output_type": "error",
        "traceback": [
         "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-40480b8c0d08>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    start_clust = time.perf_counter()\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
        ]
       }
      ],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    memory = memory_usage(f)\n    infile = 'Input/A_HA_sample.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    \n    print(\"Finished.\")\n    \n    print(f\"Starting calculations for segment {segment}.\"\n    \n    start_clust = time.perf_counter()\n    \n    segment = 4\n    parameter = settings.loc[segment].to_list()\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    subset = upload.query('segment == @segment').reset_index()\n\n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n    \n    print(\"Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\"Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n    print(\"Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\"Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n\n    for i in range(num):\n\n        query = clusters.query('cluster == @i')\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n\n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters.update(centroids)\n    clusters.sort_values(by=['cluster', 'subtype']).to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n\n    print(\"Finished.\")\n\n    stop_clust = time.perf_counter()\n    print(f\"Clustering done in {stop_clust - start_clust:0.4f} seconds.\")\n    print(\"Maximum memory used: %s\" % max(mem_usage))\n    diagnostic = co.Counter(clusterlabel)\n    print(f\"{str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\"Mean of inner cluster distance mean {overall_mean/num}\")\n    print(f\"{exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\"{exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")",
      "start_time": "2021-01-17T18:21:54.614Z"
     },
     {
      "end_time": "2021-01-17T18:22:09.168Z",
      "execution_time": "171ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    memory = memory_usage(f)\n    infile = 'Input/A_HA_sample.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    \n    print(\"Finished.\")\n    \n    print(f\"Starting calculations for segment {segment}.\")\n    \n    start_clust = time.perf_counter()\n    \n    segment = 4\n    parameter = settings.loc[segment].to_list()\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    subset = upload.query('segment == @segment').reset_index()\n\n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n    \n    print(\"Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\"Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n    print(\"Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\"Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n\n    for i in range(num):\n\n        query = clusters.query('cluster == @i')\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n\n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters.update(centroids)\n    clusters.sort_values(by=['cluster', 'subtype']).to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n\n    print(\"Finished.\")\n\n    stop_clust = time.perf_counter()\n    print(f\"Clustering done in {stop_clust - start_clust:0.4f} seconds.\")\n    print(\"Maximum memory used: %s\" % max(mem_usage))\n    diagnostic = co.Counter(clusterlabel)\n    print(f\"{str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\"Mean of inner cluster distance mean {overall_mean/num}\")\n    print(f\"{exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\"{exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")",
      "start_time": "2021-01-17T18:22:08.997Z"
     },
     {
      "end_time": "2021-01-17T18:23:59.617Z",
      "execution_time": "166ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = 'Input/A_HA_sample.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    \n    print(\"Finished.\")\n    \n    print(f\"Starting calculations for segment {segment}.\")\n    \n    start_clust = time.perf_counter()\n    \n    segment = 4\n    parameter = settings.loc[segment].to_list()\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    subset = upload.query('segment == @segment').reset_index()\n\n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n    \n    print(\"Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\"Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n    print(\"Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\"Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n\n    for i in range(num):\n\n        query = clusters.query('cluster == @i')\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n\n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters.update(centroids)\n    clusters.sort_values(by=['cluster', 'subtype']).to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n\n    print(\"Finished.\")\n\n    stop_clust = time.perf_counter()\n    print(f\"Clustering done in {stop_clust - start_clust:0.4f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\"{str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\"Mean of inner cluster distance mean {overall_mean/num}\")\n    print(f\"{exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\"{exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")",
      "start_time": "2021-01-17T18:23:59.451Z"
     },
     {
      "end_time": "2021-01-17T18:24:19.343Z",
      "execution_time": "162ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = 'Input/A_HA_sample.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    \n    print(\"Finished.\")\n    \n    segment = 4\n    print(f\"Starting calculations for segment {segment}.\")\n    \n    start_clust = time.perf_counter()\n    \n    parameter = settings.loc[segment].to_list()\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    subset = upload.query('segment == @segment').reset_index()\n\n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n    \n    print(\"Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\"Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n    print(\"Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\"Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n\n    for i in range(num):\n\n        query = clusters.query('cluster == @i')\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n\n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters.update(centroids)\n    clusters.sort_values(by=['cluster', 'subtype']).to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n\n    print(\"Finished.\")\n\n    stop_clust = time.perf_counter()\n    print(f\"Clustering done in {stop_clust - start_clust:0.4f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\"{str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\"Mean of inner cluster distance mean {overall_mean/num}\")\n    print(f\"{exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\"{exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")",
      "start_time": "2021-01-17T18:24:19.181Z"
     },
     {
      "end_time": "2021-01-17T18:36:38.700Z",
      "execution_time": "158ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = 'Input/A.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    \n    print(\"Finished.\")\n    \n    segment = 4\n    print(f\"Starting calculations for segment {segment}:\")\n    \n    start_clust = time.perf_counter()\n    \n    parameter = settings.loc[segment].to_list()\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    subset = upload.query('segment == @segment').reset_index()\n\n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n    \n    print(\"Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\"Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\"Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n    print(\"Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\"Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n\n    for i in range(num):\n\n        query = clusters.query('cluster == @i')\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n\n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters.update(centroids)\n    clusters.sort_values(by=['cluster', 'subtype']).to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n\n    print(\"Finished.\")\n\n    stop_clust = time.perf_counter()\n    print(f\"Clustering done in {stop_clust - start_clust:0.4f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\"{str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\"Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n    print(f\"{exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\"{exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")",
      "start_time": "2021-01-17T18:36:38.542Z"
     },
     {
      "end_time": "2021-01-18T11:20:11.735Z",
      "execution_time": "172ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = 'Input/A.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    \n    print(\"Finished.\")\n    \n    for segment in segments:\n        \n        print(f\" Starting calculations for segment {segment}:\")\n\n        start_clust = time.perf_counter()\n\n        parameter = settings.loc[segment].to_list()\n        upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print(\" Nucleotide k-mer frequency calculation.\", end = ' ')\n\n        freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print(\"Finished.\")\n\n        print(\" Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = parameter[1].item(),\n            min_dist = parameter[2].item(),\n            n_components = parameter[3].item(),\n            random_state = parameter[4].item(),\n            metric = parameter[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print(\"Finished.\")\n\n        print(\" Aminoacid k-mer frequency calculation.\", end = ' ')\n\n        freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print(\"Finished.\")\n\n        print(\" Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = parameter[7].item(),\n            min_dist = parameter[8].item(),\n            n_components = parameter[9].item(),\n            random_state = parameter[10].item(),\n            metric = parameter[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print(\"Finished.\")\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print(\" Running HDBscan for clustering.\", end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n            cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n            alpha = parameter[15].item(), #don't mess with this\n        ).fit(matrix)\n\n        print(\"Finished.\")\n\n        print(\" Centroid extraction.\", end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['true']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = parameter[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].update(centroids)\n        clusters[segment].sort_values(by=['cluster', 'subtype']).to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n\n        print(\"Finished.\")\n\n        stop_clust = time.perf_counter()\n        print(f\" Clustering done in {stop_clust - start_clust:0.2f} seconds.\")\n        diagnostic = co.Counter(clusterlabel)\n        print(f\" {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n        print(f\" Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n        print(f\" {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n        print(f\" {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")",
      "start_time": "2021-01-18T11:20:11.563Z"
     },
     {
      "end_time": "2021-01-18T11:22:44.058Z",
      "execution_time": "163ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = '../../B.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    \n    print(\"Finished.\")\n    \n    for segment in segments:\n        \n        print(f\" Starting calculations for segment {segment}:\")\n\n        start_clust = time.perf_counter()\n\n        parameter = settings.loc[segment].to_list()\n        upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print(\" Nucleotide k-mer frequency calculation.\", end = ' ')\n\n        freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print(\"Finished.\")\n\n        print(\" Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = parameter[1].item(),\n            min_dist = parameter[2].item(),\n            n_components = parameter[3].item(),\n            random_state = parameter[4].item(),\n            metric = parameter[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print(\"Finished.\")\n\n        print(\" Aminoacid k-mer frequency calculation.\", end = ' ')\n\n        freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print(\"Finished.\")\n\n        print(\" Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = parameter[7].item(),\n            min_dist = parameter[8].item(),\n            n_components = parameter[9].item(),\n            random_state = parameter[10].item(),\n            metric = parameter[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print(\"Finished.\")\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print(\" Running HDBscan for clustering.\", end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n            cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n            alpha = parameter[15].item(), #don't mess with this\n        ).fit(matrix)\n\n        print(\"Finished.\")\n\n        print(\" Centroid extraction.\", end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['true']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = parameter[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].update(centroids)\n        clusters[segment].sort_values(by=['cluster', 'subtype']).to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n\n        print(\"Finished.\")\n\n        stop_clust = time.perf_counter()\n        print(f\" Clustering done in {stop_clust - start_clust:0.2f} seconds.\")\n        diagnostic = co.Counter(clusterlabel)\n        print(f\" {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n        print(f\" Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n        print(f\" {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n        print(f\" {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")",
      "start_time": "2021-01-18T11:22:43.895Z"
     },
     {
      "end_time": "2021-01-18T11:52:57.627Z",
      "execution_time": "173ms",
      "outputs": [
       {
        "ename": "SyntaxError",
        "evalue": "EOL while scanning string literal (<ipython-input-29-13dc04f3ad3e>, line 164)",
        "output_type": "error",
        "traceback": [
         "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-13dc04f3ad3e>\"\u001b[0;36m, line \u001b[0;32m164\u001b[0m\n\u001b[0;31m    print(f\"Overall execution time {time:0.2f} seconds.)\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
        ]
       }
      ],
      "source": "#def main():\n\nprint(\"Read input and settings file.\", end = ' ')\n\ninfile = '../../B.csv'   \nsetfile = 'Input/settings.csv'\noutpath = 'Output/'\n\nsettings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\nupload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\nsegments = settings.index.values.tolist()\nclusters = co.defaultdict(list)\ntime = 0\n\nprint(\"Finished.\")\n\nfor segment in segments:\n\n    print(f\"Starting calculations for segment {segment}:\")\n\n    start_clust = time.perf_counter()\n\n    parameter = settings.loc[segment].to_list()\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    subset = upload.query('segment == @segment').reset_index()\n\n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n\n    print(\" Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\" Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\" Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\" Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n    print(\" Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\" Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters[segment]['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n\n    for i in range(num):\n\n        query = clusters[segment].query('cluster == @i')\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n\n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters[segment].update(centroids)\n    clusters[segment].sort_values(by=['cluster', 'subtype']).to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n\n    print(\"Finished.\")\n\n    stop_clust = time.perf_counter()\n    exec_clust = stop_clust - start_clust\n    time = time + exec_clust\n\n    print(f\" Clustering done in {exec_clust:0.2f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\" {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\" Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n    print(f\" {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\" {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n\nprint(f\"Overall execution time {time:0.2f} seconds.)",
      "start_time": "2021-01-18T11:52:57.454Z"
     },
     {
      "end_time": "2021-01-18T11:53:06.258Z",
      "execution_time": "908ms",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n"
       },
       {
        "ename": "AttributeError",
        "evalue": "'int' object has no attribute 'perf_counter'",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-30-8d6bf1788c38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Starting calculations for segment {segment}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mstart_clust\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mparameter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'perf_counter'"
        ]
       }
      ],
      "source": "#def main():\n\nprint(\"Read input and settings file.\", end = ' ')\n\ninfile = '../../B.csv'   \nsetfile = 'Input/settings.csv'\noutpath = 'Output/'\n\nsettings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\nupload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\nsegments = settings.index.values.tolist()\nclusters = co.defaultdict(list)\ntime = 0\n\nprint(\"Finished.\")\n\nfor segment in segments:\n\n    print(f\"Starting calculations for segment {segment}:\")\n\n    start_clust = time.perf_counter()\n\n    parameter = settings.loc[segment].to_list()\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    subset = upload.query('segment == @segment').reset_index()\n\n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n\n    print(\" Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\" Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\" Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\" Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n    print(\" Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\" Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters[segment]['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n\n    for i in range(num):\n\n        query = clusters[segment].query('cluster == @i')\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n\n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters[segment].update(centroids)\n    clusters[segment].sort_values(by=['cluster', 'subtype']).to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n\n    print(\"Finished.\")\n\n    stop_clust = time.perf_counter()\n    exec_clust = stop_clust - start_clust\n    time = time + exec_clust\n\n    print(f\" Clustering done in {exec_clust:0.2f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\" {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\" Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n    print(f\" {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\" {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n\nprint(f\"Overall execution time {time:0.2f} seconds.\")",
      "start_time": "2021-01-18T11:53:05.350Z"
     },
     {
      "end_time": "2021-01-18T11:53:53.051Z",
      "execution_time": "922ms",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n"
       },
       {
        "ename": "AttributeError",
        "evalue": "'int' object has no attribute 'perf_counter'",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-31-18f6b86a9892>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Starting calculations for segment {segment}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mstart_clust\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mparameter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'perf_counter'"
        ]
       }
      ],
      "source": "#def main():\n\nprint(\"Read input and settings file.\", end = ' ')\n\ninfile = '../../B.csv'   \nsetfile = 'Input/settings.csv'\noutpath = 'Output/'\n\nsettings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\nupload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\nsegments = settings.index.values.tolist()\nclusters = co.defaultdict(list)\nexec_time = 0\n\nprint(\"Finished.\")\n\nfor segment in segments:\n\n    print(f\"Starting calculations for segment {segment}:\")\n\n    start_clust = time.perf_counter()\n\n    parameter = settings.loc[segment].to_list()\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    subset = upload.query('segment == @segment').reset_index()\n\n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n\n    print(\" Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\" Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\" Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\" Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n    print(\" Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\" Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters[segment]['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n\n    for i in range(num):\n\n        query = clusters[segment].query('cluster == @i')\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n\n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters[segment].update(centroids)\n    clusters[segment].sort_values(by=['cluster', 'subtype']).to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n\n    print(\"Finished.\")\n\n    stop_clust = time.perf_counter()\n    exec_clust = stop_clust - start_clust\n    exec_time = exec_time + exec_clust\n\n    print(f\" Clustering done in {exec_clust:0.2f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\" {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\" Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n    print(f\" {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\" {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n\nprint(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-18T11:53:52.129Z"
     },
     {
      "end_time": "2021-01-18T12:13:59.892Z",
      "execution_time": "19m 21s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n Nucleotide k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Aminoacid k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Running HDBscan for clustering. Finished.\n Centroid extraction. Finished.\n Clustering done in 160.10 seconds.\n 10382 sequences, 6 unclustered, 239 cluster.\n Mean of inner cluster distance mean 0.0001108158\n 0(0) clusters containing matching NA types.\n 0(0) clusters containing matching HA types.\nStarting calculations for segment 2:\n Nucleotide k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Aminoacid k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Running HDBscan for clustering. Finished.\n Centroid extraction. Finished.\n Clustering done in 153.61 seconds.\n 10406 sequences, 12 unclustered, 263 cluster.\n Mean of inner cluster distance mean 0.0000472150\n 0(0) clusters containing matching NA types.\n 0(0) clusters containing matching HA types.\nStarting calculations for segment 3:\n Nucleotide k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Aminoacid k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Running HDBscan for clustering. Finished.\n Centroid extraction. Finished.\n Clustering done in 136.31 seconds.\n 10397 sequences, 7 unclustered, 235 cluster.\n Mean of inner cluster distance mean 0.0001054200\n 0(0) clusters containing matching NA types.\n 0(0) clusters containing matching HA types.\nStarting calculations for segment 4:\n Nucleotide k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Aminoacid k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Running HDBscan for clustering. Finished.\n Centroid extraction. Finished.\n Clustering done in 147.91 seconds.\n 10512 sequences, 11 unclustered, 244 cluster.\n Mean of inner cluster distance mean 0.0000740418\n 0(0) clusters containing matching NA types.\n 0(0) clusters containing matching HA types.\nStarting calculations for segment 5:\n Nucleotide k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Aminoacid k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Running HDBscan for clustering. Finished.\n Centroid extraction. Finished.\n Clustering done in 147.11 seconds.\n 10390 sequences, 18 unclustered, 251 cluster.\n Mean of inner cluster distance mean 0.0001167966\n 0(0) clusters containing matching NA types.\n 0(0) clusters containing matching HA types.\nStarting calculations for segment 6:\n Nucleotide k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Aminoacid k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Running HDBscan for clustering. Finished.\n Centroid extraction. Finished.\n Clustering done in 145.60 seconds.\n 10496 sequences, 20 unclustered, 256 cluster.\n Mean of inner cluster distance mean 0.0001162096\n 0(0) clusters containing matching NA types.\n 0(0) clusters containing matching HA types.\nStarting calculations for segment 7:\n Nucleotide k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Aminoacid k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Running HDBscan for clustering. Finished.\n Centroid extraction. Finished.\n Clustering done in 134.39 seconds.\n 10402 sequences, 37 unclustered, 245 cluster.\n Mean of inner cluster distance mean 0.0001648957\n 0(0) clusters containing matching NA types.\n 0(0) clusters containing matching HA types.\nStarting calculations for segment 8:\n Nucleotide k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Aminoacid k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Running HDBscan for clustering. Finished.\n Centroid extraction. Finished.\n Clustering done in 135.29 seconds.\n 10405 sequences, 26 unclustered, 242 cluster.\n Mean of inner cluster distance mean 0.0001719148\n 0(0) clusters containing matching NA types.\n 0(0) clusters containing matching HA types.\nOverall execution time 1160.31 seconds.\n"
       }
      ],
      "source": "#def main():\n\nprint(\"Read input and settings file.\", end = ' ')\n\ninfile = '../../B.csv'   \nsetfile = 'Input/settings.csv'\noutpath = 'Output/'\n\nsettings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\nupload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\nsegments = settings.index.values.tolist()\nclusters = co.defaultdict(list)\nexec_time = 0\n\nprint(\"Finished.\")\n\nfor segment in segments:\n\n    print(f\"Starting calculations for segment {segment}:\")\n\n    start_clust = time.perf_counter()\n\n    parameter = settings.loc[segment].to_list()\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    subset = upload.query('segment == @segment').reset_index()\n\n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n\n    print(\" Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\" Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\" Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\" Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n    print(\" Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\" Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters[segment]['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n\n    for i in range(num):\n\n        query = clusters[segment].query('cluster == @i')\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n\n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters[segment].update(centroids)\n    clusters[segment].sort_values(by=['cluster', 'subtype']).to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n\n    print(\"Finished.\")\n\n    stop_clust = time.perf_counter()\n    exec_clust = stop_clust - start_clust\n    exec_time = exec_time + exec_clust\n\n    print(f\" Clustering done in {exec_clust:0.2f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\" {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\" Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n    print(f\" {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\" {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n\nprint(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-18T11:54:38.646Z"
     },
     {
      "end_time": "2021-01-18T13:36:12.677Z",
      "execution_time": "210ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = '../../B.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    exec_time = 0\n\n    print(\"Finished.\")\n\n    for segment in segments:\n\n        print(f\"Starting calculations for segment {segment}:\")\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print(\" Nucleotide k-mer frequency calculation.\", end = ' ')\n\n        freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print(\"Finished.\")\n\n        print(\" Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = parameter[1].item(),\n            min_dist = parameter[2].item(),\n            n_components = parameter[3].item(),\n            random_state = parameter[4].item(),\n            metric = parameter[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print(\"Finished.\")\n\n        print(\" Aminoacid k-mer frequency calculation.\", end = ' ')\n\n        freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print(\"Finished.\")\n\n        print(\" Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = parameter[7].item(),\n            min_dist = parameter[8].item(),\n            n_components = parameter[9].item(),\n            random_state = parameter[10].item(),\n            metric = parameter[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print(\"Finished.\")\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print(\" Running HDBscan for clustering.\", end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n            cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n            alpha = parameter[15].item(), #don't mess with this\n        ).fit(matrix)\n\n        print(\"Finished.\")\n\n        print(\" Centroid extraction.\", end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['true']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = parameter[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].update(centroids)\n\n        print(\"Finished.\")\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f\" Clustering done in {exec_clust:0.2f} seconds.\")\n        diagnostic = co.Counter(clusterlabel)\n        print(f\" {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n        print(f\" Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n        print(f\" {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n        print(f\" {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n\n    result = pd.concat(clusters)\n    result.index.set_names([\"segment\", \"accession\"], inplace=True)\n    result.reset_index(level = \"segment\", inplace=True)  \n    result.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n    print(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-18T13:36:12.467Z"
     },
     {
      "end_time": "2021-01-18T13:46:06.432Z",
      "execution_time": "187ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = '../../B.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    exec_time = 0\n\n    print(\"Finished.\")\n\n    for segment in segments:\n\n        print(f\"Starting calculations for segment {segment}:\")\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print(\" Nucleotide k-mer frequency calculation.\", end = ' ')\n\n        freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print(\"Finished.\")\n\n        print(\" Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = parameter[1].item(),\n            min_dist = parameter[2].item(),\n            n_components = parameter[3].item(),\n            random_state = parameter[4].item(),\n            metric = parameter[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print(\"Finished.\")\n\n        print(\" Aminoacid k-mer frequency calculation.\", end = ' ')\n\n        freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print(\"Finished.\")\n\n        print(\" Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = parameter[7].item(),\n            min_dist = parameter[8].item(),\n            n_components = parameter[9].item(),\n            random_state = parameter[10].item(),\n            metric = parameter[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print(\"Finished.\")\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print(\" Running HDBscan for clustering.\", end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n            cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n            alpha = parameter[15].item(), #don't mess with this\n        ).fit(matrix)\n\n        print(\"Finished.\")\n\n        print(\" Centroid extraction.\", end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['true']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = parameter[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].update(centroids)\n\n        print(\"Finished.\")\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f\" Clustering done in {exec_clust:0.2f} seconds.\")\n        diagnostic = co.Counter(clusterlabel)\n        print(f\" {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n        print(f\" Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n        print(f\" {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n        print(f\" {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n\n    result = pd.concat(clusters)\n    result.index.set_names([\"segment\", \"accession\"], inplace=True)\n    result.reset_index(level = \"segment\", inplace=True)  \n    result.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n    print(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-18T13:46:06.245Z"
     },
     {
      "end_time": "2021-01-18T13:47:32.330Z",
      "execution_time": "188ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = '../../B.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    exec_time = 0\n\n    print(\"Finished.\")\n\n    for segment in segments:\n\n        print(f\"Starting calculations for segment {segment}:\")\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\n        freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = parameter[1].item(),\n            min_dist = parameter[2].item(),\n            n_components = parameter[3].item(),\n            random_state = parameter[4].item(),\n            metric = parameter[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print(\"Finished.\")\n\n        print(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\n        freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = parameter[7].item(),\n            min_dist = parameter[8].item(),\n            n_components = parameter[9].item(),\n            random_state = parameter[10].item(),\n            metric = parameter[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print(\"Finished.\")\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print(\"- Running HDBscan for clustering.\", end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n            cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n            alpha = parameter[15].item(), #don't mess with this\n        ).fit(matrix)\n\n        print(\"Finished.\")\n\n        print(\"- Centroid extraction.\", end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['true']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = parameter[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].update(centroids)\n\n        print(\"Finished.\")\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\n        diagnostic = co.Counter(clusterlabel)\n        print(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n        print(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n        print(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n        print(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n\n    result = pd.concat(clusters)\n    result.index.set_names([\"segment\", \"accession\"], inplace=True)\n    result.reset_index(level = \"segment\", inplace=True)  \n    result.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n    print(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-18T13:47:32.142Z"
     },
     {
      "end_time": "2021-01-18T15:04:38.229Z",
      "execution_time": "2m 37s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. "
       },
       {
        "ename": "AttributeError",
        "evalue": "'list' object has no attribute 'max'",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-98-265fc29e9bae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mclusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mclusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_clust\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mincrement\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'max'"
        ]
       }
      ],
      "source": "#def main():\n\nprint(\"Read input and settings file.\", end = ' ')\n\ninfile = '../../B.csv'   \nsetfile = 'Input/settings.csv'\noutpath = 'Output/'\n\nsettings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\nupload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\nupload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\nsegments = settings.index.values.tolist()\nclusters = co.defaultdict(list)\nexec_time = 0\nincrement = 0\n\nprint(\"Finished.\")\n\nfor segment in segments:\n\n    print(f\"Starting calculations for segment {segment}:\")\n\n    start_clust = time.perf_counter()\n    parameter = settings.loc[segment].to_list()\n    subset = upload.query('segment == @segment').reset_index()\n\n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n\n    print(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n    print(\"- Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\"- Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters[segment]['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n\n    for i in range(num):\n\n        query = clusters[segment].query('cluster == @i')\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n\n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n    new_clust = clusters[segment].query('cluster != -1')['cluster'] + increment\n\n    clusters[segment].update(centroids)\n    clusters[segment].update(new_clust)\n    increment += clusters['cluster'].max()\n\n    print(\"Finished.\")\n\n    stop_clust = time.perf_counter()\n    exec_clust = stop_clust - start_clust\n    exec_time = exec_time + exec_clust\n\n    print(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n    print(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n    print(\"Finished.\")\n\nresult = pd.concat(clusters)\nresult.index.set_names([\"segment\", \"accession\"], inplace=True)\nresult.reset_index(level = \"segment\", inplace=True)  \nresult.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\nresult.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\nprint(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-18T15:02:01.481Z"
     },
     {
      "end_time": "2021-01-18T15:35:31.886Z",
      "execution_time": "19m 13s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 153.94 seconds.\n- 10381 sequences, 11 unclustered, 235 cluster.\n- Mean of inner cluster distance mean 0.0001484015\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 2:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 153.70 seconds.\n- 10405 sequences, 11 unclustered, 259 cluster.\n- Mean of inner cluster distance mean 0.0000459151\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 3:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. "
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": "/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\nfailed. This is likely due to too small an eigengap. Consider\nadding some noise or jitter to your data.\n\nFalling back to random initialisation!\n  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 135.62 seconds.\n- 10396 sequences, 16 unclustered, 231 cluster.\n- Mean of inner cluster distance mean 0.0000558589\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 4:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 147.79 seconds.\n- 10511 sequences, 13 unclustered, 245 cluster.\n- Mean of inner cluster distance mean 0.0000552752\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 5:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 145.51 seconds.\n- 10389 sequences, 15 unclustered, 252 cluster.\n- Mean of inner cluster distance mean 0.0000610103\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 6:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 146.32 seconds.\n- 10495 sequences, 14 unclustered, 253 cluster.\n- Mean of inner cluster distance mean 0.0000657352\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 7:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 135.91 seconds.\n- 10401 sequences, 29 unclustered, 246 cluster.\n- Mean of inner cluster distance mean 0.0000506483\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 8:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 133.15 seconds.\n- 10403 sequences, 35 unclustered, 244 cluster.\n- Mean of inner cluster distance mean 0.0001635287\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nOverall execution time 1151.95 seconds.\n"
       }
      ],
      "source": "#def main():\n\nprint(\"Read input and settings file.\", end = ' ')\n\ninfile = '../../B.csv'   \nsetfile = 'Input/settings.csv'\noutpath = 'Output/'\n\nsettings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\nupload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\nupload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\nsegments = settings.index.values.tolist()\nclusters = co.defaultdict(list)\nexec_time = 0\nincrement = 0\n\nprint(\"Finished.\")\n\nfor segment in segments:\n\n    print(f\"Starting calculations for segment {segment}:\")\n\n    start_clust = time.perf_counter()\n    parameter = settings.loc[segment].to_list()\n    subset = upload.query('segment == @segment').reset_index()\n\n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n\n    print(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n    print(\"- Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\"- Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters[segment]['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n\n    for i in range(num):\n\n        query = clusters[segment].query('cluster == @i')\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n\n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n    new_clust = clusters[segment].query('cluster != -1')['cluster'] + increment\n\n    clusters[segment].update(centroids)\n    clusters[segment].update(new_clust)\n    increment += clusters[segment]['cluster'].max()\n\n    print(\"Finished.\")\n\n    stop_clust = time.perf_counter()\n    exec_clust = stop_clust - start_clust\n    exec_time = exec_time + exec_clust\n\n    print(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n    print(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n    print(\"Finished.\")\n\nresult = pd.concat(clusters)\nresult.index.set_names([\"segment\", \"accession\"], inplace=True)\nresult.reset_index(level = \"segment\", inplace=True)  \nresult.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\nresult.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\nprint(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-18T15:16:18.712Z"
     },
     {
      "end_time": "2021-01-18T15:49:55.732Z",
      "execution_time": "211ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = '../../B.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    exec_time = 0\n    increment = 0\n\n    print(\"Finished.\")\n\n    for segment in segments:\n\n        print(f\"Starting calculations for segment {segment}:\")\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\n        freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = parameter[1].item(),\n            min_dist = parameter[2].item(),\n            n_components = parameter[3].item(),\n            random_state = parameter[4].item(),\n            metric = parameter[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print(\"Finished.\")\n\n        print(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\n        freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = parameter[7].item(),\n            min_dist = parameter[8].item(),\n            n_components = parameter[9].item(),\n            random_state = parameter[10].item(),\n            metric = parameter[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print(\"Finished.\")\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print(\"- Running HDBscan for clustering.\", end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n            cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n            alpha = parameter[15].item(), #don't mess with this\n        ).fit(matrix)\n\n        print(\"Finished.\")\n\n        print(\"- Centroid extraction.\", end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['true']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = parameter[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n        new_clust = clusters[segment].query('cluster != -1')['cluster'] + increment\n        new_clust['cluster'] = new_clust['cluster'].astype(int) \n\n        clusters[segment].update(centroids)\n        clusters[segment].update(new_clust)\n        increment += num - 1\n\n        print(\"Finished.\")\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\n        diagnostic = co.Counter(clusterlabel)\n        print(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n        print(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n        print(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n        print(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n        print(\"Finished.\")\n\n    result = pd.concat(clusters)\n    result.index.set_names([\"segment\", \"accession\"], inplace=True)\n    result.reset_index(level = \"segment\", inplace=True)  \n    result.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n    print(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-18T15:49:55.521Z"
     },
     {
      "end_time": "2021-01-18T15:59:17.978Z",
      "execution_time": "220ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = '../../B.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    exec_time = 0\n    increment = 0\n\n    print(\"Finished.\")\n\n    for segment in segments:\n\n        print(f\"Starting calculations for segment {segment}:\")\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\n        freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = parameter[1].item(),\n            min_dist = parameter[2].item(),\n            n_components = parameter[3].item(),\n            random_state = parameter[4].item(),\n            metric = parameter[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print(\"Finished.\")\n\n        print(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\n        freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = parameter[7].item(),\n            min_dist = parameter[8].item(),\n            n_components = parameter[9].item(),\n            random_state = parameter[10].item(),\n            metric = parameter[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print(\"Finished.\")\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print(\"- Running HDBscan for clustering.\", end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n            cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n            alpha = parameter[15].item(), #don't mess with this\n        ).fit(matrix)\n\n        print(\"Finished.\")\n\n        print(\"- Centroid extraction.\", end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['true']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = parameter[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n        new_clust = clusters[segment].query('cluster != -1')['cluster'] + int(increment)\n        \n        clusters[segment].update(centroids)\n        clusters[segment].update(new_clust.astype(int))\n        increment += num - 1\n\n        print(\"Finished.\")\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\n        diagnostic = co.Counter(clusterlabel)\n        print(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n        print(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n        print(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n        print(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n        print(\"Finished.\")\n\n    result = pd.concat(clusters)\n    result.index.set_names([\"segment\", \"accession\"], inplace=True)\n    result.reset_index(level = \"segment\", inplace=True)  \n    result.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n    print(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-18T15:59:17.758Z"
     },
     {
      "end_time": "2021-01-18T16:05:55.277Z",
      "execution_time": "2m 45s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 157.49 seconds.\n- 10381 sequences, 13 unclustered, 232 cluster.\n- Mean of inner cluster distance mean 0.0001164629\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 2:\n- Nucleotide k-mer frequency calculation. "
       },
       {
        "ename": "KeyboardInterrupt",
        "evalue": "",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-130-37f7e9b03fc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mfreq_nt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mfreq_nt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_to_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mfreq_nt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_frequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mmatrix_nt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfreq_nt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m<ipython-input-2-b2ad2e68375b>\u001b[0m in \u001b[0;36mcalculate_frequence\u001b[0;34m(self, infile)\u001b[0m\n\u001b[1;32m    110\u001b[0m                             \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkmer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
        ]
       }
      ],
      "source": "#def main():\n\nprint(\"Read input and settings file.\", end = ' ')\n\ninfile = '../../B.csv'   \nsetfile = 'Input/settings.csv'\noutpath = 'Output/'\n\nsettings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\nupload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\nupload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\nsegments = settings.index.values.tolist()\nclusters = co.defaultdict(list)\nexec_time = 0\nincrement = 0\n\nprint(\"Finished.\")\n\nfor segment in segments:\n\n    print(f\"Starting calculations for segment {segment}:\")\n\n    start_clust = time.perf_counter()\n    parameter = settings.loc[segment].to_list()\n    subset = upload.query('segment == @segment').reset_index()\n\n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n\n    print(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n    print(\"- Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\"- Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters[segment]['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n\n    for i in range(num):\n\n        query = clusters[segment].query('cluster == @i')\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n\n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n    new_clust = clusters[segment].query('cluster != -1')['cluster'] + increment\n\n    clusters[segment].update(centroids)\n    clusters[segment].update(new_clust.astype(int))\n    increment += num - 1\n\n    print(\"Finished.\")\n\n    stop_clust = time.perf_counter()\n    exec_clust = stop_clust - start_clust\n    exec_time = exec_time + exec_clust\n\n    print(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n    print(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n    print(\"Finished.\")\n\nresult = pd.concat(clusters)\nresult.index.set_names([\"segment\", \"accession\"], inplace=True)\nresult.reset_index(level = \"segment\", inplace=True)  \nresult.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\nresult.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\nprint(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-18T16:03:09.932Z"
     },
     {
      "end_time": "2021-01-18T16:17:13.992Z",
      "execution_time": "3m 38s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 151.69 seconds.\n- 10381 sequences, 13 unclustered, 232 cluster.\n- Mean of inner cluster distance mean 0.0001164629\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 2:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. "
       },
       {
        "ename": "KeyboardInterrupt",
        "evalue": "",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-150-c015a141ea6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     ).fit_transform(matrix_nt)\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmatrix_nt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/umap_.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   2012\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m         \"\"\"\n\u001b[0;32m-> 2014\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2015\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/umap_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m                 \u001b[0muse_pynndescent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1801\u001b[0;31m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1802\u001b[0m             )\n\u001b[1;32m   1803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/umap_.py\u001b[0m in \u001b[0;36mnearest_neighbors\u001b[0;34m(X, n_neighbors, metric, metric_kwds, angular, random_state, low_memory, use_pynndescent, verbose)\u001b[0m\n\u001b[1;32m    395\u001b[0m                     \u001b[0mleaf_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleaf_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m                     \u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m                 )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
        ]
       }
      ],
      "source": "#def main():\n\nprint(\"Read input and settings file.\", end = ' ')\n\ninfile = '../../B.csv'   \nsetfile = 'Input/settings.csv'\noutpath = 'Output/'\n\nsettings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\nupload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\nupload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\nsegments = settings.index.values.tolist()\nclusters = co.defaultdict(list)\nexec_time = 0\nincrement = 0\n\nprint(\"Finished.\")\n\nfor segment in segments:\n\n    print(f\"Starting calculations for segment {segment}:\")\n\n    start_clust = time.perf_counter()\n    parameter = settings.loc[segment].to_list()\n    subset = upload.query('segment == @segment').reset_index()\n\n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n\n    print(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n    print(\"- Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\"- Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n    clusters[segment]['cluster'] = clusters[segment]['cluster'].astype(int)\n\n    num = clusters[segment]['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n\n    for i in range(num):\n\n        query = clusters[segment].query('cluster == @i')\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n\n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n    new_clust = clusters[segment].query('cluster != -1')['cluster'] + increment\n\n    clusters[segment].update(centroids)\n    clusters[segment].update(new_clust)\n    increment += num - 1\n\n    print(\"Finished.\")\n\n    stop_clust = time.perf_counter()\n    exec_clust = stop_clust - start_clust\n    exec_time = exec_time + exec_clust\n\n    print(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n    print(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n    print(\"Finished.\")\n\nresult = pd.concat(clusters)\nresult.index.set_names([\"segment\", \"accession\"], inplace=True)\nresult.reset_index(level = \"segment\", inplace=True)  \nresult.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\nresult.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\nprint(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-18T16:13:36.489Z"
     },
     {
      "end_time": "2021-01-18T16:18:11.439Z",
      "execution_time": "56ms",
      "outputs": [
       {
        "ename": "IndentationError",
        "evalue": "unexpected indent (<ipython-input-153-e6a068b364f1>, line 22)",
        "output_type": "error",
        "traceback": [
         "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-153-e6a068b364f1>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    print(f\"Starting calculations for segment {segment}:\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
        ]
       }
      ],
      "source": "#def main():\n\nprint(\"Read input and settings file.\", end = ' ')\n\ninfile = '../../B.csv'   \nsetfile = 'Input/settings.csv'\noutpath = 'Output/'\n\nsettings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\nupload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\nupload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\nsegments = settings.index.values.tolist()\nclusters = co.defaultdict(list)\nexec_time = 0\nincrement = 0\n\nprint(\"Finished.\")\n\n#for segment in segments:\nsegment = 1\n\n    print(f\"Starting calculations for segment {segment}:\")\n\n    start_clust = time.perf_counter()\n    parameter = settings.loc[segment].to_list()\n    subset = upload.query('segment == @segment').reset_index()\n\n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n\n    print(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\n    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print(\"Finished.\")\n\n    print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = parameter[1].item(),\n        min_dist = parameter[2].item(),\n        n_components = parameter[3].item(),\n        random_state = parameter[4].item(),\n        metric = parameter[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print(\"Finished.\")\n\n    print(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\n    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print(\"Finished.\")\n\n    print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = parameter[7].item(),\n        min_dist = parameter[8].item(),\n        n_components = parameter[9].item(),\n        random_state = parameter[10].item(),\n        metric = parameter[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print(\"Finished.\")\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n    print(\"- Running HDBscan for clustering.\", end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n        alpha = parameter[15].item(), #don't mess with this\n    ).fit(matrix)\n\n    print(\"Finished.\")\n\n    print(\"- Centroid extraction.\", end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n    clusters[segment]['cluster'] = clusters[segment]['cluster'].astype(int)\n\n    num = clusters[segment]['cluster'].max()+1\n    values = ['true']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n\n    for i in range(num):\n\n        query = clusters[segment].query('cluster == @i')\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = parameter[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n\n        subs.clear()\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n    new_clust = clusters[segment].query('cluster != -1')['cluster'] + increment\n\n    clusters[segment].update(centroids)\n    clusters[segment].update(new_clust)\n    increment += num - 1\n\n    print(\"Finished.\")\n\n    stop_clust = time.perf_counter()\n    exec_clust = stop_clust - start_clust\n    exec_time = exec_time + exec_clust\n\n    print(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\n    diagnostic = co.Counter(clusterlabel)\n    print(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n    print(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n    print(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n    print(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n    print(\"Finished.\")\n\nresult = pd.concat(clusters)\nresult.index.set_names([\"segment\", \"accession\"], inplace=True)\nresult.reset_index(level = \"segment\", inplace=True)  \nresult.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\nresult.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\nprint(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-18T16:18:11.383Z"
     },
     {
      "end_time": "2021-01-18T16:21:01.844Z",
      "execution_time": "2m 35s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 153.77 seconds.\n- 10381 sequences, 11 unclustered, 235 cluster.\n- Mean of inner cluster distance mean 0.0001484015\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nOverall execution time 153.77 seconds.\n"
       }
      ],
      "source": "#def main():\n\nprint(\"Read input and settings file.\", end = ' ')\n\ninfile = '../../B.csv'   \nsetfile = 'Input/settings.csv'\noutpath = 'Output/'\n\nsettings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\nupload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\nupload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\nsegments = settings.index.values.tolist()\nclusters = co.defaultdict(list)\nexec_time = 0\nincrement = 0\n\nprint(\"Finished.\")\n\n#for segment in segments:\nsegment = 1\n\nprint(f\"Starting calculations for segment {segment}:\")\n\nstart_clust = time.perf_counter()\nparameter = settings.loc[segment].to_list()\nsubset = upload.query('segment == @segment').reset_index()\n\nsequence = subset[['genome']].copy()\naccession = subset[['accession']].copy()\nsubtype = subset[['subtype']].copy()\n\nprint(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\nfreq_nt = vectorizer(k = parameter[0].item(), convert = 0)\nfreq_nt.adjust_to_data(sequence)\nfreq_nt.calculate_frequence(sequence)\n\nmatrix_nt = freq_nt.get_matrix()\nkeys_nt = freq_nt.get_keys()\n\ndel freq_nt\n\nprint(\"Finished.\")\n\nprint(\"- Running UMAP for dimension reduction.\", end = ' ')\n\nmatrix_nt_red = umap.UMAP(\n    n_neighbors = parameter[1].item(),\n    min_dist = parameter[2].item(),\n    n_components = parameter[3].item(),\n    random_state = parameter[4].item(),\n    metric = parameter[5],\n).fit_transform(matrix_nt)\n\ndel matrix_nt\n\nprint(\"Finished.\")\n\nprint(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\nfreq_aa = vectorizer(k = parameter[6].item(), convert = 1)\nfreq_aa.adjust_to_data(sequence)\nfreq_aa.calculate_frequence(sequence)\n\nmatrix_aa = freq_aa.get_matrix()\nkeys_aa = freq_aa.get_keys()\n\ndel freq_aa\n\nprint(\"Finished.\")\n\nprint(\"- Running UMAP for dimension reduction.\", end = ' ')\n\nmatrix_aa_red = umap.UMAP(\n    n_neighbors = parameter[7].item(),\n    min_dist = parameter[8].item(),\n    n_components = parameter[9].item(),\n    random_state = parameter[10].item(),\n    metric = parameter[11],\n).fit_transform(matrix_aa)\n\ndel matrix_aa\n\nprint(\"Finished.\")\n\nmatrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\nprint(\"- Running HDBscan for clustering.\", end = ' ')\n\nmatrix_clust = hdbscan.HDBSCAN(\n    min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n    min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n    cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n    alpha = parameter[15].item(), #don't mess with this\n).fit(matrix)\n\nprint(\"Finished.\")\n\nprint(\"- Centroid extraction.\", end = ' ')\n\nclusterlabel = matrix_clust.labels_\n\nblank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\nclusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\nclusters[segment]['cluster'] = clusters[segment]['cluster'].astype(int)\n\nnum = clusters[segment]['cluster'].max()+1\nvalues = ['true']*num\naccessions = []\nexclude = []\ninclude = []\noverall_mean=0\nsubs = co.defaultdict(list)\n\nfor i in range(num):\n\n    query = clusters[segment].query('cluster == @i')\n    match = query.index.values.tolist()\n    sub = matrix.filter(items = match, axis=0)\n    dist = ssd.cdist(sub, sub, metric = parameter[16])\n    inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n    accessions.append(inner_mean.idxmin())\n    overall_mean = overall_mean + inner_mean.mean()\n\n    for sub in query['subtype'].tolist():\n        if re.match('^[H][0-9]+N[0-9]+$', sub): \n            subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n            subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n        else:\n            subs['X'].append('X0')\n            subs['X'].append('X0')\n\n    if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n        exclude.append(2)\n        if 'X' not in subs.keys():\n            include.append(2)\n    elif len(set(subs['H'])) == 1:\n        exclude.append(1)\n        if 'X' not in subs.keys():\n            include.append(1)\n    elif len(set(subs['N'])) == 1:\n        exclude.append(0)\n        if 'X' not in subs.keys():\n            include.append(0)\n\n    subs.clear()\n\ncentroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\nnew_clust = clusters[segment].query('cluster != -1')['cluster'] + increment\n\nclusters[segment].update(centroids)\nclusters[segment].update(new_clust)\nincrement += num - 1\n\nprint(\"Finished.\")\n\nstop_clust = time.perf_counter()\nexec_clust = stop_clust - start_clust\nexec_time = exec_time + exec_clust\n\nprint(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\ndiagnostic = co.Counter(clusterlabel)\nprint(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\nprint(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\nprint(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\nprint(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\nprint(\"Finished.\")\n\nresult = pd.concat(clusters)\nresult.index.set_names([\"segment\", \"accession\"], inplace=True)\nresult.reset_index(level = \"segment\", inplace=True)  \nresult.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\nresult.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\nprint(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-18T16:18:27.111Z"
     },
     {
      "end_time": "2021-01-18T16:30:56.813Z",
      "execution_time": "2m 33s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. "
       },
       {
        "ename": "NameError",
        "evalue": "name 'clusers' is not defined",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-175-cc69eb22596b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0mblank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusterlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'false'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusterlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'centroid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccession\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accession'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mNameError\u001b[0m: name 'clusers' is not defined"
        ]
       }
      ],
      "source": "#def main():\n\nprint(\"Read input and settings file.\", end = ' ')\n\ninfile = '../../B.csv'   \nsetfile = 'Input/settings.csv'\noutpath = 'Output/'\n\nsettings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\nupload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\nupload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\nsegments = settings.index.values.tolist()\nclusters = co.defaultdict(list)\nexec_time = 0\nincrement = 0\n\nprint(\"Finished.\")\n\n#for segment in segments:\nsegment = 1\n\nprint(f\"Starting calculations for segment {segment}:\")\n\nstart_clust = time.perf_counter()\nparameter = settings.loc[segment].to_list()\nsubset = upload.query('segment == @segment').reset_index()\n\nsequence = subset[['genome']].copy()\naccession = subset[['accession']].copy()\nsubtype = subset[['subtype']].copy()\n\nprint(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\nfreq_nt = vectorizer(k = parameter[0].item(), convert = 0)\nfreq_nt.adjust_to_data(sequence)\nfreq_nt.calculate_frequence(sequence)\n\nmatrix_nt = freq_nt.get_matrix()\nkeys_nt = freq_nt.get_keys()\n\ndel freq_nt\n\nprint(\"Finished.\")\n\nprint(\"- Running UMAP for dimension reduction.\", end = ' ')\n\nmatrix_nt_red = umap.UMAP(\n    n_neighbors = parameter[1].item(),\n    min_dist = parameter[2].item(),\n    n_components = parameter[3].item(),\n    random_state = parameter[4].item(),\n    metric = parameter[5],\n).fit_transform(matrix_nt)\n\ndel matrix_nt\n\nprint(\"Finished.\")\n\nprint(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\nfreq_aa = vectorizer(k = parameter[6].item(), convert = 1)\nfreq_aa.adjust_to_data(sequence)\nfreq_aa.calculate_frequence(sequence)\n\nmatrix_aa = freq_aa.get_matrix()\nkeys_aa = freq_aa.get_keys()\n\ndel freq_aa\n\nprint(\"Finished.\")\n\nprint(\"- Running UMAP for dimension reduction.\", end = ' ')\n\nmatrix_aa_red = umap.UMAP(\n    n_neighbors = parameter[7].item(),\n    min_dist = parameter[8].item(),\n    n_components = parameter[9].item(),\n    random_state = parameter[10].item(),\n    metric = parameter[11],\n).fit_transform(matrix_aa)\n\ndel matrix_aa\n\nprint(\"Finished.\")\n\nmatrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\nprint(\"- Running HDBscan for clustering.\", end = ' ')\n\nmatrix_clust = hdbscan.HDBSCAN(\n    min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n    min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n    cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n    alpha = parameter[15].item(), #don't mess with this\n).fit(matrix)\n\nprint(\"Finished.\")\n\nprint(\"- Centroid extraction.\", end = ' ')\n\nclusterlabel = matrix_clust.labels_\n\nblank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\nclusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\nprint(clusers[segment])\n\nnum = clusters[segment]['cluster'].max()+1\nvalues = ['true']*num\naccessions = []\nexclude = []\ninclude = []\noverall_mean=0\nsubs = co.defaultdict(list)\n\nfor i in range(num):\n\n    query = clusters[segment].query('cluster == @i')\n    match = query.index.values.tolist()\n    sub = matrix.filter(items = match, axis=0)\n    dist = ssd.cdist(sub, sub, metric = parameter[16])\n    inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n    accessions.append(inner_mean.idxmin())\n    overall_mean = overall_mean + inner_mean.mean()\n\n    for sub in query['subtype'].tolist():\n        if re.match('^[H][0-9]+N[0-9]+$', sub): \n            subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n            subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n        else:\n            subs['X'].append('X0')\n            subs['X'].append('X0')\n\n    if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n        exclude.append(2)\n        if 'X' not in subs.keys():\n            include.append(2)\n    elif len(set(subs['H'])) == 1:\n        exclude.append(1)\n        if 'X' not in subs.keys():\n            include.append(1)\n    elif len(set(subs['N'])) == 1:\n        exclude.append(0)\n        if 'X' not in subs.keys():\n            include.append(0)\n\n    subs.clear()\n\nprint(clusers[segment])\n    \ncentroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\nnew_clust = pd.DataFrame(clusters[segment].query('cluster != -1')['cluster'] + increment)\n\nprint(clusers[segment])\n\nclusters[segment].update(centroids)\nclusters[segment].update(new_clust)\nincrement += num - 1\n\nprint(\"Finished.\")\n\nstop_clust = time.perf_counter()\nexec_clust = stop_clust - start_clust\nexec_time = exec_time + exec_clust\n\nprint(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\ndiagnostic = co.Counter(clusterlabel)\nprint(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\nprint(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\nprint(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\nprint(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\nprint(\"Finished.\")\n\nresult = pd.concat(clusters)\nresult.index.set_names([\"segment\", \"accession\"], inplace=True)\nresult.reset_index(level = \"segment\", inplace=True)  \nresult.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\nresult.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\nprint(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-18T16:28:23.536Z"
     },
     {
      "end_time": "2021-01-18T16:34:45.593Z",
      "execution_time": "2m 37s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction.            cluster centroid subtype\naccession                          \nLC033391       216    false      NA\nKT854634        58    false      NA\nKX615827        65    false      NA\nCY218618       217    false      NA\nMN637988        89    false      NA\n...            ...      ...     ...\nCY018763       214    false      NA\nCY018659       207    false      NA\nCY018843       206    false      NA\nCY018771       206    false      NA\nCY019537       206    false      NA\n\n[10381 rows x 3 columns]\n           cluster centroid subtype\naccession                          \nLC033391       216    false      NA\nKT854634        58    false      NA\nKX615827        65    false      NA\nCY218618       217    false      NA\nMN637988        89    false      NA\n...            ...      ...     ...\nCY018763       214    false      NA\nCY018659       207    false      NA\nCY018843       206    false      NA\nCY018771       206    false      NA\nCY019537       206    false      NA\n\n[10381 rows x 3 columns]\n           cluster centroid subtype\naccession                          \nLC033391       216    false      NA\nKT854634        58    false      NA\nKX615827        65    false      NA\nCY218618       217    false      NA\nMN637988        89    false      NA\n...            ...      ...     ...\nCY018763       214    false      NA\nCY018659       207    false      NA\nCY018843       206    false      NA\nCY018771       206    false      NA\nCY019537       206    false      NA\n\n[10381 rows x 3 columns]\n           cluster centroid subtype\naccession                          \nLC033391     216.0    false      NA\nKT854634      58.0    false      NA\nKX615827      65.0    false      NA\nCY218618     217.0    false      NA\nMN637988      89.0    false      NA\n...            ...      ...     ...\nCY018763     214.0    false      NA\nCY018659     207.0    false      NA\nCY018843     206.0    false      NA\nCY018771     206.0    false      NA\nCY019537     206.0    false      NA\n\n[10381 rows x 3 columns]\nFinished.\n- Clustering done in 156.00 seconds.\n- 10381 sequences, 13 unclustered, 232 cluster.\n- Mean of inner cluster distance mean 0.0001164629\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nOverall execution time 156.00 seconds.\n"
       }
      ],
      "source": "#def main():\n\nprint(\"Read input and settings file.\", end = ' ')\n\ninfile = '../../B.csv'   \nsetfile = 'Input/settings.csv'\noutpath = 'Output/'\n\nsettings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\nupload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\nupload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\nsegments = settings.index.values.tolist()\nclusters = co.defaultdict(list)\nexec_time = 0\nincrement = 0\n\nprint(\"Finished.\")\n\n#for segment in segments:\nsegment = 1\n\nprint(f\"Starting calculations for segment {segment}:\")\n\nstart_clust = time.perf_counter()\nparameter = settings.loc[segment].to_list()\nsubset = upload.query('segment == @segment').reset_index()\n\nsequence = subset[['genome']].copy()\naccession = subset[['accession']].copy()\nsubtype = subset[['subtype']].copy()\n\nprint(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\nfreq_nt = vectorizer(k = parameter[0].item(), convert = 0)\nfreq_nt.adjust_to_data(sequence)\nfreq_nt.calculate_frequence(sequence)\n\nmatrix_nt = freq_nt.get_matrix()\nkeys_nt = freq_nt.get_keys()\n\ndel freq_nt\n\nprint(\"Finished.\")\n\nprint(\"- Running UMAP for dimension reduction.\", end = ' ')\n\nmatrix_nt_red = umap.UMAP(\n    n_neighbors = parameter[1].item(),\n    min_dist = parameter[2].item(),\n    n_components = parameter[3].item(),\n    random_state = parameter[4].item(),\n    metric = parameter[5],\n).fit_transform(matrix_nt)\n\ndel matrix_nt\n\nprint(\"Finished.\")\n\nprint(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\nfreq_aa = vectorizer(k = parameter[6].item(), convert = 1)\nfreq_aa.adjust_to_data(sequence)\nfreq_aa.calculate_frequence(sequence)\n\nmatrix_aa = freq_aa.get_matrix()\nkeys_aa = freq_aa.get_keys()\n\ndel freq_aa\n\nprint(\"Finished.\")\n\nprint(\"- Running UMAP for dimension reduction.\", end = ' ')\n\nmatrix_aa_red = umap.UMAP(\n    n_neighbors = parameter[7].item(),\n    min_dist = parameter[8].item(),\n    n_components = parameter[9].item(),\n    random_state = parameter[10].item(),\n    metric = parameter[11],\n).fit_transform(matrix_aa)\n\ndel matrix_aa\n\nprint(\"Finished.\")\n\nmatrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\nprint(\"- Running HDBscan for clustering.\", end = ' ')\n\nmatrix_clust = hdbscan.HDBSCAN(\n    min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n    min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n    cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n    alpha = parameter[15].item(), #don't mess with this\n).fit(matrix)\n\nprint(\"Finished.\")\n\nprint(\"- Centroid extraction.\", end = ' ')\n\nclusterlabel = matrix_clust.labels_\n\nblank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\nclusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\nprint(clusters[segment])\n\nnum = clusters[segment]['cluster'].max()+1\nvalues = ['true']*num\naccessions = []\nexclude = []\ninclude = []\noverall_mean=0\nsubs = co.defaultdict(list)\n\nfor i in range(num):\n\n    query = clusters[segment].query('cluster == @i')\n    match = query.index.values.tolist()\n    sub = matrix.filter(items = match, axis=0)\n    dist = ssd.cdist(sub, sub, metric = parameter[16])\n    inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n    accessions.append(inner_mean.idxmin())\n    overall_mean = overall_mean + inner_mean.mean()\n\n    for sub in query['subtype'].tolist():\n        if re.match('^[H][0-9]+N[0-9]+$', sub): \n            subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n            subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n        else:\n            subs['X'].append('X0')\n            subs['X'].append('X0')\n\n    if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n        exclude.append(2)\n        if 'X' not in subs.keys():\n            include.append(2)\n    elif len(set(subs['H'])) == 1:\n        exclude.append(1)\n        if 'X' not in subs.keys():\n            include.append(1)\n    elif len(set(subs['N'])) == 1:\n        exclude.append(0)\n        if 'X' not in subs.keys():\n            include.append(0)\n\n    subs.clear()\n\nprint(clusters[segment])\n    \ncentroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\nnew_clust = pd.DataFrame(clusters[segment].query('cluster != -1')['cluster'] + increment).astype(int)\n\nprint(clusters[segment])\n\nclusters[segment].update(centroids)\nclusters[segment].update(new_clust)\nincrement += num - 1\n\nprint(clusters[segment])\n\nprint(\"Finished.\")\n\nstop_clust = time.perf_counter()\nexec_clust = stop_clust - start_clust\nexec_time = exec_time + exec_clust\n\nprint(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\ndiagnostic = co.Counter(clusterlabel)\nprint(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\nprint(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\nprint(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\nprint(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\nprint(\"Finished.\")\n\nresult = pd.concat(clusters)\nresult.index.set_names([\"segment\", \"accession\"], inplace=True)\nresult.reset_index(level = \"segment\", inplace=True)  \nresult.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\nresult.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\nprint(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-18T16:32:08.552Z"
     },
     {
      "end_time": "2021-01-18T16:52:45.940Z",
      "execution_time": "2m 33s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 152.43 seconds.\n- 10381 sequences, 13 unclustered, 232 cluster.\n- Mean of inner cluster distance mean 0.0001164629\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nOverall execution time 152.43 seconds.\n"
       }
      ],
      "source": "#def main():\n\nprint(\"Read input and settings file.\", end = ' ')\n\ninfile = '../../B.csv'   \nsetfile = 'Input/settings.csv'\noutpath = 'Output/'\n\nsettings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\nupload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\nupload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\nsegments = settings.index.values.tolist()\nclusters = co.defaultdict(list)\nexec_time = 0\nincrement = 0\n\nprint(\"Finished.\")\n\n#for segment in segments:\nsegment = 1\n\nprint(f\"Starting calculations for segment {segment}:\")\n\nstart_clust = time.perf_counter()\nparameter = settings.loc[segment].to_list()\nsubset = upload.query('segment == @segment').reset_index()\n\nsequence = subset[['genome']].copy()\naccession = subset[['accession']].copy()\nsubtype = subset[['subtype']].copy()\n\nprint(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\nfreq_nt = vectorizer(k = parameter[0].item(), convert = 0)\nfreq_nt.adjust_to_data(sequence)\nfreq_nt.calculate_frequence(sequence)\n\nmatrix_nt = freq_nt.get_matrix()\nkeys_nt = freq_nt.get_keys()\n\ndel freq_nt\n\nprint(\"Finished.\")\n\nprint(\"- Running UMAP for dimension reduction.\", end = ' ')\n\nmatrix_nt_red = umap.UMAP(\n    n_neighbors = parameter[1].item(),\n    min_dist = parameter[2].item(),\n    n_components = parameter[3].item(),\n    random_state = parameter[4].item(),\n    metric = parameter[5],\n).fit_transform(matrix_nt)\n\ndel matrix_nt\n\nprint(\"Finished.\")\n\nprint(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\nfreq_aa = vectorizer(k = parameter[6].item(), convert = 1)\nfreq_aa.adjust_to_data(sequence)\nfreq_aa.calculate_frequence(sequence)\n\nmatrix_aa = freq_aa.get_matrix()\nkeys_aa = freq_aa.get_keys()\n\ndel freq_aa\n\nprint(\"Finished.\")\n\nprint(\"- Running UMAP for dimension reduction.\", end = ' ')\n\nmatrix_aa_red = umap.UMAP(\n    n_neighbors = parameter[7].item(),\n    min_dist = parameter[8].item(),\n    n_components = parameter[9].item(),\n    random_state = parameter[10].item(),\n    metric = parameter[11],\n).fit_transform(matrix_aa)\n\ndel matrix_aa\n\nprint(\"Finished.\")\n\nmatrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\nprint(\"- Running HDBscan for clustering.\", end = ' ')\n\nmatrix_clust = hdbscan.HDBSCAN(\n    min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n    min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n    cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n    alpha = parameter[15].item(), #don't mess with this\n).fit(matrix)\n\nprint(\"Finished.\")\n\nprint(\"- Centroid extraction.\", end = ' ')\n\nclusterlabel = matrix_clust.labels_\n\nblank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\nclusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\nnum = clusters[segment]['cluster'].max()+1\nvalues = ['true']*num\naccessions = []\nexclude = []\ninclude = []\noverall_mean=0\nsubs = co.defaultdict(list)\n\nfor i in range(num):\n\n    query = clusters[segment].query('cluster == @i')\n    match = query.index.values.tolist()\n    sub = matrix.filter(items = match, axis=0)\n    dist = ssd.cdist(sub, sub, metric = parameter[16])\n    inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n    accessions.append(inner_mean.idxmin())\n    overall_mean = overall_mean + inner_mean.mean()\n\n    for sub in query['subtype'].tolist():\n        if re.match('^[H][0-9]+N[0-9]+$', sub): \n            subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n            subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n        else:\n            subs['X'].append('X0')\n            subs['X'].append('X0')\n\n    if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n        exclude.append(2)\n        if 'X' not in subs.keys():\n            include.append(2)\n    elif len(set(subs['H'])) == 1:\n        exclude.append(1)\n        if 'X' not in subs.keys():\n            include.append(1)\n    elif len(set(subs['N'])) == 1:\n        exclude.append(0)\n        if 'X' not in subs.keys():\n            include.append(0)\n\n    subs.clear()\n    \ncentroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\nclusters[segment].loc[clusters[segment]['cluster'] == -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] == -1, ['cluster']] + increment\nclusters[segment].update(centroids)\n\nincrement += num - 1\n\nprint(\"Finished.\")\n\nstop_clust = time.perf_counter()\nexec_clust = stop_clust - start_clust\nexec_time = exec_time + exec_clust\n\nprint(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\ndiagnostic = co.Counter(clusterlabel)\nprint(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\nprint(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\nprint(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\nprint(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\nprint(\"Finished.\")\n\nresult = pd.concat(clusters)\nresult.index.set_names([\"segment\", \"accession\"], inplace=True)\nresult.reset_index(level = \"segment\", inplace=True)  \nresult.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\nresult.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\nprint(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-18T16:50:12.530Z"
     },
     {
      "end_time": "2021-01-18T16:55:02.137Z",
      "execution_time": "202ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = '../../B.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    exec_time = 0\n    increment = 0\n\n    print(\"Finished.\")\n\n    for segment in segments:\n\n        print(f\"Starting calculations for segment {segment}:\")\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\n        freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = parameter[1].item(),\n            min_dist = parameter[2].item(),\n            n_components = parameter[3].item(),\n            random_state = parameter[4].item(),\n            metric = parameter[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print(\"Finished.\")\n\n        print(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\n        freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = parameter[7].item(),\n            min_dist = parameter[8].item(),\n            n_components = parameter[9].item(),\n            random_state = parameter[10].item(),\n            metric = parameter[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print(\"Finished.\")\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print(\"- Running HDBscan for clustering.\", end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n            cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n            alpha = parameter[15].item(), #don't mess with this\n        ).fit(matrix)\n\n        print(\"Finished.\")\n\n        print(\"- Centroid extraction.\", end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['true']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = parameter[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] == -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] == -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print(\"Finished.\")\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\n        diagnostic = co.Counter(clusterlabel)\n        print(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n        print(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n        print(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n        print(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n        print(\"Finished.\")\n\n    result = pd.concat(clusters)\n    result.index.set_names([\"segment\", \"accession\"], inplace=True)\n    result.reset_index(level = \"segment\", inplace=True)  \n    result.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n    print(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-18T16:55:01.935Z"
     },
     {
      "end_time": "2021-01-18T17:20:49.622Z",
      "execution_time": "2m 32s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 151.31 seconds.\n- 10381 sequences, 13 unclustered, 232 cluster.\n- Mean of inner cluster distance mean 0.0001164629\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nOverall execution time 151.31 seconds.\n"
       }
      ],
      "source": "#def main():\n\nprint(\"Read input and settings file.\", end = ' ')\n\ninfile = '../../B.csv'   \nsetfile = 'Input/settings.csv'\noutpath = 'Output/'\n\nsettings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\nupload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\nupload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\nsegments = settings.index.values.tolist()\nclusters = co.defaultdict(list)\nexec_time = 0\nincrement = 100\n\nprint(\"Finished.\")\n\n#for segment in segments:\nsegment = 1\n\nprint(f\"Starting calculations for segment {segment}:\")\n\nstart_clust = time.perf_counter()\nparameter = settings.loc[segment].to_list()\nsubset = upload.query('segment == @segment').reset_index()\n\nsequence = subset[['genome']].copy()\naccession = subset[['accession']].copy()\nsubtype = subset[['subtype']].copy()\n\nprint(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\nfreq_nt = vectorizer(k = parameter[0].item(), convert = 0)\nfreq_nt.adjust_to_data(sequence)\nfreq_nt.calculate_frequence(sequence)\n\nmatrix_nt = freq_nt.get_matrix()\nkeys_nt = freq_nt.get_keys()\n\ndel freq_nt\n\nprint(\"Finished.\")\n\nprint(\"- Running UMAP for dimension reduction.\", end = ' ')\n\nmatrix_nt_red = umap.UMAP(\n    n_neighbors = parameter[1].item(),\n    min_dist = parameter[2].item(),\n    n_components = parameter[3].item(),\n    random_state = parameter[4].item(),\n    metric = parameter[5],\n).fit_transform(matrix_nt)\n\ndel matrix_nt\n\nprint(\"Finished.\")\n\nprint(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\nfreq_aa = vectorizer(k = parameter[6].item(), convert = 1)\nfreq_aa.adjust_to_data(sequence)\nfreq_aa.calculate_frequence(sequence)\n\nmatrix_aa = freq_aa.get_matrix()\nkeys_aa = freq_aa.get_keys()\n\ndel freq_aa\n\nprint(\"Finished.\")\n\nprint(\"- Running UMAP for dimension reduction.\", end = ' ')\n\nmatrix_aa_red = umap.UMAP(\n    n_neighbors = parameter[7].item(),\n    min_dist = parameter[8].item(),\n    n_components = parameter[9].item(),\n    random_state = parameter[10].item(),\n    metric = parameter[11],\n).fit_transform(matrix_aa)\n\ndel matrix_aa\n\nprint(\"Finished.\")\n\nmatrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\nprint(\"- Running HDBscan for clustering.\", end = ' ')\n\nmatrix_clust = hdbscan.HDBSCAN(\n    min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n    min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n    cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n    alpha = parameter[15].item(), #don't mess with this\n).fit(matrix)\n\nprint(\"Finished.\")\n\nprint(\"- Centroid extraction.\", end = ' ')\n\nclusterlabel = matrix_clust.labels_\n\nblank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\nclusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\nnum = clusters[segment]['cluster'].max()+1\nvalues = ['true']*num\naccessions = []\nexclude = []\ninclude = []\noverall_mean=0\nsubs = co.defaultdict(list)\n\nfor i in range(num):\n\n    query = clusters[segment].query('cluster == @i')\n    match = query.index.values.tolist()\n    sub = matrix.filter(items = match, axis=0)\n    dist = ssd.cdist(sub, sub, metric = parameter[16])\n    inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n    accessions.append(inner_mean.idxmin())\n    overall_mean = overall_mean + inner_mean.mean()\n\n    for sub in query['subtype'].tolist():\n        if re.match('^[H][0-9]+N[0-9]+$', sub): \n            subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n            subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n        else:\n            subs['X'].append('X0')\n            subs['X'].append('X0')\n\n    if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n        exclude.append(2)\n        if 'X' not in subs.keys():\n            include.append(2)\n    elif len(set(subs['H'])) == 1:\n        exclude.append(1)\n        if 'X' not in subs.keys():\n            include.append(1)\n    elif len(set(subs['N'])) == 1:\n        exclude.append(0)\n        if 'X' not in subs.keys():\n            include.append(0)\n\n    subs.clear()\n\ncentroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\nclusters[segment].loc[clusters[segment]['cluster'] == -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] == -1, ['cluster']] + increment\nclusters[segment].update(centroids)\n\nincrement += num - 1\n\nprint(\"Finished.\")\n\nstop_clust = time.perf_counter()\nexec_clust = stop_clust - start_clust\nexec_time = exec_time + exec_clust\n\nprint(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\ndiagnostic = co.Counter(clusterlabel)\nprint(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\nprint(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\nprint(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\nprint(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\nprint(\"Finished.\")\n\nresult = pd.concat(clusters)\nresult.index.set_names([\"segment\", \"accession\"], inplace=True)\nresult.reset_index(level = \"segment\", inplace=True)  \nresult.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\nresult.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\nprint(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-18T17:18:17.348Z"
     },
     {
      "end_time": "2021-01-18T17:25:44.802Z",
      "execution_time": "204ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = '../../B.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    exec_time = 0\n    increment = 100\n\n    print(\"Finished.\")\n\n    for segment in segments:\n    \n        print(f\"Starting calculations for segment {segment}:\")\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\n        freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = parameter[1].item(),\n            min_dist = parameter[2].item(),\n            n_components = parameter[3].item(),\n            random_state = parameter[4].item(),\n            metric = parameter[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print(\"Finished.\")\n\n        print(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\n        freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = parameter[7].item(),\n            min_dist = parameter[8].item(),\n            n_components = parameter[9].item(),\n            random_state = parameter[10].item(),\n            metric = parameter[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print(\"Finished.\")\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print(\"- Running HDBscan for clustering.\", end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n            cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n            alpha = parameter[15].item(), #don't mess with this\n        ).fit(matrix)\n\n        print(\"Finished.\")\n\n        print(\"- Centroid extraction.\", end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['true']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = parameter[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print(\"Finished.\")\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\n        diagnostic = co.Counter(clusterlabel)\n        print(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n        print(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n        print(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n        print(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n        print(\"Finished.\")\n\n    result = pd.concat(clusters)\n    result.index.set_names([\"segment\", \"accession\"], inplace=True)\n    result.reset_index(level = \"segment\", inplace=True)  \n    result.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n    print(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-18T17:25:44.598Z"
     },
     {
      "end_time": "2021-01-18T17:28:06.098Z",
      "execution_time": "204ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = '../../B.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    exec_time = 0\n    increment = 0\n\n    print(\"Finished.\")\n\n    for segment in segments:\n    \n        print(f\"Starting calculations for segment {segment}:\")\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\n        freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = parameter[1].item(),\n            min_dist = parameter[2].item(),\n            n_components = parameter[3].item(),\n            random_state = parameter[4].item(),\n            metric = parameter[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print(\"Finished.\")\n\n        print(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\n        freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = parameter[7].item(),\n            min_dist = parameter[8].item(),\n            n_components = parameter[9].item(),\n            random_state = parameter[10].item(),\n            metric = parameter[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print(\"Finished.\")\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print(\"- Running HDBscan for clustering.\", end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n            cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n            alpha = parameter[15].item(), #don't mess with this\n        ).fit(matrix)\n\n        print(\"Finished.\")\n\n        print(\"- Centroid extraction.\", end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['true']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = parameter[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print(\"Finished.\")\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\n        diagnostic = co.Counter(clusterlabel)\n        print(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n        print(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n        print(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n        print(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n        print(\"Finished.\")\n\n    result = pd.concat(clusters)\n    result.index.set_names([\"segment\", \"accession\"], inplace=True)\n    result.reset_index(level = \"segment\", inplace=True)  \n    result.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n    print(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-18T17:28:05.894Z"
     },
     {
      "end_time": "2021-01-18T17:49:35.324Z",
      "execution_time": "203ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = '../../A.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    exec_time = 0\n    increment = 0\n\n    print(\"Finished.\")\n\n    for segment in segments:\n    \n        print(f\"Starting calculations for segment {segment}:\")\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\n        freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = parameter[1].item(),\n            min_dist = parameter[2].item(),\n            n_components = parameter[3].item(),\n            random_state = parameter[4].item(),\n            metric = parameter[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print(\"Finished.\")\n\n        print(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\n        freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = parameter[7].item(),\n            min_dist = parameter[8].item(),\n            n_components = parameter[9].item(),\n            random_state = parameter[10].item(),\n            metric = parameter[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print(\"Finished.\")\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print(\"- Running HDBscan for clustering.\", end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n            cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n            alpha = parameter[15].item(), #don't mess with this\n        ).fit(matrix)\n\n        print(\"Finished.\")\n\n        print(\"- Centroid extraction.\", end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['true']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = parameter[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print(\"Finished.\")\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\n        diagnostic = co.Counter(clusterlabel)\n        print(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n        print(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n        print(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n        print(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n        print(\"Finished.\")\n\n    result = pd.concat(clusters)\n    result.index.set_names([\"segment\", \"accession\"], inplace=True)\n    result.reset_index(level = \"segment\", inplace=True)  \n    result.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',')\n    print(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-18T17:49:35.121Z"
     },
     {
      "end_time": "2021-01-19T13:16:24.825Z",
      "execution_time": "215ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = '../../A.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    upload.query('curation == \"Pass\"', inplace = True)\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    exec_time = 0\n    increment = 0\n\n    print(\"Finished.\")\n\n    segments = [1]\n    for segment in segments:\n    \n        print(f\"Starting calculations for segment {segment}:\")\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\n        freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = parameter[1].item(),\n            min_dist = parameter[2].item(),\n            n_components = parameter[3].item(),\n            random_state = parameter[4].item(),\n            metric = parameter[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print(\"Finished.\")\n\n        print(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\n        freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = parameter[7].item(),\n            min_dist = parameter[8].item(),\n            n_components = parameter[9].item(),\n            random_state = parameter[10].item(),\n            metric = parameter[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print(\"Finished.\")\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print(\"- Running HDBscan for clustering.\", end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n            cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n            alpha = parameter[15].item(), #don't mess with this\n        ).fit(matrix)\n\n        print(\"Finished.\")\n\n        print(\"- Centroid extraction.\", end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['true']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = parameter[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print(\"Finished.\")\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\n        diagnostic = co.Counter(clusterlabel)\n        print(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n        print(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n        print(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n        print(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n        print(\"Finished.\")\n\n    result = pd.concat(clusters)\n    result.index.set_names([\"segment\", \"accession\"], inplace=True)\n    result.reset_index(level = \"segment\", inplace=True)  \n    result.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',', mode='w')\n    print(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-19T13:16:24.610Z"
     },
     {
      "end_time": "2021-01-19T15:05:19.357Z",
      "execution_time": "213ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = '../../B.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    upload.query('curation == \"Pass\"', inplace = True)\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    exec_time = 0\n    increment = 0\n\n    print(\"Finished.\")\n\n    #segments = [1]\n    for segment in segments:\n    \n        print(f\"Starting calculations for segment {segment}:\")\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\n        freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = parameter[1].item(),\n            min_dist = parameter[2].item(),\n            n_components = parameter[3].item(),\n            random_state = parameter[4].item(),\n            metric = parameter[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print(\"Finished.\")\n\n        print(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\n        freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = parameter[7].item(),\n            min_dist = parameter[8].item(),\n            n_components = parameter[9].item(),\n            random_state = parameter[10].item(),\n            metric = parameter[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print(\"Finished.\")\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print(\"- Running HDBscan for clustering.\", end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n            cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n            alpha = parameter[15].item(), #don't mess with this\n        ).fit(matrix)\n\n        print(\"Finished.\")\n\n        print(\"- Centroid extraction.\", end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['False'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['True']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = parameter[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print(\"Finished.\")\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\n        diagnostic = co.Counter(clusterlabel)\n        print(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n        print(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n        print(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n        print(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n        print(\"Finished.\")\n\n    result = pd.concat(clusters)\n    result.index.set_names([\"segment\", \"accession\"], inplace=True)\n    result.reset_index(level = \"segment\", inplace=True)  \n    result.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',', mode='w')\n    print(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-19T15:05:19.144Z"
     },
     {
      "end_time": "2021-01-19T15:14:22.080Z",
      "execution_time": "219ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = '../../B.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    upload.query('curation == \"Pass\"', inplace = True)\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    exec_time = 0\n    increment = 0\n\n    print(\"Finished.\")\n\n    #segments = [1]\n    for segment in segments:\n    \n        print(f\"Starting calculations for segment {segment}:\")\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\n        freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = parameter[1].item(),\n            min_dist = parameter[2].item(),\n            n_components = parameter[3].item(),\n            random_state = parameter[4].item(),\n            metric = parameter[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print(\"Finished.\")\n\n        print(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\n        freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = parameter[7].item(),\n            min_dist = parameter[8].item(),\n            n_components = parameter[9].item(),\n            random_state = parameter[10].item(),\n            metric = parameter[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print(\"Finished.\")\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print(\"- Running HDBscan for clustering.\", end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n            cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n            alpha = parameter[15].item(), #don't mess with this\n        ).fit(matrix)\n\n        print(\"Finished.\")\n\n        print(\"- Centroid extraction.\", end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['False'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['True']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = parameter[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print(\"Finished.\")\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\n        diagnostic = co.Counter(clusterlabel)\n        print(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n        print(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n        print(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n        print(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n        print(\"Finished.\")\n\n    result = pd.concat(clusters)\n    result.index.set_names([\"segment\", \"accession\"], inplace=True)\n    result.reset_index(level = \"segment\", inplace=True)  \n    result.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',', mode='w')\n    print(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-19T15:14:21.861Z"
     },
     {
      "end_time": "2021-01-19T16:29:10.726Z",
      "execution_time": "212ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = '../../A.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    upload.query('curation == \"Pass\"', inplace = True)\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    exec_time = 0\n    increment = 0\n\n    print(\"Finished.\")\n\n    segments = [6]\n    for segment in segments:\n    \n        print(f\"Starting calculations for segment {segment}:\")\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\n        freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = parameter[1].item(),\n            min_dist = parameter[2].item(),\n            n_components = parameter[3].item(),\n            random_state = parameter[4].item(),\n            metric = parameter[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print(\"Finished.\")\n\n        print(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\n        freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = parameter[7].item(),\n            min_dist = parameter[8].item(),\n            n_components = parameter[9].item(),\n            random_state = parameter[10].item(),\n            metric = parameter[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print(\"Finished.\")\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print(\"- Running HDBscan for clustering.\", end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n            cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n            alpha = parameter[15].item(), #don't mess with this\n        ).fit(matrix)\n\n        print(\"Finished.\")\n\n        print(\"- Centroid extraction.\", end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['False'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['True']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = parameter[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print(\"Finished.\")\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\n        diagnostic = co.Counter(clusterlabel)\n        print(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n        print(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n        print(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n        print(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n        print(\"Finished.\")\n\n    result = pd.concat(clusters)\n    result.index.set_names([\"segment\", \"accession\"], inplace=True)\n    result.reset_index(level = \"segment\", inplace=True)  \n    result.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',', mode='w')\n    print(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-19T16:29:10.514Z"
     },
     {
      "end_time": "2021-01-19T16:47:06.229Z",
      "execution_time": "220ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = '../../B.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    upload.query('curation == \"Pass\"', inplace = True)\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    exec_time = 0\n    increment = 0\n\n    print(\"Finished.\")\n\n    segments = [6]\n    for segment in segments:\n    \n        print(f\"Starting calculations for segment {segment}:\")\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\n        freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = parameter[1].item(),\n            min_dist = parameter[2].item(),\n            n_components = parameter[3].item(),\n            random_state = parameter[4].item(),\n            metric = parameter[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print(\"Finished.\")\n\n        print(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\n        freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = parameter[7].item(),\n            min_dist = parameter[8].item(),\n            n_components = parameter[9].item(),\n            random_state = parameter[10].item(),\n            metric = parameter[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print(\"Finished.\")\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print(\"- Running HDBscan for clustering.\", end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n            cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n            alpha = parameter[15].item(), #don't mess with this\n        ).fit(matrix)\n\n        print(\"Finished.\")\n\n        print(\"- Centroid extraction.\", end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['False'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['True']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = parameter[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print(\"Finished.\")\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\n        diagnostic = co.Counter(clusterlabel)\n        print(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n        print(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n        print(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n        print(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n        print(\"Finished.\")\n\n    result = pd.concat(clusters)\n    result.index.set_names([\"segment\", \"accession\"], inplace=True)\n    result.reset_index(level = \"segment\", inplace=True)  \n    result.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',', mode='w')\n    print(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-19T16:47:06.009Z"
     },
     {
      "end_time": "2021-01-19T16:50:10.279Z",
      "execution_time": "222ms",
      "outputs": [],
      "source": "def main():\n\n    print(\"Read input and settings file.\", end = ' ')\n\n    infile = '../../A.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    upload.query('curation == \"Pass\"', inplace = True)\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    exec_time = 0\n    increment = 0\n\n    print(\"Finished.\")\n\n    segments = [6]\n    for segment in segments:\n    \n        print(f\"Starting calculations for segment {segment}:\")\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print(\"- Nucleotide k-mer frequency calculation.\", end = ' ')\n\n        freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = parameter[1].item(),\n            min_dist = parameter[2].item(),\n            n_components = parameter[3].item(),\n            random_state = parameter[4].item(),\n            metric = parameter[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print(\"Finished.\")\n\n        print(\"- Aminoacid k-mer frequency calculation.\", end = ' ')\n\n        freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print(\"Finished.\")\n\n        print(\"- Running UMAP for dimension reduction.\", end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = parameter[7].item(),\n            min_dist = parameter[8].item(),\n            n_components = parameter[9].item(),\n            random_state = parameter[10].item(),\n            metric = parameter[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print(\"Finished.\")\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print(\"- Running HDBscan for clustering.\", end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n            cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n            alpha = parameter[15].item(), #don't mess with this\n        ).fit(matrix)\n\n        print(\"Finished.\")\n\n        print(\"- Centroid extraction.\", end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['False'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['True']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = parameter[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print(\"Finished.\")\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f\"- Clustering done in {exec_clust:0.2f} seconds.\")\n        diagnostic = co.Counter(clusterlabel)\n        print(f\"- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n        print(f\"- Mean of inner cluster distance mean {overall_mean/num:0.10f}\")\n        print(f\"- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.\")\n        print(f\"- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.\")\n        print(\"Finished.\")\n\n    result = pd.concat(clusters)\n    result.index.set_names([\"segment\", \"accession\"], inplace=True)\n    result.reset_index(level = \"segment\", inplace=True)  \n    result.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',', mode='w')\n    print(f\"Overall execution time {exec_time:0.2f} seconds.\")",
      "start_time": "2021-01-19T16:50:10.057Z"
     },
     {
      "end_time": "2021-01-19T17:29:29.225Z",
      "execution_time": "61ms",
      "outputs": [
       {
        "ename": "SyntaxError",
        "evalue": "invalid syntax (<ipython-input-3-bcf5478cebb3>, line 13)",
        "output_type": "error",
        "traceback": [
         "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-bcf5478cebb3>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    upload.query('curation == 'Pass'', inplace = True)\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
        ]
       }
      ],
      "source": "def main():\n\n    print('Read input and settings file.', end = ' ')\n\n    infile = '../../B.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n    threads = 8\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    upload.query('curation == 'Pass'', inplace = True)\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    mafft_dict = co.defaultdict(list)\n    \n    exec_time = 0\n    increment = 0\n\n    print('Finished.')\n\n    segments = [6]\n    for segment in segments:\n    \n        mafft_dict[segment] = co.defaultdict(list)\n        \n        print(f'Starting calculations for segment {segment}:')\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        setting = [para if type(para) == str else para.item() for para in parameter]\n        \n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print('- Nucleotide k-mer frequency calculation.', end = ' ')\n\n        freq_nt = vectorizer(k = setting[0], convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = setting[1],\n            min_dist = setting[2],\n            n_components = setting[3],\n            random_state = setting[4],\n            metric = setting[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print('Finished.')\n\n        print('- Aminoacid k-mer frequency calculation.', end = ' ')\n\n        freq_aa = vectorizer(k = setting[6], convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = setting[7],\n            min_dist = setting[8],\n            n_components = setting[9],\n            random_state = setting[10],\n            metric = setting[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print('Finished.')\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print('- Running HDBscan for clustering.', end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = setting[12], #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = setting[13], #minimum size that can become a cluster\n            cluster_selection_epsilon = setting[14], #don't seperate clusters with a distance less than value\n            alpha = setting[15], #don't mess with this\n        ).fit(matrix)\n\n        print('Finished.')\n\n        print('- Centroid extraction.', end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['False'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['True']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        msa_dict = co.defaultdict(str)\n        \n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = setting[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n            \n            mafft_sub = upload.filter(items = match, axis=0)\n\n            fasta = mafft_sub[['genome']].copy()\n            fasta.to_csv('genome.fasta', header=None, index=True, sep='\\n', mode='w')\n\n            mafft_cline = MafftCommandline(input='genome.fasta', thread=threads)\n            stdout, stderr = mafft_cline()\n            #align = AlignIO.read(StringIO(stdout), 'fasta')\n            #count = AlignIO.write(align, 'result.faa', 'fasta')\n\n            for j in stdout.split('\\n'):\n                if j == '':\n                    pass\n                elif j[0] == '>':\n                    accession = j\n                else:\n                    msa_dict[accession] += j\n\n            alignment = pd.DataFrame.from_dict(msa_dict, orient='index', columns=['alignment'])\n            alignment.index.rename('accession', inplace=True)\n\n            msa_dict.clear()\n\n            mafft_dict[segment][i] = alignment\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print('Finished.')\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f'- Clustering done in {exec_clust:0.2f} seconds.')\n        diagnostic = co.Counter(clusterlabel)\n        print(f'- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.')\n        print(f'- Mean of inner cluster distance mean {overall_mean/num:0.10f}')\n        print(f'- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.')\n        print(f'- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.')\n        print('Finished.')\n\n    result_cluster = pd.concat(clusters)\n    result_cluster.index.set_names(['segment', 'accession'], inplace=True)\n    result_cluster.reset_index(level = 'segment', inplace=True)  \n    result_cluster.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result_cluster.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',', mode='w')\n    \n    result_msa = pd.concat(z)\n    result_msa.index.set_names(['segment', 'cluster', 'accession'], inplace=True)\n    result_msa.reset_index(level = ['segment', 'cluster'], inplace=True)  \n    result_msa.sort_values(by=['segment', 'cluster', 'accession', 'alignment'], inplace = True)\n    \n    print(f'Overall execution time {exec_time:0.2f} seconds.')",
      "start_time": "2021-01-19T17:29:29.164Z"
     },
     {
      "end_time": "2021-01-19T17:29:48.734Z",
      "execution_time": "70ms",
      "outputs": [
       {
        "ename": "SyntaxError",
        "evalue": "EOL while scanning string literal (<ipython-input-4-8e45873f2968>, line 13)",
        "output_type": "error",
        "traceback": [
         "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-8e45873f2968>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    upload.query('curation == \"Pass\", inplace = True)\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
        ]
       }
      ],
      "source": "def main():\n\n    print('Read input and settings file.', end = ' ')\n\n    infile = '../../B.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n    threads = 8\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    upload.query('curation == \"Pass\", inplace = True)\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    mafft_dict = co.defaultdict(list)\n    \n    exec_time = 0\n    increment = 0\n\n    print('Finished.')\n\n    segments = [6]\n    for segment in segments:\n    \n        mafft_dict[segment] = co.defaultdict(list)\n        \n        print(f'Starting calculations for segment {segment}:')\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        setting = [para if type(para) == str else para.item() for para in parameter]\n        \n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print('- Nucleotide k-mer frequency calculation.', end = ' ')\n\n        freq_nt = vectorizer(k = setting[0], convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = setting[1],\n            min_dist = setting[2],\n            n_components = setting[3],\n            random_state = setting[4],\n            metric = setting[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print('Finished.')\n\n        print('- Aminoacid k-mer frequency calculation.', end = ' ')\n\n        freq_aa = vectorizer(k = setting[6], convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = setting[7],\n            min_dist = setting[8],\n            n_components = setting[9],\n            random_state = setting[10],\n            metric = setting[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print('Finished.')\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print('- Running HDBscan for clustering.', end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = setting[12], #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = setting[13], #minimum size that can become a cluster\n            cluster_selection_epsilon = setting[14], #don't seperate clusters with a distance less than value\n            alpha = setting[15], #don't mess with this\n        ).fit(matrix)\n\n        print('Finished.')\n\n        print('- Centroid extraction.', end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['False'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['True']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        msa_dict = co.defaultdict(str)\n        \n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = setting[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n            \n            mafft_sub = upload.filter(items = match, axis=0)\n\n            fasta = mafft_sub[['genome']].copy()\n            fasta.to_csv('genome.fasta', header=None, index=True, sep='\\n', mode='w')\n\n            mafft_cline = MafftCommandline(input='genome.fasta', thread=threads)\n            stdout, stderr = mafft_cline()\n            #align = AlignIO.read(StringIO(stdout), 'fasta')\n            #count = AlignIO.write(align, 'result.faa', 'fasta')\n\n            for j in stdout.split('\\n'):\n                if j == '':\n                    pass\n                elif j[0] == '>':\n                    accession = j\n                else:\n                    msa_dict[accession] += j\n\n            alignment = pd.DataFrame.from_dict(msa_dict, orient='index', columns=['alignment'])\n            alignment.index.rename('accession', inplace=True)\n\n            msa_dict.clear()\n\n            mafft_dict[segment][i] = alignment\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print('Finished.')\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f'- Clustering done in {exec_clust:0.2f} seconds.')\n        diagnostic = co.Counter(clusterlabel)\n        print(f'- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.')\n        print(f'- Mean of inner cluster distance mean {overall_mean/num:0.10f}')\n        print(f'- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.')\n        print(f'- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.')\n        print('Finished.')\n\n    result_cluster = pd.concat(clusters)\n    result_cluster.index.set_names(['segment', 'accession'], inplace=True)\n    result_cluster.reset_index(level = 'segment', inplace=True)  \n    result_cluster.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result_cluster.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',', mode='w')\n    \n    result_msa = pd.concat(z)\n    result_msa.index.set_names(['segment', 'cluster', 'accession'], inplace=True)\n    result_msa.reset_index(level = ['segment', 'cluster'], inplace=True)  \n    result_msa.sort_values(by=['segment', 'cluster', 'accession', 'alignment'], inplace = True)\n    \n    print(f'Overall execution time {exec_time:0.2f} seconds.')",
      "start_time": "2021-01-19T17:29:48.664Z"
     },
     {
      "end_time": "2021-01-19T17:30:04.434Z",
      "execution_time": "336ms",
      "outputs": [],
      "source": "def main():\n\n    print('Read input and settings file.', end = ' ')\n\n    infile = '../../B.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n    threads = 8\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    upload.query('curation == \"Pass\"', inplace = True)\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    mafft_dict = co.defaultdict(list)\n    \n    exec_time = 0\n    increment = 0\n\n    print('Finished.')\n\n    segments = [6]\n    for segment in segments:\n    \n        mafft_dict[segment] = co.defaultdict(list)\n        \n        print(f'Starting calculations for segment {segment}:')\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        setting = [para if type(para) == str else para.item() for para in parameter]\n        \n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print('- Nucleotide k-mer frequency calculation.', end = ' ')\n\n        freq_nt = vectorizer(k = setting[0], convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = setting[1],\n            min_dist = setting[2],\n            n_components = setting[3],\n            random_state = setting[4],\n            metric = setting[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print('Finished.')\n\n        print('- Aminoacid k-mer frequency calculation.', end = ' ')\n\n        freq_aa = vectorizer(k = setting[6], convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = setting[7],\n            min_dist = setting[8],\n            n_components = setting[9],\n            random_state = setting[10],\n            metric = setting[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print('Finished.')\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print('- Running HDBscan for clustering.', end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = setting[12], #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = setting[13], #minimum size that can become a cluster\n            cluster_selection_epsilon = setting[14], #don't seperate clusters with a distance less than value\n            alpha = setting[15], #don't mess with this\n        ).fit(matrix)\n\n        print('Finished.')\n\n        print('- Centroid extraction.', end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['False'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['True']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        msa_dict = co.defaultdict(str)\n        \n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = setting[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n            \n            mafft_sub = upload.filter(items = match, axis=0)\n\n            fasta = mafft_sub[['genome']].copy()\n            fasta.to_csv('genome.fasta', header=None, index=True, sep='\\n', mode='w')\n\n            mafft_cline = MafftCommandline(input='genome.fasta', thread=threads)\n            stdout, stderr = mafft_cline()\n            #align = AlignIO.read(StringIO(stdout), 'fasta')\n            #count = AlignIO.write(align, 'result.faa', 'fasta')\n\n            for j in stdout.split('\\n'):\n                if j == '':\n                    pass\n                elif j[0] == '>':\n                    accession = j\n                else:\n                    msa_dict[accession] += j\n\n            alignment = pd.DataFrame.from_dict(msa_dict, orient='index', columns=['alignment'])\n            alignment.index.rename('accession', inplace=True)\n\n            msa_dict.clear()\n\n            mafft_dict[segment][i] = alignment\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print('Finished.')\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f'- Clustering done in {exec_clust:0.2f} seconds.')\n        diagnostic = co.Counter(clusterlabel)\n        print(f'- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.')\n        print(f'- Mean of inner cluster distance mean {overall_mean/num:0.10f}')\n        print(f'- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.')\n        print(f'- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.')\n        print('Finished.')\n\n    result_cluster = pd.concat(clusters)\n    result_cluster.index.set_names(['segment', 'accession'], inplace=True)\n    result_cluster.reset_index(level = 'segment', inplace=True)  \n    result_cluster.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result_cluster.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',', mode='w')\n    \n    result_msa = pd.concat(z)\n    result_msa.index.set_names(['segment', 'cluster', 'accession'], inplace=True)\n    result_msa.reset_index(level = ['segment', 'cluster'], inplace=True)  \n    result_msa.sort_values(by=['segment', 'cluster', 'accession', 'alignment'], inplace = True)\n    \n    print(f'Overall execution time {exec_time:0.2f} seconds.')",
      "start_time": "2021-01-19T17:30:04.098Z"
     },
     {
      "end_time": "2021-01-19T17:33:26.438Z",
      "execution_time": "325ms",
      "outputs": [],
      "source": "def main():\n\n    print('Read input and settings file.', end = ' ')\n\n    infile = '../../B.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n    threads = 8\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    upload.query('curation == \"Pass\"', inplace = True)\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    mafft_dict = co.defaultdict(list)\n    \n    exec_time = 0\n    increment = 0\n\n    print('Finished.')\n\n    segments = [6]\n    for segment in segments:\n    \n        mafft_dict[segment] = co.defaultdict(list)\n        \n        print(f'Starting calculations for segment {segment}:')\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        setting = [para if type(para) == str else para.item() for para in parameter]\n        \n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print('- Nucleotide k-mer frequency calculation.', end = ' ')\n\n        freq_nt = vectorizer(k = setting[0], convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = setting[1],\n            min_dist = setting[2],\n            n_components = setting[3],\n            random_state = setting[4],\n            metric = setting[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print('Finished.')\n\n        print('- Aminoacid k-mer frequency calculation.', end = ' ')\n\n        freq_aa = vectorizer(k = setting[6], convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = setting[7],\n            min_dist = setting[8],\n            n_components = setting[9],\n            random_state = setting[10],\n            metric = setting[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print('Finished.')\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print('- Running HDBscan for clustering.', end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = setting[12], #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = setting[13], #minimum size that can become a cluster\n            cluster_selection_epsilon = setting[14], #don't seperate clusters with a distance less than value\n            alpha = setting[15], #don't mess with this\n        ).fit(matrix)\n\n        print('Finished.')\n\n        print('- Centroid extraction.', end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['False'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['True']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        msa_dict = co.defaultdict(str)\n        \n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = setting[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n            \n            mafft_sub = upload.filter(items = match, axis=0)\n\n            fasta = mafft_sub[['genome']].copy()\n            fasta.to_csv('genome.fasta', header=None, index=True, sep='\\n', mode='w')\n\n            mafft_cline = MafftCommandline(input='genome.fasta', thread=threads)\n            stdout, stderr = mafft_cline()\n            \n            for j in stdout.split('\\n'):\n                if j == '':\n                    pass\n                elif j[0] == '>':\n                    accession = j\n                else:\n                    msa_dict[accession] += j\n\n            alignment = pd.DataFrame.from_dict(msa_dict, orient='index', columns=['alignment'])\n            alignment.index.rename('accession', inplace=True)\n\n            msa_dict.clear()\n\n            mafft_dict[segment][i] = alignment\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print('Finished.')\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f'- Clustering done in {exec_clust:0.2f} seconds.')\n        diagnostic = co.Counter(clusterlabel)\n        print(f'- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.')\n        print(f'- Mean of inner cluster distance mean {overall_mean/num:0.10f}')\n        print(f'- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.')\n        print(f'- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.')\n        print('Finished.')\n\n    result_cluster = pd.concat(clusters)\n    result_cluster.index.set_names(['segment', 'accession'], inplace=True)\n    result_cluster.reset_index(level = 'segment', inplace=True)  \n    result_cluster.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result_cluster.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',', mode='w')\n    \n    result_msa = pd.concat(mafft_dict)\n    result_msa.index.set_names(['segment', 'cluster', 'accession'], inplace=True)\n    result_msa.reset_index(level = ['segment', 'cluster'], inplace=True)  \n    result_msa.sort_values(by=['segment', 'cluster', 'accession', 'alignment'], inplace = True)\n    result_msa.to_csv(outpath + 'alignment.csv', index=True, header=True, sep=',', mode='w')\n    \n    print(f'Overall execution time {exec_time:0.2f} seconds.')",
      "start_time": "2021-01-19T17:33:26.113Z"
     },
     {
      "end_time": "2021-01-19T17:43:10.500Z",
      "execution_time": "335ms",
      "outputs": [],
      "source": "def main():\n\n    print('Read input and settings file.', end = ' ')\n\n    infile = '../../B.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n    threads = 8\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    upload.query('curation == \"Pass\"', inplace = True)\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    mafft_dict = co.defaultdict(list)\n    \n    exec_time = 0\n    increment = 0\n\n    print('Finished.')\n\n    segments = [6]\n    for segment in segments:\n        \n        print(f'Starting calculations for segment {segment}:')\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        setting = [para if type(para) == str else para.item() for para in parameter]\n        \n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        print('- Nucleotide k-mer frequency calculation.', end = ' ')\n\n        freq_nt = vectorizer(k = setting[0], convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = setting[1],\n            min_dist = setting[2],\n            n_components = setting[3],\n            random_state = setting[4],\n            metric = setting[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print('Finished.')\n\n        print('- Aminoacid k-mer frequency calculation.', end = ' ')\n\n        freq_aa = vectorizer(k = setting[6], convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = setting[7],\n            min_dist = setting[8],\n            n_components = setting[9],\n            random_state = setting[10],\n            metric = setting[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print('Finished.')\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print('- Running HDBscan for clustering.', end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = setting[12], #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = setting[13], #minimum size that can become a cluster\n            cluster_selection_epsilon = setting[14], #don't seperate clusters with a distance less than value\n            alpha = setting[15], #don't mess with this\n        ).fit(matrix)\n\n        print('Finished.')\n\n        print('- Centroid extraction.', end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['False'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['True']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        align_dict = co.defaultdict(list)\n        msa_dict = co.defaultdict(str)\n        \n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = setting[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n            \n            mafft_sub = upload.filter(items = match, axis=0)\n\n            fasta = mafft_sub[['genome']].copy()\n            fasta.to_csv('genome.fasta', header=None, index=True, sep='\\n', mode='w')\n\n            mafft_cline = MafftCommandline(input='genome.fasta', thread=threads)\n            stdout, stderr = mafft_cline()\n            \n            for j in stdout.split('\\n'):\n                if j == '':\n                    pass\n                elif j[0] == '>':\n                    accession = j\n                else:\n                    msa_dict[accession] += j\n\n            alignment = pd.DataFrame.from_dict(msa_dict, orient='index', columns=['alignment'])\n            alignment.index.rename('accession', inplace=True)\n\n            msa_dict.clear()\n\n            align_dict[i] = alignment\n\n        mafft_dict[segment] = pd.concat(align_dict)\n            \n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print('Finished.')\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f'- Clustering done in {exec_clust:0.2f} seconds.')\n        diagnostic = co.Counter(clusterlabel)\n        print(f'- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.')\n        print(f'- Mean of inner cluster distance mean {overall_mean/num:0.10f}')\n        print(f'- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.')\n        print(f'- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.')\n        print('Finished.')\n\n    result_cluster = pd.concat(clusters)\n    result_cluster.index.set_names(['segment', 'accession'], inplace=True)\n    result_cluster.reset_index(level = 'segment', inplace=True)  \n    result_cluster.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result_cluster.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',', mode='w')\n    \n    result_msa = pd.concat(mafft_dict)\n    result_msa.index.set_names(['segment', 'cluster', 'accession'], inplace=True)\n    result_msa.reset_index(level = ['segment', 'cluster'], inplace=True)  \n    result_msa.sort_values(by=['segment', 'cluster', 'accession', 'alignment'], inplace = True)\n    result_msa.to_csv(outpath + 'alignment.csv', index=True, header=True, sep=',', mode='w')\n    \n    print(f'Overall execution time {exec_time:0.2f} seconds.')",
      "start_time": "2021-01-19T17:43:10.165Z"
     },
     {
      "end_time": "2021-01-19T17:52:54.785Z",
      "execution_time": "3m 1s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 6:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Empty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Empty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nEmpty DataFrame\nColumns: [genome]\nIndex: []\nFinished.\n- Clustering done in 180.03 seconds.\n- 10417 sequences, 13 unclustered, 250 cluster.\n- Mean of inner cluster distance mean 0.0000583877\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nOverall execution time 180.03 seconds.\n"
       }
      ],
      "source": "#def main():\n\nprint('Read input and settings file.', end = ' ')\n\ninfile = '../../B.csv'   \nsetfile = 'Input/settings.csv'\noutpath = 'Output/'\nthreads = 8\n\nsettings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\nupload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\nupload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\nupload.query('curation == \"Pass\"', inplace = True)\nsegments = settings.index.values.tolist()\nclusters = co.defaultdict(list)\nmafft_dict = co.defaultdict(list)\n\nexec_time = 0\nincrement = 0\n\nprint('Finished.')\n\nsegments = [6]\nfor segment in segments:\n\n    print(f'Starting calculations for segment {segment}:')\n\n    start_clust = time.perf_counter()\n    parameter = settings.loc[segment].to_list()\n    setting = [para if type(para) == str else para.item() for para in parameter]\n\n    subset = upload.query('segment == @segment').reset_index()\n\n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n\n    print('- Nucleotide k-mer frequency calculation.', end = ' ')\n\n    freq_nt = vectorizer(k = setting[0], convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print('Finished.')\n\n    print('- Running UMAP for dimension reduction.', end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = setting[1],\n        min_dist = setting[2],\n        n_components = setting[3],\n        random_state = setting[4],\n        metric = setting[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print('Finished.')\n\n    print('- Aminoacid k-mer frequency calculation.', end = ' ')\n\n    freq_aa = vectorizer(k = setting[6], convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print('Finished.')\n\n    print('- Running UMAP for dimension reduction.', end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = setting[7],\n        min_dist = setting[8],\n        n_components = setting[9],\n        random_state = setting[10],\n        metric = setting[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print('Finished.')\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n    print('- Running HDBscan for clustering.', end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = setting[12], #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = setting[13], #minimum size that can become a cluster\n        cluster_selection_epsilon = setting[14], #don't seperate clusters with a distance less than value\n        alpha = setting[15], #don't mess with this\n    ).fit(matrix)\n\n    print('Finished.')\n\n    print('- Centroid extraction.', end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['False'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters[segment]['cluster'].max()+1\n    values = ['True']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n\n    align_dict = co.defaultdict(list)\n    msa_dict = co.defaultdict(str)\n\n    for i in range(num):\n\n        query = clusters[segment].query('cluster == @i')\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = setting[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n\n        subs.clear()\n\n        mafft_sub = subset.filter(items = match, axis=0)\n\n        fasta = mafft_sub[['genome']].copy()\n        \n        print(fasta)\n        fasta.to_csv('genome.fasta', header=None, index=True, sep='\\n', mode='w')\n\n        mafft_cline = MafftCommandline(input='genome.fasta', thread=threads)\n        stdout, stderr = mafft_cline()\n\n        for j in stdout.split('\\n'):\n            if j == '':\n                pass\n            elif j[0] == '>':\n                accession = j\n            else:\n                msa_dict[accession] += j\n\n        alignment = pd.DataFrame.from_dict(msa_dict, orient='index', columns=['alignment'])\n        alignment.index.rename('accession', inplace=True)\n\n        msa_dict.clear()\n\n        align_dict[i] = alignment\n\n    mafft_dict[segment] = pd.concat(align_dict)\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n    clusters[segment].update(centroids)\n\n    increment += num - 1\n\n    print('Finished.')\n\n    stop_clust = time.perf_counter()\n    exec_clust = stop_clust - start_clust\n    exec_time = exec_time + exec_clust\n\n    print(f'- Clustering done in {exec_clust:0.2f} seconds.')\n    diagnostic = co.Counter(clusterlabel)\n    print(f'- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.')\n    print(f'- Mean of inner cluster distance mean {overall_mean/num:0.10f}')\n    print(f'- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.')\n    print(f'- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.')\n    print('Finished.')\n\nresult_cluster = pd.concat(clusters)\nresult_cluster.index.set_names(['segment', 'accession'], inplace=True)\nresult_cluster.reset_index(level = 'segment', inplace=True)  \nresult_cluster.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\nresult_cluster.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',', mode='w')\n\nresult_msa = pd.concat(mafft_dict)\nresult_msa.index.set_names(['segment', 'cluster', 'accession'], inplace=True)\nresult_msa.reset_index(level = ['segment', 'cluster'], inplace=True)  \nresult_msa.sort_values(by=['segment', 'cluster', 'accession', 'alignment'], inplace = True)\nresult_msa.to_csv(outpath + 'alignment.csv', index=True, header=True, sep=',', mode='w')\n\nprint(f'Overall execution time {exec_time:0.2f} seconds.')",
      "start_time": "2021-01-19T17:49:53.572Z"
     },
     {
      "end_time": "2021-01-19T18:23:10.002Z",
      "execution_time": "4m 58s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 6:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction.                                                       genome\naccession                                                   \n>MK380549  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK469114  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MH705703  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MG916763  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MH705839  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n...                                                      ...\n>MK762735  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK380575  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK469155  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK445462  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK380576  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n\n[66 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY240371  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY240363  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY242653  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY242661  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY242645  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY239060  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH362881  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH585127  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231418  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH362909  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n...                                                      ...\n>CY248251  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248259  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248267  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY240204  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH081819  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n\n[152 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY124958  ATCTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY124902  ATCTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY124998  ATCTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY124870  ATCTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY124918  ATCTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY124926  ATCTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY124934  ATCTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY124942  ATCTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY124886  ATCTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY124910  ATCTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY124894  ATCTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY124950  ATCTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY124982  ATCTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY124990  ATCTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY124974  ATCTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY124878  ATCTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY188739  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY188723  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY188779  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY188707  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n                                                      genome\naccession                                                   \n>CY156556  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY150763  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY198867  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY156676  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY115257  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCCTCAA...\n...                                                      ...\n>CY198339  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY156700  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY150747  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY156540  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY115185  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n\n[128 rows x 1 columns]\n                                                      genome\naccession                                                   \n>MN156030  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK630561  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK630609  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK676256  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK676272  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK474489  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>MH135895  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH583090  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH362865  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH585104  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH671699  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n...                                                      ...\n>CY262213  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH136543  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH136551  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH583986  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH245804  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n\n[233 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY256551  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY250197  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY256559  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY250205  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY231514  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n...                                                      ...\n>CY217187  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY212260  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613321  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY042693  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>KX921930  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n\n[217 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY221160  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY236747  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY236739  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY226905  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY221648  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY230247  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY242543  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n                                                      genome\naccession                                                   \n>KX007634  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>KX612649  ATCTTCTCAAAAAACTGAGGCAAATAAGCCAAAAATGAACAATGCT...\n>KX612510  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>KX920626  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613457  ATCTTCTCAAAAAACTGAGGCAAATAAGCCAAAAATGAACAATGCT...\n>KX612913  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAAATGAACAATG...\n>KX920610  ATCTTCTCAAAAAACTGAGGCAAATAAGCCAAAAATGAACAATGCT...\n>KX920330  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>KX613593  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX920578  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>KX617000  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY116904  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX919674  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX919874  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY116848  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>KX919602  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX615224  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>CY211349  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX618113  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX614904  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX920290  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX615464  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX614249  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007089  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613785  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>KX612262  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>KX920650  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>CY263087  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY263119  CTTCTCAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGCTACC...\n>CY226272  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAAATGAACAATG...\n>KX920658  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAAATGAACAATG...\n>KX614257  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>KX614297  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>KX922674  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613217  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>KY042338  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>KX614928  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>KY042345  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>KX618121  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>CY217780  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>KX617456  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX617464  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX006517  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY043059  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>KX614049  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>KX617601  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAAATGAACAATG...\n>KX617921  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGCT...\n>KY003880  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGCT...\n>KX617929  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY003889  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY043368  TCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGCT...\n>KX921138  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>MN949522  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949530  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949539  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949599  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949607  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN638208  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049334  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819441  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949611  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949618  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949635  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949667  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949675  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949683  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949698  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949706  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949722  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949738  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949794  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949818  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949834  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049350  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949842  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949890  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949898  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949923  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949954  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949962  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049414  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881627  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881635  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MK676192  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584031  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK857782  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK715545  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK715553  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK857798  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK995931  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK998800  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085450  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085453  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN155894  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN155966  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK999118  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085769  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK999222  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK999230  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085962  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK676264  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK772043  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK858022  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK858030  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK996083  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK996091  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK996100  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN086048  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230663  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN371723  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK858085  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY222375  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY222255  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY224272  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY217788  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY226032  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY217724  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248108  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248132  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248180  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY248666  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248687  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH583122  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY223647  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248853  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n...                                                      ...\n>CY238136  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248092  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY003736  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248219  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248885  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n\n[75 rows x 1 columns]\n                                                      genome\naccession                                                   \n>MN638001  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT048790  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819193  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819201  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881427  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881435  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049155  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056877  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343805  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343941  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT105834  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243973  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MT342914  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049075  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029607  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056789  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243149  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MT306790  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819337  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949295  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029592  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049083  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n...                                                      ...\n>MT049675  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057581  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343733  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030678  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT307278  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n\n[84 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY209719  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY003788  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY209561  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY289923  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY289875  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY289954  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY211208  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY209695  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY211271  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>MT242949  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN638072  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN638088  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN638144  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949327  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049130  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056869  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049147  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056925  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT105652  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT242989  ATCTTCTCAAAACTGAATCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314763  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314787  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT306870  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881563  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949490  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949555  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949572  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029960  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029967  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029975  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029983  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057037  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057029  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057061  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057069  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315035  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315043  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315046  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881595  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949859  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949930  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN950003  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343287  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN950135  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030255  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030263  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243493  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN950287  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315579  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243605  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT048724  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN950303  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030518  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT105738  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315795  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057677  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057717  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN950375  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT105826  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243965  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>CY233562  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY238168  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY238176  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247956  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248076  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248869  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249104  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249448  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MH245252  ATCTTCTCAAAACTAAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH583130  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH585144  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH362905  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH604616  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n...                                                      ...\n>MK182397  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH607114  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248148  ATCTTCTCAAAACTGAAGCAAATGAGCCAAAAATGAACAATGCTAC...\n>CY248203  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229335  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n\n[235 rows x 1 columns]\n                                                      genome\naccession                                                   \n>MH540463  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584623  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH604789  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH602212  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH606658  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH602221  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY262754  ATCTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTAC...\n>MH130696  ATCTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTAC...\n>MH581548  ATCTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTAC...\n>CY263637  ATCTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTAC...\n>MH130647  ATCTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTAC...\n>MH581499  ATCTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY221456  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229815  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY237007  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY237015  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248781  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248489  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249019  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247535  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY232818  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231402  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY240168  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY234010  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY221480  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY233165  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248347  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248379  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248387  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY230335  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>KX615296  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920490  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX007610  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006710  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX007457  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX007465  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612150  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043625  TCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTC...\n>KX612422  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006493  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613809  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613817  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613289  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616224  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX617913  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921378  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006777  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613945  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615800  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616776  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616784  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043642  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615096  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921754  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006793  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613953  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX611990  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043700  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615584  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX617120  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX617512  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY003722  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043301  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006833  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006841  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921402  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613369  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615176  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920690  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920698  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY042955  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616816  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX617440  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MT314587  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314579  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230207  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN155886  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085498  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085522  ATCTTCTMAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN155902  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230247  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230255  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN371651  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056901  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029680  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK998934  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK998982  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK999086  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK999089  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN156014  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230463  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN156078  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085834  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085882  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085906  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230559  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230583  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085954  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN156118  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN086024  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN086072  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN086080  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN156166  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK999390  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>KX007033  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX006977  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KU592517  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613913  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX611950  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921114  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX617208  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX615152  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY043667  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX615160  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX616072  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX616176  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921506  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX922082  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX617737  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX920210  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX617472  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921746  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>KX006525  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>KX006654  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>KX007009  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>KX007197  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>KX007380  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n...                                                      ...\n>KY043290  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX616328  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX920882  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921674  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX616344  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n\n[78 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY221520  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613985  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613977  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612921  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612222  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n...                                                      ...\n>KY042443  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>KX613081  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>KY042449  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>KX613089  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>KX920354  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n\n[69 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY212212  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY226256  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY233570  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231889  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY226016  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247351  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY230039  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY230055  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY233221  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247655  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231862  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY225992  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY224496  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231869  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY226264  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231346  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY226048  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY221736  ATCTTCTCAAAACTGAAGCAAATAAGCCAAAAATGAACAATGCTAC...\n>CY238531  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249240  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249256  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249288  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249470  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MT342767  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819329  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881515  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949175  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949266  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949279  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049003  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049011  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049014  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049027  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049043  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT242893  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085586  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030702  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030694  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MT342863  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT306830  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT242901  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT342975  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT342983  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049123  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056845  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT242917  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT105602  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT242925  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT105610  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT306886  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343094  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243157  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243213  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315099  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243237  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243245  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343279  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057109  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049363  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030031  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT105690  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315115  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315131  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343434  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243445  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343504  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343519  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315435  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315619  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243629  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243653  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243676  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343709  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057621  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315651  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243685  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243732  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030630  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030622  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057733  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049794  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343965  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>MT342751  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT342754  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029400  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029392  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314475  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314483  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT048891  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029496  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029488  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN155862  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT342870  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN435034  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN318694  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN638080  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN638150  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN638159  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819361  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949343  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT048730  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056885  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049163  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056909  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029688  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT105642  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT105658  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT242981  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056626  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243005  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314811  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314827  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314843  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029992  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029999  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN950019  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315054  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT307022  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030343  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057376  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315667  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881699  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049707  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881707  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030576  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030570  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MN949191  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949207  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949247  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056745  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314643  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN435028  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK715561  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK625818  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085562  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK995963  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK625896  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK363824  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN371683  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MK676232  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK999286  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049726  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK676312  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN086143  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MN949183  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343031  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MT243021  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056957  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314795  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT306918  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881587  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030229  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030233  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057565  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057573  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819561  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN950351  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MH583098  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH245268  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH606262  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH671715  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH726835  ATCTTCTCAAAACTGAAGCAARTAGGCCAAAAATGAACAATGCTAC...\n>MK715521  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MK998766  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY266012  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH583181  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH585183  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH585192  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH363057  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584165  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH245300  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH363073  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584247  ATCTTCTCAAAGCTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584267  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085530  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH583250  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH245380  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY262746  ATCTTATCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY265640  ATCTTATCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY265860  ATCTTATCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH130640  ATCTTATCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH581492  ATCTTATCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK625884  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK363758  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230382  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH233786  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584503  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085724  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230431  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH130957  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH581809  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH136303  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH245572  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584727  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH606710  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH081483  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH245628  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY250789  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY260196  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085966  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230622  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH136409  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH583802  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH245660  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH585680  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243797  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315771  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230654  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH606962  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230668  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH583930  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH583940  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230711  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH363569  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH081795  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK996147  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>KU592228  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614654  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614662  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613177  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613265  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613273  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612430  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612438  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612446  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612470  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612486  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX617561  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612206  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613993  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043164  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614001  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614009  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615392  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615400  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY042532  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615456  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX617400  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX922650  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY263071  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY263079  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>KY042925  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006929  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY042949  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MN819233  ATCTTCTCAAAACTGAATCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949151  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT242709  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314603  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT342847  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n...                                                      ...\n>MT030790  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030780  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057812  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057821  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343991  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n\n[70 rows x 1 columns]\n                                                      genome\naccession                                                   \n>MK445703  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MG916691  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MH705663  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MH705695  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTCCTC...\n>MH705719  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MH705911  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MH706055  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTCCTC...\n>MH706263  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MH706303  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN874022  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MG916795  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK380287  ATGAACAATGCTACCTTCAACTATACAAACATTAACCTTATTTCTC...\n>MK469116  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK380288  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK380289  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK380551  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK469400  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK445430  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK445432  ATGAACAATGCTACCTTCAACTATACAAATGTTAACCTTATTTCTC...\n>MK445434  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK445436  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK445437  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK445439  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK380555  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MH706575  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK380298  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK469402  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK469134  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK380569  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK469409  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK445449  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK445450  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK380303  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MT040796  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589272  ATGAACAATGCTACCCTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589280  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589288  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589296  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589304  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589312  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589328  ATGAACAATGCTACCTTCAACTATACAAACATTAACCTTATTTCTC...\n>MN589344  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589376  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589496  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MG279369  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK380306  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK469150  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK445456  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK469151  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK445457  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK380312  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK380314  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK380572  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK445712  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK445714  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK742934  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK911827  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK380574  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n                                                      genome\naccession                                                   \n>CY249494  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229487  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248971  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248979  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247343  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY217820  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY233514  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY226681  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229879  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY238709  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY240136  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY233458  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247631  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY212324  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247671  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY217436  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY218558  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247687  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY237133  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY237125  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY233970  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MN085465  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK999078  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN950151  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MT243404  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MT243421  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MN950180  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MT049507  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MT030303  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MN085994  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315859  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MT315867  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>MN881451  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT048819  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT048835  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT048828  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029736  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029744  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030646  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049763  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343869  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY153364  AATAGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTA...\n>CY153052  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY153100  AATAGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTA...\n>CY153156  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n>CY153356  AATAGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTA...\n>CY152964  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n>CY152972  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n>CY153036  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n>CY153004  AATAGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTA...\n>CY153044  AATAGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTA...\n>CY153124  AATAGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTA...\n>CY153116  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n>CY150041  AATAGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTA...\n>CY153196  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n>CY153244  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n>CY153308  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n                                                      genome\naccession                                                   \n>CY249693  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231490  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY233954  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>CY248590  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>CY221408  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY222423  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY222439  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY224760  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY224752  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229831  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229847  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231450  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231466  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY237236  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY237252  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY238056  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY240299  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249112  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249120  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249136  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249152  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249128  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249144  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249160  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249168  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249176  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY242613  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY242629  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY236402  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY211357  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY212124  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY243808  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY250462  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY244848  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY215300  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY209751  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248371  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MN638040  ATCTTCTCAAAACTGAAGCAAACAGGCCAAAAATGAACAATGCTAC...\n>MN638047  ATCTTCTCAAAACTGAAGCAAACAGGCCAAAAATGAACAATGCTAC...\n>MN638054  ATCTTCTCAAAACTGAAGCAAACAGGCCAAAAATGAACAATGCTAC...\n>MN638065  ATCTTCTCAAAACTGAAGCAAACAGGCCAAAAATGAACAATGCTAC...\n>MT314723  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343039  ATCTTTTCTCAAAACTGAAGCAAACAGGCCAAAAATGAACAATGCT...\n>MT243373  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343510  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819569  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057781  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030750  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY249581  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY246912  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY217476  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY222119  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY237526  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY225848  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231780  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247679  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY233094  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY226064  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY226072  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY217580  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247447  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247455  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY215292  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY211240  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY211247  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY215308  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY211326  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY211333  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY236395  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY211341  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY212132  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249248  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249264  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>KX921898  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX007155  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY042981  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY042257  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920922  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920762  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043779  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043670  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY042731  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616240  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX922138  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAATGAACAATGCTACC...\n>KX922538  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAATGAACAATGCTACC...\n>KY003896  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY116864  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612038  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612046  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612062  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612054  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616208  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043885  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920962  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921762  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX618057  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>KX920506  ATCTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614726  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614734  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX007674  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006589  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n...                                                      ...\n>KX921938  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921946  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615168  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920362  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX949101  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n\n[158 rows x 1 columns]\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>CY218478  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY215595  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY221008  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY215587  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY212220  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY217163  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY212228  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>KX922178  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612589  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043657  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612597  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615968  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX922474  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX618105  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX618161  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616704  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616440  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921322  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX618137  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY211452  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MN085426  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN318670  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MN318678  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MN435045  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN155926  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MN230537  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230542  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230703  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MN156190  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n                                                      genome\naccession                                                   \n>MH585224  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH363049  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584152  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH606327  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH606338  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH606346  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH135999  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH583209  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH583226  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584194  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584203  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584207  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584216  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584221  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584232  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584239  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584258  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584271  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584279  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH671742  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH606371  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK025809  ATCTTCTCAAAACTGAARCAAATGGGCCAAAAATGAACAATGCTAC...\n>MH080947  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584294  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH606466  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH606474  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH585440  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584455  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584463  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584527  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584534  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH245468  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584545  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK996003  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH363297  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH583629  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH671758  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH604797  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584703  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK025857  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH081411  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH606754  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH583778  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH585632  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH604878  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH671803  AAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>MH363457  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH604895  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH233914  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH585711  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH582036  ATCTTCTTAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY263661  ATCTTCTTAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH131184  ATCTTCTTAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MK998734  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK995907  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK857814  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MK998862  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MK998870  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n...                                                      ...\n>MK772035  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK772051  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK625996  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK398366  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK858093  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n\n[64 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY215635  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231817  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY224408  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH585282  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY232880  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247583  ATCTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247591  ATCTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247972  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248028  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAT...\n>CY247916  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247940  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247948  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY209647  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY289932  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY211310  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY211428  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY246896  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY246904  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH894591  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK181616  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616928  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229671  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247255  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247279  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248931  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY233284  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616968  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921018  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY042553  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616992  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX617585  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043966  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX922026  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248116  ATCTTCTCAAAAYTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>KX613465  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612897  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920602  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612374  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615992  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616000  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY042873  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921194  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX617344  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921418  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX922066  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX922058  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920322  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614984  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614976  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616368  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921058  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY236635  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY234082  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY233490  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247383  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247423  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY236587  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY236579  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229471  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY237609  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY240347  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY233078  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY237212  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249661  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249677  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249533  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY221704  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819115  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY226392  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY238972  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY238765  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY236693  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231586  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248695  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229207  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229215  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248877  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY233594  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248425  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248433  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248441  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248481  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248465  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY233546  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY222247  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY238733  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231338  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY221368  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY242000  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n...                                                      ...\n>CY247519  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY222151  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY217772  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY223615  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY226416  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n\n[80 rows x 1 columns]\n                                                      genome\naccession                                                   \n>MT342898  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT342954  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029632  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056821  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT342988  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029919  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029911  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315395  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315403  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243541  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT307126  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315542  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315547  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT105770  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030550  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY218747  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229423  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248537  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248545  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248558  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248566  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248598  ATCTTCTTAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY232739  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY232142  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247303  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247319  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247327  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247335  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247367  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247375  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247415  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229255  TTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTT...\n>CY232684  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249709  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249717  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249725  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY232755  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY232148  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>KX921554  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043848  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920994  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921002  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY003637  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613521  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613249  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY042805  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613257  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920634  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614888  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614896  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615752  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043271  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615760  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616688  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616696  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921850  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX922458  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KU592244  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921122  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616624  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616632  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920818  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613049  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>KX612462  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX919994  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX922242  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX922298  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613305  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX617352  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612022  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615624  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615040  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY263039  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>KX616112  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX611974  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>KX613513  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043935  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KU592356  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KU592252  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KU592260  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KU592268  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX007664  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX007749  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006597  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006889  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006897  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043157  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614782  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006849  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006857  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006865  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006873  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006881  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX007570  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043608  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>KX615832  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX922258  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>KX922330  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>KY003598  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613529  ATCTTCTCAAAACTGAAGCAAATAGGCTAAAAATGAACAATGCTAC...\n>KX612102  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614518  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614526  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616504  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>KY043525  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614305  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614313  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614321  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615744  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043280  GGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTAACCC...\n>CY263047  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>KX616448  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY217844  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY217868  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY236371  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY236332  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY236324  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY236347  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY240128  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY236355  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY116710  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231823  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY224432  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY224440  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231830  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY224672  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248307  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248299  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248315  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248339  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249088  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249096  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247623  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY222391  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229783  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231522  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY211318  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY217460  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249741  ATCTTCTCAAAACTGAAGCAAATAGGACAAAAATGAACAATGCTAC...\n>KY042707  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX922530  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248916  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>KX614225  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX007433  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043628  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612641  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616400  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n...                                                      ...\n>KY003771  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX618129  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006533  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006557  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616200  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n\n[81 rows x 1 columns]\n                                                      genome\naccession                                                   \n>MT242861  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029656  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT105594  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN638128  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN638136  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230647  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MT049498  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057357  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315315  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030526  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT105748  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MN881491  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314667  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314659  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243125  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315323  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057365  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243437  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343686  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MT342743  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314507  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314515  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT306750  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949144  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n...                                                      ...\n>MT049937  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030827  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030838  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030846  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT344005  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n\n[282 rows x 1 columns]\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>MG916755  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MH705759  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MH705967  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MG916779  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MH706127  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MH706447  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MH706455  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n                                                      genome\naccession                                                   \n>MK898359  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTACTTCTC...\n>MG916707  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MG916715  ATGAACAATGCTACCTTCAAATATACAAACGTTAACCTTATTTCTC...\n>MG916723  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MG916731  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n...                                                      ...\n>MK911851  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MK380319  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTACTTCTC...\n>MK445721  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MK445722  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN874049  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTACTTCTC...\n\n[96 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY226360  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY223631  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY218502  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY217332  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY225840  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY224264  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY232966  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY209623  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY289959  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY233522  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY263015  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY229511  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY242559  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY224648  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY229647  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237668  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>KX922162  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613569  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613577  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613585  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613601  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612713  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613345  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920666  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920306  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920146  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920402  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX007652  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX007425  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX007282  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX007262  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614678  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920554  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614710  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614638  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613537  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX617697  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY042919  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612118  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615488  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921162  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY232786  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231386  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX617641  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK961858  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>MK961866  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY243374  AAACTGAAGTAAATAGGCCAAAAAATGAACAATGCTACCTTCAACT...\n>CY263939  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY263923  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY263842  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY243358  AAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY263899  CTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTACC...\n>CY263915  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY263931  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY263907  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY263826  CTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTACC...\n>CY243398  AAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>KX921706  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615784  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY221296  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX922570  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX007164  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX007158  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MN637992  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT242669  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT242685  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819185  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314491  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n...                                                      ...\n>MN086168  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN086184  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN156198  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT244005  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT244013  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n\n[265 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY209687  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY211200  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY215276  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY209671  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921362  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY212188  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY218332  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>KX617617  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KU592276  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614201  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX919594  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231909  CAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAAC...\n>CY226144  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614798  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612689  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920570  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX922354  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY211460  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY236425  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX919794  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920514  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KU933511  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616664  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX617857  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX617392  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX617689  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614952  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616792  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY042314  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006549  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY042436  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612809  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX617649  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY263063  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>KX921666  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY212099  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACGATGCTAC...\n>CY209735  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACGATGCTAC...\n>KX615656  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615648  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615664  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615672  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921066  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX611886  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX617745  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX617753  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX617777  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX617769  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY212268  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY218361  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006921  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY042796  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613057  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615016  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616320  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY232771  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231370  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921266  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043200  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX922370  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>MN638112  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN435058  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030351  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057421  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315387  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057445  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN435105  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MN085618  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK554873  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315027  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315019  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK998990  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085945  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN950263  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030399  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK857998  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT105818  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY154276  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154316  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154508  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154540  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154612  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154116  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154356  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154500  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY175555  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY150317  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154172  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154484  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154164  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154140  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY150325  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154236  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n                                                      genome\naccession                                                   \n>KY003713  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043884  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612518  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043905  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612526  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615552  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX922266  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX618073  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920242  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921450  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921874  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921690  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY003621  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY003629  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MH233722  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK622954  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY263781  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH080747  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH080763  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n...                                                      ...\n>CY256663  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH081835  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MG830697  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH582057  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH131205  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n\n[78 rows x 1 columns]\n                                                      genome\naccession                                                   \n>MT242741  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243053  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT306894  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343102  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343836  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049850  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT316003  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315995  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>KT866405  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866121  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866129  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866671  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866964  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866113  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT865958  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT865937  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866209  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866100  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866108  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KU592635  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KU592643  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866554  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866744  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866599  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866544  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866699  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866331  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854434  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866354  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866813  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854516  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854706  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854852  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854901  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866591  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854273  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866758  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854297  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866472  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866918  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866073  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n                                                      genome\naccession                                                   \n>CY224520  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY221136  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237478  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY240355  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY231434  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAATGAACAATGCTA...\n...                                                      ...\n>CY236975  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY236983  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237360  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY231602  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH583974  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n\n[161 rows x 1 columns]\n                                                      genome\naccession                                                   \n>KT866940  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866988  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866363  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854792  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854671  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854200  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854427  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854961  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>CY244840  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY233994  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY242597  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY240283  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY242621  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY233149  ATCTTCTCAAAAAACTGAGGCAGATAGGCCAAAAATGAACAATGCT...\n>CY221496  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY239162  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY229967  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237708  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH131045  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MG830617  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH581897  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY263031  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY237747  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY238656  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY233634  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY238144  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>MN169078  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MH705631  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK469399  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MH705727  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MH705783  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n...                                                      ...\n>MK445719  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK445720  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK380318  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK576204  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK380320  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n\n[115 rows x 1 columns]\n                                                      genome\naccession                                                   \n>MK715625  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MK857894  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MK999030  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MK999070  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MK474523  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MK554890  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MK630481  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MK630521  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n                                                      genome\naccession                                                   \n>CY237581  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY211436  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY229303  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY224424  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY225960  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY218449  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY217283  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY217812  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY224512  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY226008  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY229247  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY232668  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY238459  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY238348  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY215268  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY236316  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY226240  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>CY211372  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY229279  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY229199  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY211156  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY242605  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY234114  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY223623  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>KT866489  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866237  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854773  ATGAACAATGCTACCTTCAGCTATACAAACGTTAACCTTATTTCTC...\n>KT866773  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854865  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866289  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866710  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT865952  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866339  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866708  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854831  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866504  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854618  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n                                                      genome\naccession                                                   \n>CY236951  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY236943  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY240243  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY221168  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY231745  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n...                                                      ...\n>MH131152  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH582004  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY226232  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY217732  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY226384  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n\n[71 rows x 1 columns]\n                                                      genome\naccession                                                   \n>KX612494  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043901  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043971  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX922306  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006913  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615256  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616256  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043920  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921042  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX922466  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615496  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615504  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615512  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX617673  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921810  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921610  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MT314619  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT242749  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819249  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819257  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819265  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819273  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819281  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819289  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819297  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819305  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819313  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949263  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056693  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029568  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029583  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056709  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056757  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314651  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315083  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057093  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315091  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057101  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819505  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881667  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881675  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343462  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057313  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030590  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030598  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>MH135903  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY265980  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH584071  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY262770  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY262610  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH136191  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH081427  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH130512  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH583666  ATCTTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262514  ATCTTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY265557  ATCTTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH136383  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH583746  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH080605  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY265884  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH081651  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH363553  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n                                                      genome\naccession                                                   \n>CY224528  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY240227  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY222479  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY229695  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH080939  ATCTTCTCAAAAAACTGAGGCAACTAGGCCAAAAATGAACAATGCT...\n...                                                      ...\n>CY250317  ATCTTCTCAAAAGACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY250309  ATCTTCTCAAAAGACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY256607  ATCTTCTCAAAAGACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY256711  ATCTTCTCAAAAGACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262244  ATCTTCTCAAAAGACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n\n[66 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY237921  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY225968  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY224448  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY242589  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY232982  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY232990  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY212108  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY224304  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY222279  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY211404  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY229295  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY217275  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY215532  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY226000  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY224504  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY233022  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY215324  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>KT866247  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866137  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866161  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866169  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866177  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866185  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KX003147  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866227  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KU592565  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866662  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866413  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854965  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KY090588  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK469120  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KU592461  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK469130  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT853333  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866752  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT865966  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854811  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KU592717  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KU592549  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KU592592  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KU592627  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854451  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT865982  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK469140  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KU592445  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KU592584  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866466  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTT...\n>KT866190  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854489  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866434  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866666  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n                                                      genome\naccession                                                   \n>CY229583  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237905  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237945  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY217396  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY218693  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY222447  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY224808  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237416  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>CY239076  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY238120  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY238128  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY232135  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY232707  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY224768  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY231650  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY239052  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY224792  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>MN588784  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN588800  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN588808  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN588824  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN588840  ATGAACAATGCTACCTTCAACTATACAAACGTTAATCCTATTTCTC...\n>MN588848  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN588864  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN588904  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN588960  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN589000  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN589096  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n                                                      genome\naccession                                                   \n>CY221528  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY221416  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY222431  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY224744  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY236802  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY236810  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY222263  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY232834  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>KT854670  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854656  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT865974  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854541  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854419  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854421  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>KT854702  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854949  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854209  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT853318  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT853324  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n...                                                      ...\n>KT853287  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT853485  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT854465  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866043  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KT866607  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n\n[236 rows x 1 columns]\n                                                      genome\naccession                                                   \n>KX615112  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX920370  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX614806  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX614814  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX613873  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX919618  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX007205  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX007364  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX007001  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX007142  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KY042477  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX613201  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX007618  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX615560  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KY116840  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX920530  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KY116778  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KY116768  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX617216  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX617224  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX617705  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KY042747  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX920978  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX615520  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KY043835  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX614265  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX922074  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KY042463  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX612801  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX616552  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX616576  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX921602  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>CY263103  CTTCTCAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCTACCT...\n>KX922226  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX919778  ATCTTCTCAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCTA...\n>KX920082  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX920090  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KY042331  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX613017  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX614385  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KX921306  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n>KY042939  ATCTTCTCAAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>CY218623  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>KX613921  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY042836  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX612134  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX919890  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX612905  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY043626  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX612382  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX615984  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921434  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX922050  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX922618  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237961  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX617553  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX920378  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX920074  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX919922  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY224624  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY236520  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX616912  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX611902  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX615528  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>KX920898  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY043942  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921882  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>KX921370  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX922122  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX922554  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX922546  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921618  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262887  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY263127  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>KY042696  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX922034  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY043957  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921394  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX617889  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX611918  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921082  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY042765  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX922410  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX919666  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY003839  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921730  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX920098  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX919954  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921386  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>CY236448  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY212172  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY236677  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY221288  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY217139  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY218324  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY218663  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY233205  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY221152  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY229687  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX920618  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY240152  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY232888  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX612613  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262144  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY256679  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237344  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY221352  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY224688  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY215516  CAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCA...\n>CY237494  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237929  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237937  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY239154  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY218510  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY217348  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY240176  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY218582  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY217468  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY226368  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY231538  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY234122  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY236456  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY212316  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY236755  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY236763  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY236779  ATCTTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGC...\n>CY236771  ATCTTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGC...\n>CY222295  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262903  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>MK969555  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY229663  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY217324  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY218494  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY218534  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY218542  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY218716  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY221200  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY222359  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY238372  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY231610  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY237149  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY237141  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY226224  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY226344  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>MH584047  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH585528  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH584759  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH585584  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH081683  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH136449  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH583821  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH583834  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH606906  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH081686  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY265749  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>CY249621  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249685  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY237454  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY221328  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY221320  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY211412  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY211420  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY218310  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY218304  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY215420  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY236464  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY215428  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY215436  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY215444  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY218414  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY215452  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY215460  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY218421  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY217508  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY221104  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248735  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247295  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY218393  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY212308  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY218755  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY221720  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249765  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY215332  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY218346  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY217564  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY221640  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY224712  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248156  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248211  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248235  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY217302  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY218739  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY221144  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY222463  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH081246  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY263607  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY221312  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>KX612166  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX615304  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX919698  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY116790  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY209553  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX616920  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX617480  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX615416  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX615408  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX616608  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX922130  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX612729  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX615360  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY217380  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX616528  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>CY226120  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY232903  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY226400  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229543  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229375  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231394  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY232794  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247900  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY262911  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY226088  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247463  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249035  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249200  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249208  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY222231  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229383  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY236617  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY234042  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249232  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MH362929  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK999001  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK999015  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK999022  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085690  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085698  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085706  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085714  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230391  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230399  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230407  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN950111  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT048708  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK858069  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MH080723  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGCT...\n>MH245364  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK265256  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK181605  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH584367  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>MH081603  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH081611  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH136426  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH582001  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH131149  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>CY221280  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY229591  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY239100  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX920482  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262362  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n...                                                      ...\n>CY229871  ATCTTCTCAAAAGACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY222303  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY222311  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY231666  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY231674  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n\n[177 rows x 1 columns]\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>CY151715  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n>CY151667  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n>CY151739  AATAGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTA...\n>CY152884  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n>CY152900  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n...                                                      ...\n>CY151643  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n>CY149903  CTGAGGCAGATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n>CY037377  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n>CY037401  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY037425  GAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACAA...\n\n[62 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY197363  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY197731  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGCTAC...\n>CY197867  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY197739  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY197715  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGCTAC...\n...                                                      ...\n>CY198027  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY197939  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY197971  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGCTAC...\n>CY197091  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY197987  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGCTAC...\n\n[62 rows x 1 columns]\n                                                      genome\naccession                                                   \n>KY116687  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY209603  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY211263  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY229263  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY226920  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY226976  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>KX613889  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY231426  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX617865  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY239092  ATCTTCTCAAAAAACTGAGGTAAATAGGCCAAAAATGAACAATGCT...\n>CY217620  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n...                                                      ...\n>CY221512  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY226352  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921146  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY042777  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX617048  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n\n[75 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY249510  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248574  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY226248  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY116733  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY209608  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY217219  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY215396  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY221632  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY221376  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY222527  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249749  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249757  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247855  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY221472  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY224544  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229655  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY237969  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249027  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249192  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229799  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY212252  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY151779  AAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACCA...\n>CY151827  AAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACCA...\n>CY151627  AAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY151883  AAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACCA...\n>CY151931  AAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACCA...\n...                                                      ...\n>CY040451  AAAAATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATT...\n>CY038289  GCAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGT...\n>CY019525  CAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAAC...\n>CY018527  AACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTAT...\n>CY038265  AAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n\n[71 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY200451  AAATTGAAGCAAATAGGCCGAAAATGAACAATGCTACCCTCAACTA...\n>CY200531  AATAGGCCGAAAATGAACAATGCTACCCTCAACTATACAAACGTTA...\n>CY200643  CCGAAAATGAACAATGCTACCCTCAACTATACAAACGTTAACCCTA...\n>MH636853  CTTCTCAAAATTGAAGCAAATAGGCCGAAAATGAACAATGCTACCC...\n>KM063750  ATGAACAATGCTACCCTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY176123  AAATTGAAGCAAATAGGCCGAAAATGAACAATGCTACCCTCAACTA...\n>CY176259  AAATTGAAGCAAATAGGCCGAAAATGAACAATGCTACCCTCAACTA...\n>CY176299  AAATTGAAGCAAATAGGCCGAAAATGAACAATGCTACCCTCAACTA...\n>CY263955  AATAGGCCGAAAATGAACAATGCTACCCTCAACTATACAAACGTTA...\n>CY182363  AAATTGAAGCAAATAGGCCGAAAATGAACAATGCTACCCTCAACTA...\n>CY182459  AAATTGAAGCAAATAGGCCGAAAATGAACAATGCTACCCTCAACTA...\n>CY182555  AAATTGAAGCAAATAGGCCGAAAATGAACAATGCTACCCTCAACTA...\n>CY201027  AATAGGCCGAAAATGAACAATGCTACCCTCAACTATACAAACGTTA...\n>CY200251  AAATTGAAGCAAATAGGCCGAAAATGAACAATGCTACCCTCAACTA...\n>CY201003  AAATTGAAGCAAATAGGCCGAAAATGAACAATGCTACCCTCAACTA...\n>CY201011  AATAGGCCGAAAATGAACAATGCTACCCTCAACTATACAAACGTTA...\n>CY202571  AATAGGCCGAAAATGAACAATGCTACCCTCAACTATACAAACGTTA...\n>CY153444  AATAGGCCAAAAAATGAACAATGCTACCCTCAACTATACAGACGTT...\n>KJ532195  ATGAACAATGCTACCCTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY201531  CCGAAAATGAACAATGCTACCCTCAACTATACAAACGTTAACCCTA...\n>KM063768  ATGAACAATGCTACCCTCAACTATACAAACGTTAACCCTATTTCTC...\n                                                      genome\naccession                                                   \n>CY238104  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY221256  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229559  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247559  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247567  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247575  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247932  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231922  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY224576  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY215603  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY215611  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY217308  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY215619  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247647  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249462  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248172  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MT242877  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT242885  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819353  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT048760  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT048763  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949311  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049091  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056652  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049099  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314739  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056836  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057117  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049371  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243645  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057605  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>CY198931  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198963  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198299  CTTCTTAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198859  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY198875  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY199043  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY199651  AAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAAC...\n>CY199659  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY199731  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199811  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199739  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY200395  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY198827  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198803  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY198835  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY199491  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY199507  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199411  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY199395  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199403  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY199435  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY199715  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY200555  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY200283  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198219  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198843  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY199803  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY198211  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199147  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199787  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199795  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY199827  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199939  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY199851  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199859  CTTCTCAAAGACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199915  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199883  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY198939  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198947  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198955  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198971  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198979  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199747  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198811  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198795  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199459  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199467  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199475  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199443  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198891  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198907  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198915  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199723  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199819  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>LC033187  AGCAGAAGCAGAGCATCTTCTCAAAAACTGAGGCAAATAGGCCAAA...\n>CY199907  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199891  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199123  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198883  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY198923  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199099  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199755  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199843  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY200003  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n                                                      genome\naccession                                                   \n>KX614750  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006905  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613433  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY042679  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX006998  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n...                                                      ...\n>KY042519  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612318  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615592  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920778  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921314  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n\n[106 rows x 1 columns]\n                                                      genome\naccession                                                   \n>KX615208  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615216  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920746  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616160  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY042725  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX921010  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX618081  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX618169  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920010  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY237047  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237039  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237913  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY238112  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY221384  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY229431  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY242677  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY229983  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY221112  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY218264  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY226448  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY233394  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY229991  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY222383  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY240184  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237850  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237858  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237866  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY231506  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY234018  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH130584  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY226424  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY266004  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY236548  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY224720  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY226376  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>CY223655  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY236967  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY236959  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY215284  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY209727  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249653  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249573  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249605  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY241992  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH080830  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY263717  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231791  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY225864  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY217227  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY215404  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY215412  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY218407  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY221024  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY226152  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY222327  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231410  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY237304  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY237312  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248505  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248513  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248521  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY233141  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY222223  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY221264  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY224376  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY225920  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY217340  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229407  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY233674  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY237676  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247311  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247431  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247439  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>CY212116  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY215492  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY233014  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY234106  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY247863  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>CY247871  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY289862  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY116738  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249701  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY238547  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY222319  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229935  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249280  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249312  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249486  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231594  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248124  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248164  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248195  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248893  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>CY151371  TGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACA...\n>CY151435  TGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACA...\n>CY151075  TGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACA...\n>CY150891  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n>CY150883  TGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACA...\n>CY151043  TGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACA...\n>CY151019  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n>CY151059  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY150875  TGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACA...\n>CY151259  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY151363  TGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACA...\n>CY151267  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n>CY150923  TGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACA...\n>CY150939  TCTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY150995  TGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACA...\n>CY151003  AATAGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTA...\n>CY151155  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n>CY151107  TGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACA...\n>CY151307  TGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACA...\n>CY151203  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n>CY151251  TGAGGCAAATAGGACAAAAATGAACAATGCTACCTTCAACTATACA...\n>CY151275  TGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACA...\n>CY151347  TGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACA...\n>CY151115  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n                                                      genome\naccession                                                   \n>MT242693  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243101  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343194  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343311  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343319  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049374  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819473  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819489  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881603  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881611  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030087  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030080  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030103  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030095  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030111  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030119  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315139  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315147  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT306958  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT306974  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343342  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343353  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT375805  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT307078  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343780  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MT242677  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT342791  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT342831  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT306775  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT306876  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056997  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057005  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343207  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315155  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315163  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030199  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243429  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343478  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343485  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT307062  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT307070  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343621  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343645  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343653  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343669  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT375821  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030494  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030502  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243789  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343829  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343861  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343893  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315883  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243901  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN950399  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049834  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315915  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057797  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MT029334  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056813  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056981  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056989  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057265  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057277  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057293  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057285  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343471  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030742  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057773  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY101022  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY099787  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY100747  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY099795  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY101006  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY100755  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY100763  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY099779  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY099803  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY100659  TCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY100667  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY099811  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY101014  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY100675  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY099819  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY101030  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY099827  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY101038  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY100683  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY100691  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY099835  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY101046  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY100699  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY100707  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY099915  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY099843  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY100715  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY100723  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY100731  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY099851  TCAAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCA...\n>CY100739  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY101068  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY106562  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY175835  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY188755  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY188771  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY188763  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY188731  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTATCT...\n>CY188747  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>MN427418  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN427411  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK771971  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK857862  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK857870  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK857878  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK857886  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK995982  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK995995  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK998998  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN435077  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN507137  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN427426  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085684  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN155974  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX007602  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK999318  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY224536  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY217612  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY222487  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX922594  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY217420  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n...                                                      ...\n>KX919642  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920122  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920130  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX919706  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX919714  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n\n[86 rows x 1 columns]\n                                                      genome\naccession                                                   \n>MK961842  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY264003  ATGAACAATGCTACCTTCAACTATACAAATGTTAACCCTATTTCTC...\n>CY263979  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY264019  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182411  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182435  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182443  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182491  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182515  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182531  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182539  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182547  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182387  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182587  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n                                                      genome\naccession                                                   \n>CY111488  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY150349  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154012  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154028  AATAGGCCAAAAATGAACAATGCTACCTTCAACTATACAAATGTTA...\n>CY150333  CTTCTCAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGCTACC...\n...                                                      ...\n>CY154380  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154460  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154572  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154628  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154228  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n\n[75 rows x 1 columns]\n                                                      genome\naccession                                                   \n>MN085442  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK630537  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK715633  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MN371686  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK999166  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MN085874  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MN085986  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MN086088  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n                                                      genome\naccession                                                   \n>KX007642  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX922610  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007562  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX920834  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY042289  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX612558  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY003694  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007253  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX612777  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY043563  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921562  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY043454  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY043460  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921570  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY003869  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY042996  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613505  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX615872  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY043223  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921282  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX616216  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613361  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>CY151595  TCTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY151035  TGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACA...\n>CY151163  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n>CY151283  TGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACA...\n>CY151531  CTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATAC...\n...                                                      ...\n>CY018215  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY018223  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY018231  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY018239  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY018247  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n\n[121 rows x 1 columns]\n                                                      genome\naccession                                                   \n>MH080739  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262674  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH081326  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH081459  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH245684  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY250813  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY258750  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH582012  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH131160  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MG830671  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262578  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY265996  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH136503  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262290  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY263416  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY265956  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>KX613561  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY042422  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612681  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX612673  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY042415  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX613337  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615264  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616288  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX616296  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX617569  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX169271  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043648  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615064  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>KX007646  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614161  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX614129  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX885877  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043927  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX919786  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX919834  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX919850  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX919858  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX615544  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KX920546  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MH363097  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK625820  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK363839  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK244741  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK363879  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAATGAACAATGCTA...\n>MK244717  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK625828  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK625836  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK363782  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK474539  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK676280  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>MN230263  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230271  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230287  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230311  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230317  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN318702  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN318734  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK999182  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK999190  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK999198  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085938  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230607  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230615  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN086064  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK676320  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MT342775  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT306758  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT242773  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT342910  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314707  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056797  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343007  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057021  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057014  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343191  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243181  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243221  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343239  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057077  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030007  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243309  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343383  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343496  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881683  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881691  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030375  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049559  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049571  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243533  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057461  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315483  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030407  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT307158  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN950295  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049627  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343797  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315755  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315747  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243773  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343813  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT375837  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT375845  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN950343  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN950367  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049739  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030638  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057693  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315811  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243933  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243997  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY155084  GGCAAATAGGCCAAAATGAACAATGCTACCCTCAACTATACAAACG...\n>CY154892  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCCTCAACTA...\n>CY154788  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCCTCAACTA...\n>CY154716  GGCAAATAGGCCAAAAATGAACAATGCTACCCTCAACTATACAAAC...\n>CY154724  AATAGGCCAAAAATGAACAATGCTACCCTCAACTATACAAACGTTA...\n>CY155092  TCTCAAAACTGAGGCAAATAGGCCAAAATGAACAATGCTACCCTCA...\n>CY150445  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCCTCAACTA...\n>CY150493  GAGGCAAATAGGCCAAAAATGAACAATGCTACCCTCAACTATACAA...\n>CY150453  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCCTCAACTA...\n>CY150413  TCTCAAAACTGAGGCAAATAGGCCAAAATGAACAATGCTACCCTCA...\n>CY154900  TCTCAAAACTGAGGCAAATAGGCCAAAATGAACAATGCTACCCTCA...\n>CY033830  GGCAAATAGGCCAAAAATGAACAATGCTACCCTCAACTATACAAAC...\n>CY174379  TCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCCTC...\n>CY174387  AAACTGAGGCAAATAGGCCAAAAAATGAACAATGCTACCCTCAACT...\n>CY152228  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCC...\n>CY154820  AATAGGCCAAAAATGAACAATGCTACCCTCAACTATACAAACGTTA...\n>CY155076  AATAGGCCAAAATGAACAATGCTACCCTCAACTATACAAACGTTAA...\n>CY150429  TCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCCTC...\n>CY150437  TCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCCTC...\n>CY154804  GGCAAATAGGCCAAAAATGAACAATGCTACCCTCAACTATACAAAC...\n>CY033886  TAGGCCAAAAATGAACAATGCTACCCTCAACTATACAAACGTTAAC...\n>CY033894  TAGGCCAAAAATGAACAATGCTACCCTCAACTATACAAACGTTAAC...\n>CY033902  TAGGCCAAAAATGAACAATGCTACCCTCAACTATACAAACGTTAAC...\n>CY150373  GCAAATAGGCCAAAAATGAACAATGCTACCCTCAACTATACAAACG...\n>CY150405  TCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCCTC...\n>CY155196  AATAGGCCAAAAATGAACAATGCTACCCTCAACTATACAAACGTTA...\n>CY154996  TCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCCTC...\n>CY154924  TCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCCTC...\n>CY022223  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCCTCAACTA...\n>CY031789  AATAGGCCAAAAATGAACAATGCTACCCTCAACTATACAAACGTTA...\n>CY040387  TCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCCTC...\n                                                      genome\naccession                                                   \n>AY139059  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTCCTC...\n>CY099867  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY119572  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY119612  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCCTCAA...\n>AY582012  ATGAACAATGCTACCCTCAACTATACAAACGTTAACCCTATTCCTC...\n...                                                      ...\n>CY018135  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY019477  AAACTGAGGCAAATAGGCCCAAAATGAACAATGCTACCTTCAACTA...\n>CY022215  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY018479  TTCTCAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCCTC...\n>CY018655  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n\n[65 rows x 1 columns]\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>CY263535  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH080675  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH233778  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH583266  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH081048  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH130464  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH081274  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH583819  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY265672  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH081670  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n                                                      genome\naccession                                                   \n>MT342730  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT306798  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT105626  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT029704  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT243013  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT056949  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT030015  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN950095  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT343536  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT343539  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN881763  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>CY258878  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH581564  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH130712  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY258886  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY258894  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY262834  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH130741  ATCTTCTCAAAAACCGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MG830483  ATCTTCTCAAAAACCGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH581593  ATCTTCTCAAAAACCGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH130805  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MG830546  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH581657  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH607090  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n                                                      genome\naccession                                                   \n>MT243093  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343132  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN638184  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN638187  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN638196  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819409  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819417  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029824  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029832  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314947  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314955  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243109  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343605  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MT029384  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029376  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819321  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029558  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029552  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056717  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT056725  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT242965  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881539  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314923  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MT314915  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MT243085  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343119  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243117  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343151  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243173  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819449  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343247  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN950087  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT105528  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029368  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343295  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057125  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030047  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT105714  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT306998  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343361  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343368  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030127  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049403  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057197  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057184  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315259  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315251  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343457  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315347  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGTTAC...\n>MT307014  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN950191  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049515  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030335  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057373  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049522  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN950199  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343565  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343597  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057538  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057541  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243581  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315635  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343757  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057707  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057701  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881739  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343925  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315971  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315963  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315987  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343972  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343980  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>KX616488  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX922106  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007065  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613801  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613825  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613865  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY042500  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613297  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX617905  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921914  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX614345  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX614353  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007321  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007361  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX920858  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX612665  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY043183  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX006444  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007221  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007041  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX614830  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX949228  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613657  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613665  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613761  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613121  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY042621  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613137  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX615080  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007274  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY043127  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007492  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX614137  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007682  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX614209  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007690  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007698  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613705  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX617520  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613729  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613753  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX922202  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX616336  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>KX613833  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007172  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY042409  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX006372  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY043146  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX614822  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613641  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613689  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY043741  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613697  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613113  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY042470  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613145  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007267  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX616720  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX615928  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>MN819209  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN155942  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN156054  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230489  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN318758  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN318766  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN318774  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230503  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230519  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085826  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN435096  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN371731  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN156158  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>KX007524  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX614670  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX616408  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX919882  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX920522  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY003751  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY003740  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY289897  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY289818  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY212091  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY209679  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX616960  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX006380  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX006388  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX006396  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007049  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613649  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY042249  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613673  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY042822  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613105  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX616936  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613713  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613745  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY042932  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY043104  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>MT243189  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819521  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049531  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN950207  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057405  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049547  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030367  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057428  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057437  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315379  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315443  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY265948  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK625751  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK398382  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>KY116693  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY289900  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY221392  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY215340  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY217356  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY242669  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH136039  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY229839  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK474555  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY231690  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY264730  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY250269  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH602204  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY238032  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY240315  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAGATGAACAATGCT...\n>CY240323  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY236724  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY236731  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY246960  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY255743  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262999  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>KX617248  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY258870  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX612849  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY043177  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX612657  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY222287  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY221744  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237180  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237172  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237196  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237188  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>MH245244  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY256575  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY250221  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY256567  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY250213  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n...                                                      ...\n>CY223639  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH131197  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH362851  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH582049  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MG830690  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n\n[132 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY262434  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262594  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY265820  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH584315  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>MK474563  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY263805  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH081070  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH604725  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH130504  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH606746  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY265578  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262554  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH606890  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH081755  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH727059  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>MH245284  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY265812  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY265804  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY265828  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH080867  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262410  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>MH081766  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH583942  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY263591  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY263599  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH080610  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH081803  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>MH233738  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH585173  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH583175  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH136007  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH583306  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH791518  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH894599  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH894607  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK181621  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH894616  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262152  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY256687  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY263749  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH363177  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH584497  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH606554  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH584519  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH081227  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH583506  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH604823  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH363369  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH130608  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH081789  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH582033  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MG830682  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH131181  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>MT242757  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MN881507  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT029520  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT049051  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT049067  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT029528  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT056765  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT375812  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT057765  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT030734  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n                                                      genome\naccession                                                   \n>MT307214  ATCTTCTCAAAAGACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT243869  ATCTTCTCAAAAGACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN881755  ATCTTCTCAAAAGACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT049861  ATCTTCTCAAAAGACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT030766  ATCTTCTCAAAAGACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT030774  ATCTTCTCAAAAGACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>MK857774  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MN318662  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MN881443  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT048806  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK998750  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n...                                                      ...\n>MH583919  ATCTTCTCAAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTA...\n>MN086136  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN086176  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH081843  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH363609  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n\n[94 rows x 1 columns]\n                                                      genome\naccession                                                   \n>MK998806  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK630375  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK181597  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK363790  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK625788  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK715572  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK398386  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK625796  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK771974  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK999052  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK999062  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MN155982  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN155998  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN230447  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK857926  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK999126  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK999134  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK626005  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK630673  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK623002  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK623011  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK626017  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>MH135887  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH671723  ATTTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262354  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH585232  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH080966  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH130869  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH581721  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH081107  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK771985  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH136183  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH606594  ATTTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH081315  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH581956  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH131104  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262378  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH583730  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH130576  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH136455  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH245724  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262298  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY263424  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262198  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262205  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>MN881483  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT048942  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT314691  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT314715  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT242869  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT306814  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT306846  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT242933  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT242941  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT306854  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MN950239  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT049579  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT243525  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT057453  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT307102  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT307094  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT307110  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT307118  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT315819  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT315827  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT243829  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT243837  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>MT314971  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT314963  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT306910  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT343159  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT029880  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT029888  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MN819465  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT048705  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT315171  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT315179  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT243285  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT243277  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT243293  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT243301  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT049384  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT049393  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT030159  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT057149  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT057141  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT057157  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT057165  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT315203  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT315211  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT057397  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT315363  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT049539  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN950215  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN950223  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT048699  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT048711  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN950231  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT057413  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT049555  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT343613  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT307150  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT343772  ATCTTTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGC...\n>MN507202  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT315955  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MN950407  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT049874  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT030806  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT030798  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT057824  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MT057837  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n                                                      genome\naccession                                                   \n>MT242662  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT306838  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN881579  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT049326  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT343271  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT306723  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN638232  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN819529  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN819537  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT048687  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN950247  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT343743  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT343749  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>MH080838  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY263725  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH581617  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH130765  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MG830506  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MG830514  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH130773  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH581625  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH130781  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MG830522  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH581633  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH130789  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH581641  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MG830530  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH604680  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MK363732  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK625767  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK622943  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK363943  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK244709  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK445824  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK558908  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK558911  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK625733  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK265477  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK363927  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK626020  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK244761  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK363935  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK244700  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK363903  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK244733  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK363911  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK398426  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n                                                      genome\naccession                                                   \n>CY218655  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY221176  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY232699  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY231354  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY221344  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY233474  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY218463  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY217299  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY222199  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY221208  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY209758  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY211255  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248813  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY265940  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH080755  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY229703  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY258910  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262826  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH130400  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH363036  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY231498  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY226160  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237629  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY263677  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH581713  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MG830602  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH130861  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262192  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY258782  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY260204  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY233498  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY232826  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY232155  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262131  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY258758  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY255690  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY246832  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH584631  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH081350  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262634  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY243848  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237276  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237557  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH080615  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY265796  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY265594  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262626  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH233890  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH081526  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY264619  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH245681  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY221672  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY238340  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH606979  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGCT...\n>CY230343  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY238192  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY256671  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY262139  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH585762  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH585007  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGGACAATGCT...\n>MH081806  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY263669  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>CY156156  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156220  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156148  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156348  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155916  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156284  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155980  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY150605  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY150628  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156076  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156116  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156204  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156244  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY030587  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY174707  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156188  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155972  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156364  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156140  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156172  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156012  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156092  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n                                                      genome\naccession                                                   \n>MH585251  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK715593  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK630441  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK771923  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK998974  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK625863  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK363749  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN155950  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN230511  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH584671  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH604853  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK554937  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK996139  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK999366  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN156206  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>MH583082  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH135911  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237470  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH585112  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK025806  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n...                                                      ...\n>CY255698  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY260228  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY265571  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY262538  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH081827  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n\n[327 rows x 1 columns]\n                                                      genome\naccession                                                   \n>MT342995  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT306934  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT315123  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT307198  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT242635  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT105778  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT030718  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT243884  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT105804  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>MK630401  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK715529  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK998758  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK998838  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK771960  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK857838  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK857846  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK363724  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK625876  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK363887  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK857902  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK996011  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN085778  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN156086  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN230591  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN086128  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN086160  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN318798  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>MH362873  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH362890  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH584023  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK771883  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK771899  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n...                                                      ...\n>MK676288  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK363919  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK244725  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH607106  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MK630380  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n\n[82 rows x 1 columns]\n                                                      genome\naccession                                                   \n>MH583314  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH583514  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH606778  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH585656  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH583887  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH363545  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n                                                      genome\naccession                                                   \n>MH606274  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH135954  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH080578  ATCTTCTCAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCTA...\n>CY265696  ATCTTCTCAAAAACTGAGGCAAGTAGGCCAAAAATGAACAATGCTA...\n>MH080726  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n...                                                      ...\n>MH081715  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH583870  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY260220  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH585792  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH585055  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n\n[140 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY221048  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY221056  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY225872  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY224336  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY222127  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY217492  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248457  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248955  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY248963  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY249011  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY229447  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY224360  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY225896  ATTTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>MN230239  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK998942  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK630449  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK771955  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK857854  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK995971  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK998966  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085634  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK625872  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085666  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN155958  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK772011  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK772019  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK630633  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK858038  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK858042  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK996123  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN156214  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n                                                      genome\naccession                                                   \n>CY155028  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY155156  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY154836  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY154740  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY150485  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY174395  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY174403  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY174443  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY155148  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY154908  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY155012  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY150389  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY154828  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY154988  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY155100  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY155252  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY150469  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY154868  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY150397  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY155396  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY155204  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY155140  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n                                                      genome\naccession                                                   \n>MN874017  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN245833  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MK742918  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MK946990  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MK911803  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN073867  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN080959  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN245849  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN245857  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN245865  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MK911811  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN245873  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN073875  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN073883  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN080967  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN080975  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MK947006  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN073899  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN080983  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN080991  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN154161  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN245881  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN656008  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN245889  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN874057  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n                                                      genome\naccession                                                   \n>MK998790  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN230281  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK999102  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK999110  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN085762  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN156006  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN085897  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN230553  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN230565  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN230575  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MN085930  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MT049898  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>MH726891  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH583461  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH585443  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH604717  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH606562  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH081778  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH136514  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH245780  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584991  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH363577  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>DQ508915  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>AY687396  AATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCT...\n>AY139067  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>DQ508923  ATGAACAATGCTACCTTCAACTGTACAAACATTAACCCTATTACTC...\n>AY139064  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n...                                                      ...\n>CY019605  TCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTC...\n>CY018759  TCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTC...\n>CY018839  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY018767  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY019533  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n\n[127 rows x 1 columns]\n                                                      genome\naccession                                                   \n>MT243077  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314867  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314875  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314883  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314891  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343111  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243133  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343165  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314987  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT314979  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343334  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343693  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343701  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343949  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243989  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343996  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MN085490  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MH363105  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN085594  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK715617  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MN230418  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MK999033  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MN085746  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MK558896  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK363858  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK363826  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK265484  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK363849  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK398389  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK363958  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK363864  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK398397  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK363716  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK625908  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK363774  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK363766  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK625920  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK630475  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MK630489  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MK630497  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MK630513  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MK857910  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK554901  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK554913  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK630553  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK999326  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MK999334  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MN086096  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAAATGAACAATGCTA...\n>MN086104  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>CY262810  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY264611  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>MH081030  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY262458  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY265765  ATCTTCTCAAAAGCTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY256623  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>CY258718  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n                                                      genome\naccession                                                   \n>CY152268  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY151867  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY151979  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY151987  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY152027  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY152051  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY151747  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY152107  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY152139  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY151819  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY152163  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY152203  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY152252  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY099947  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY099532  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY099907  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY099524  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY151611  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n                                                      genome\naccession                                                   \n>CY152292  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY152476  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY152580  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY152588  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY152604  AATAGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTA...\n...                                                      ...\n>CY038273  AGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTAACC...\n>CY040380  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY037385  AATAGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTA...\n>CY037393  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY038777  AAAATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTT...\n\n[165 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY197355  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY156940  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY196979  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY196891  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY196907  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY196987  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY175995  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY176011  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY176043  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY176139  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY176155  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY176203  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY176291  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197235  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197243  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197371  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197339  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197323  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY196971  CTTCTCAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGCTACC...\n>CY197259  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197195  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197219  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197227  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197163  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197171  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197179  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197131  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197107  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197779  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197787  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197795  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197803  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197843  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197851  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197819  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197123  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197115  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197139  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197147  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197155  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY198531  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY198571  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY198603  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY198611  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY198507  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY198587  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY198627  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY200315  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY199011  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY196931  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197307  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY196995  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY196883  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY196915  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197771  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197187  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY198051  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197051  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197947  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n                                                      genome\naccession                                                   \n>KX613489  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY116872  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX616480  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX616008  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX611934  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n...                                                      ...\n>KX613633  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX920562  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921090  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921098  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921658  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n\n[116 rows x 1 columns]\n                                                      genome\naccession                                                   \n>KT853639  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTA...\n>KT854025  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTA...\n>KT853846  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>KT853591  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>KT853599  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n...                                                      ...\n>KM100234  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>KM100237  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>KM100241  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>KT853811  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>KT853870  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n\n[64 rows x 1 columns]\n                                                      genome\naccession                                                   \n>KX007516  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY043827  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY042628  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX615272  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX615344  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX614433  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX006348  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX614758  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>MN589424  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN589456  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN589464  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN589472  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN589536  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN589544  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN589552  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN589576  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN589584  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n                                                      genome\naccession                                                   \n>KT853684  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>KT853773  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>KT854041  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>KT854061  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>KT854159  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n...                                                      ...\n>KT853551  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>KU592292  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>KU592372  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>KT853756  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>KT853741  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n\n[95 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY263995  CTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY263867  CTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY263971  CTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY188787  CTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182571  CTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182635  CTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182651  CTTCTCAAAACTGAAACAAATAGGCCAAAAAATGAACAATGCTACC...\n                                                      genome\naccession                                                   \n>CY263963  CTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTACCT...\n>MK961826  CTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY264011  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY263947  CTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTACCT...\n>MK961882  CTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182419  CTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182467  CTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182475  CTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182507  CTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182563  CTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182595  CTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182619  CTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182395  CTTCTCAAAACTGAAACAAATAGGCCAAAAATGAACAATGCTACCT...\n                                                      genome\naccession                                                   \n>CY099540  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY098872  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY100403  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY099556  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY100419  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY153780  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153516  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153676  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153692  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153604  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153564  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n                                                      genome\naccession                                                   \n>CY197835  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN588816  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTA...\n>MN588832  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN588872  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN588888  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN588912  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN588936  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN588944  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN588952  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN588968  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN588984  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589008  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589016  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589024  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589032  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589040  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589048  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589056  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589072  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589080  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589088  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589112  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589120  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MN589128  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>JX266944  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>JX266942  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KM100235  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KM100240  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>KJ577175  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n                                                      genome\naccession                                                   \n>CY200427  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY200435  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY200459  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY202587  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY200339  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY200091  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY200075  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n                                                      genome\naccession                                                   \n>CY150803  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156884  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156644  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156804  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY150148  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156876  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156612  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156748  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156796  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156492  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156484  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156892  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156652  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156668  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156708  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156724  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156788  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY152956  AACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTAT...\n>CY152980  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY152988  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156636  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156516  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156716  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156732  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156844  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n                                                      genome\naccession                                                   \n>CY198851  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199035  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199115  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199171  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199483  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199451  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199419  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199387  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY202563  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199835  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199699  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198899  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199083  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199027  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199707  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>MN819393  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819401  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881547  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049254  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049275  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049267  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049284  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049292  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029800  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029792  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057805  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030758  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315939  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315947  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881747  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881771  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MN949135  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT342799  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN638032  ATCTTCTCAAAACTGAAGCAAATAAGCCAAAAATGAACAATGCTAC...\n>MT029432  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881467  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949231  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049061  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN507158  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN230366  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN371675  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN435066  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN507166  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN638176  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819377  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN881531  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049195  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049187  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN949383  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049203  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029768  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029756  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029784  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243061  AGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACAAAC...\n>MT049324  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049316  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029935  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT029927  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819457  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819497  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057233  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT057244  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049435  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049428  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049443  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315499  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN819553  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN950271  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN950279  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049611  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030423  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030431  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT049619  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315627  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243701  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243717  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT343765  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT243765  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT315763  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT030686  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MN371739  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MT307254  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY149959  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153180  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY150098  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY152996  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153012  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153340  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153172  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY150033  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY150017  CTTCTCCAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153236  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153428  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY149975  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153076  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY150156  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY175307  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY175315  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY175339  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY175363  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY175371  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY175403  CTTCTCCAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY175411  CTTCTCCAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY175419  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY175427  CTTCTCCAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY175443  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY175475  CTTCTCCAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY175491  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY176363  CTTCTCCAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY150090  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153348  CTTCTCCAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153380  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153388  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153412  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153420  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153268  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153060  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n                                                      genome\naccession                                                   \n>CY155444  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155316  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155380  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155324  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155428  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155740  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155516  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155708  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155724  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155620  AAACTGAGGCAAATAGGCCCAAAATGAACAATGCTACCTTCAACTA...\n>CY150573  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY150565  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155644  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155260  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155244  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY150509  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155468  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155460  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155364  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155404  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155340  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155436  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155388  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155420  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n                                                      genome\naccession                                                   \n>CY201955  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY201859  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY201867  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY201803  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY201811  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n...                                                      ...\n>CY202467  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY202475  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY202515  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY202523  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY202531  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n\n[67 rows x 1 columns]\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>KX007081  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX615288  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921834  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX617665  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX612174  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGGACAATGCT...\n>KX616536  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX922170  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613417  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAATGAACAATGCTA...\n>MH080594  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY263479  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613609  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613617  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX919826  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX617016  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921530  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MH233794  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>KX612014  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX617272  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX617296  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY233554  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY209631  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAATGAACAATGCTA...\n>KY289855  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAATGAACAATGCTA...\n>CY211171  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAATGAACAATGCTA...\n>KY289852  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAATGAACAATGCTA...\n>KX612270  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY042485  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>KX614790  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>KX007337  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAAATGAACAATGC...\n>KY043114  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX615856  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX616104  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921922  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>KX922146  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX922154  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX920026  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX006969  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613553  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX617577  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX920258  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007706  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007741  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX006678  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX618185  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX006452  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY003662  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921474  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX921210  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX615432  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX615424  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX614566  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX006501  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY209615  ATCTTCTCAAAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCT...\n>KY289902  ATCTTCTCAAAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCT...\n>KX614486  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX612873  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX616392  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY003825  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY003815  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX919962  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY003706  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY003892  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX617729  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX922586  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX614912  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX920914  ATCTTCTCAAAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCT...\n>KY042298  ATCTTCTCAAAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613769  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613129  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY042802  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX614017  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>CY215380  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY217556  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY233978  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY218017  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY226464  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY221336  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY222239  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>MH363145  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH583497  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH581913  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH131061  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MG830635  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH081382  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584751  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH583709  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH233850  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH245620  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>MG830594  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH130853  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH581705  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH585259  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH245308  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH584343  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK025838  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MK025846  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH081500  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH233874  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH606858  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH581536  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH130684  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY265664  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>MH245812  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY188795  CTTCTCGAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY264027  CTTCTCGAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY263859  CTTCTCGAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY263987  CTTCTCGAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182427  CTTCTCGAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182451  CTTCTCGAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182499  CTTCTCGAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182611  CTTCTCGAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182627  CTTCTCGAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182643  CTTCTCGAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY182659  CTTCTCGAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n                                                      genome\naccession                                                   \n>LC033395  AGCAGAAGCAGAGCATCTTCTCAAAACTGAAGCAAATAGGCCAAAA...\n>KX007189  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY171809  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY171817  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY171825  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n...                                                      ...\n>KX615232  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY201483  CTTCTAAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>KX614089  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KY043080  ATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTAC...\n>KU592685  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n\n[117 rows x 1 columns]\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>CY154148  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154444  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154020  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154604  CTTCTCAAAACTGAAGCAAATAGGCAAAAAATGAACAATGCTACCT...\n>CY153468  CTTCTCAAAACTGAAGCAAATAGGCCAAAGATGAACAATGCTACCT...\n...                                                      ...\n>CY154412  CTTCTCAAAACTGAAGCAAATAGGCAAAAAATGAACAATGCTACCT...\n>CY153996  CTTCTCAAAACTGAAGCAAATGGGCCAAAAATGAACAATGCTACCT...\n>CY154188  CTTCTCAAAACTGAAGCAAATAGGCAAAAAATGAACAATGCTACCT...\n>CY154052  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY154092  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n\n[101 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY154772  TGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACA...\n>CY154780  TGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACA...\n>CY154940  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY154932  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY154948  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n...                                                      ...\n>CY018503  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY018335  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>CY019541  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY018695  AACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTAT...\n>CY018719  AAACTGAGGCAAATAGGCCAAAAATGGACAATGCTACCTTCAACTA...\n\n[73 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY172057  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199131  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY198075  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199531  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY198347  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY172113  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY172129  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY172161  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198819  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198259  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY198387  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY198395  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY198787  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n                                                      genome\naccession                                                   \n>CY199051  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY171801  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY171921  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY171985  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY172009  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n...                                                      ...\n>CY197019  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199931  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY197067  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY202579  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198323  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n\n[75 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY197011  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY197395  TTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY197403  TTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY197379  TTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197387  TTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY196963  TTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY196923  TTCTAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197707  TTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY196947  TTCTAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197331  TTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY197763  TTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY197059  TTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n                                                      genome\naccession                                                   \n>KX922498  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007578  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY230397  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY042903  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY224824  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n...                                                      ...\n>KX614169  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007113  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY233986  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY237653  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX006541  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n\n[67 rows x 1 columns]\n                                                      genome\naccession                                                   \n>KX007765  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007014  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007532  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007757  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613897  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX614718  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613777  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX006614  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY042326  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613009  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX614217  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>CY153228  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153188  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153084  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153276  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY150164  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY150140  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>FJ766839  AGCAGAAGCAGAGCATCTTCTCAAAACTGAAGCAAATAGGCCAAAA...\n>FJ766841  AGCAGAAGCAGAGCATCTTCTCAAAACTGAGGCAAATAGGCCAAAA...\n>CY115153  TCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY153092  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCC...\n>CY175355  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY175379  CTTCTCTAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY175435  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY175483  CTTCTCTAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY176371  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY175739  CTTCTCTAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153436  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>JX512984  TAGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTAAC...\n>JX513032  CAGAGCATCTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAA...\n>CY153140  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153372  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153404  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153540  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY150074  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153260  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY150066  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n                                                      genome\naccession                                                   \n>CY150049  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY150082  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY150115  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY149993  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY152948  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n...                                                      ...\n>CY154332  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY154532  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153020  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY150001  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY153132  CTTCTCAAAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCT...\n\n[108 rows x 1 columns]\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>CY155924  AACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTAT...\n>CY156508  AACTGAGGCAAATAAGCCAAAAATGAACAATGCTACCTTCAACTAT...\n>CY150707  AACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTAT...\n>CY156604  ACTGAGGCAAATAAGCCAAAAATGAACAATGCTACCTTCAACTATA...\n>MG869086  AGCAGAAGCAGAGCATCTTCTCAAAACTGAGGCAAATAGGCCAAAA...\n...                                                      ...\n>CY149967  AACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTAT...\n>CY040427  AATAGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTA...\n>CY038297  AACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTAT...\n>CY038305  GAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACAA...\n>CY038313  AACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTAT...\n\n[77 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY196862  ATGAACAATGCTACCTTCAACCATACAAACGTTAACCCTATTTCTC...\n>CY199963  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY198403  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY197907  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY200483  ATGAACAATGCTACCTTCAACTATACAAACGTTGACCCTATTTCTC...\n>CY199611  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY199619  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199763  CTTCTCAAAAGCTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199771  CTTCTCAAAAGCTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199075  CTTCTCAAAAGCTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY200019  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY199219  CTTCTCAAAAACTAAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199899  ATGAACAATGCTACCTTCAACTATACAAACATTAACCCTATTTCTC...\n>CY199923  ATGAACAATGCTACCTTCAACTATACAAACATTAACCCTATTTCTC...\n>CY199371  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAAAATGAACAATGCTA...\n>CY199779  ATGAACAATGCTACCTTCAACTATACAAACGTTGACCCTATTTCTC...\n>CY199675  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY196955  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN588920  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>MN589168  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY200163  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY198539  ATGAACAATGCTACCTTCAACTATACAAACATTAACCCTATTTCTC...\n>CY197555  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY197563  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY197571  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY196838  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY197435  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY197467  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY199019  ATGAACAATGCTACCTTCAACTATACAAACGTTGACCCTATTTCTC...\n>CY197043  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY197675  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY198107  ATGAACAATGCTACCTTCAACTATACAAACATTAACCCTATTTCTC...\n>JX266945  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>JX266946  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>JX266948  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>JX266947  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY199987  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY200067  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199107  ATGAACAATGCTACCTTCAACTATACAAACGTTGACCCTATTTCTC...\n>KM100251  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>KM100242  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>KM100249  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>KM100236  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>KM100238  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>KJ577167  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>KJ848692  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY199971  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTACTC...\n>CY199139  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199539  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY197283  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY199875  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY199867  ATGAACAATGCTACCTTCAACTATACAAACGTTGACCCTATTTCTC...\n>CY197955  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n                                                      genome\naccession                                                   \n>MK961794  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY264043  TCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTC...\n>MK961810  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>MK961818  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>MK961834  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>MK961850  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>MK961874  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY243310  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>MK961890  TCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTC...\n>CY243326  TCTAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTC...\n>CY243342  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCTTATTTCTC...\n>MK961898  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY243334  TAGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTAAC...\n>CY243302  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY243350  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>MK961914  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY201507  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY201611  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n                                                      genome\naccession                                                   \n>KX007297  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007305  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX613377  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX949118  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>MK361006  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007022  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX007140  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KU592600  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX006744  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX006752  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>KX615736  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX617657  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX617833  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX617793  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX919914  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX919938  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY003716  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY043430  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n                                                      genome\naccession                                                   \n>CY156756  AGGCCAAAGATGAACAATGCTACCTTCAACTATACAAACGTTAACC...\n>CY156180  AGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTAACC...\n>CY156212  AGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTAACC...\n>CY156388  AAACTGAGGCAAATAGGCCAAAAAATGAACAATGCTACCTTCAACT...\n>CY150787  AGGCCAAAGATGAACAATGCTACCTTCAACTATACAAACGTTAACC...\n>CY118357  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY119852  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY119868  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY119876  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY119892  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY119900  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY119916  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY119924  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY119932  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY119948  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY118404  GAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATACAA...\n>CY119956  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY119964  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY118412  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY119980  TCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAA...\n>CY155964  AGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTAACC...\n>CY150636  AGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTAACC...\n>CY155940  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156036  AGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTAACC...\n>CY033966  AGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTAACC...\n>CY156004  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "                                                      genome\naccession                                                   \n>CY156852  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155948  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY156452  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155956  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY155884  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n...                                                      ...\n>CY018303  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY018311  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY018319  AAACTGAAGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY018327  AATAGGCCAAAAATGAACAATGCTACCTTCAACTATACAAACGTTA...\n>CY037417  ACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTATA...\n\n[126 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY171849  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY171961  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY172097  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY200683  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY200467  CTTCTCAAAAGCTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198083  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY200523  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n>CY172153  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198115  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>LC032947  AGCAGAAGCAGAGCATCTTCTCAAAAAACTGAGGCAAATAGGCCAA...\n>LC033011  AGCAGAAGCAGAGCATCTTCTCAAAAACTGAGGCAAATAGGCCAAA...\n>LC033179  AGCAGAAGCAGAGCATCTTCTCAAAAAACTGAGGCAAATAGGCCAA...\n>LC033195  AGCAGAAGCAGAGCATCTTCTCAAAAAACTGAGGCAAATAGGCCAA...\n>LC033203  AGCAGAAGCAGAGCATCTTCTCAAAAAACTGAGGCAAATAGGCCAA...\n>LC033211  AGCAGAAGCAGAGCATCTTCTCAAAAACTGAGGCAAATAGGCCAAA...\n>LC033219  AGCAGAAGCAGAGCATCTTCTCAAAAAACTGAGGCAAATAGGCCAA...\n>LC033067  ATGAACAATGCTACCTTCAACTATACAAACGTTAACCCTATTTCTC...\n>CY200931  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY201163  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY201179  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY201283  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199523  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY202155  CTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTAC...\n                                                      genome\naccession                                                   \n>CY198203  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198987  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198995  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY171865  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY172089  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n...                                                      ...\n>CY198435  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199259  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199299  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY198427  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY199515  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n\n[126 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY200699  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY200707  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY200499  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>LC032939  AGCAGAAGCAGAGCATCTTCTCAAAAACTGAGGCAAATAGGCCAAA...\n>LC032955  AGCAGAAGCAGAGCATCTTCTCAAAAACTGAGGCAAATAGGCCAAA...\n>LC033019  AGCAGAAGCAGAGCATCTTCTCAAAAACTGAGGCAAATAGGCCAAA...\n>LC033035  AGCAGAAGCAGAGCATCTTCTCAAAAACTGAGGCAAATAGGCCAAA...\n>KR073617  AAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACTA...\n>CY191365  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY191349  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY191437  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY200587  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY201115  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY200259  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY201387  TCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTC...\n>CY200963  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY200971  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY201035  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY201051  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY201067  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY200299  AAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAAC...\n>CY201099  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY200195  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY200323  CTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACC...\n>CY200939  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY200955  TTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTT...\n>CY201379  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY201515  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n                                                      genome\naccession                                                   \n>CY200667  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY200723  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY200747  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY201467  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY201659  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n...                                                      ...\n>CY200851  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY200899  CTTCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCT...\n>CY201915  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY202379  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY201539  AAAACTGAGGCAACTAGGCCAAAAATGAACAATGCTACCTTCAACT...\n\n[64 rows x 1 columns]\n                                                      genome\naccession                                                   \n>CY201931  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>KX007546  ATCTTCTCAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTA...\n>LC033379  AGCAGAAGCAGAGCATCTTCTCAAAAAACTGAGGCAAATAGGCCAA...\n>CY200507  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY201651  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY201435  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY202019  TCTAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTC...\n>CY202003  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY202307  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n                                                      genome\naccession                                                   \n>KX613281  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX615104  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>CY201795  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>CY201851  TCTCAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTC...\n>CY201875  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n...                                                      ...\n>CY202547  AAAACTGAGGCAAATAGGCCAAAAATGAACAATGCTACCTTCAACT...\n>KY042492  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX614868  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KY043571  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n>KX614876  ATCTTCTCAAAAAACTGAGGCAAATAGGCCAAAAATGAACAATGCT...\n\n[144 rows x 1 columns]\nFinished.\n- Clustering done in 296.85 seconds.\n- 10417 sequences, 12 unclustered, 249 cluster.\n- Mean of inner cluster distance mean 0.0000511611\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nOverall execution time 296.85 seconds.\n"
       }
      ],
      "source": "def main():\n\n    print('Read input and settings file.', end = ' ')\n\n    infile = '../../B.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n    threads = 8\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    upload.query('curation == \"Pass\"', inplace = True)\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    mafft_dict = co.defaultdict(list)\n\n    exec_time = 0\n    increment = 0\n\n    print('Finished.')\n\n    segments = [6]\n    for segment in segments:\n\n        print(f'Starting calculations for segment {segment}:')\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        setting = [para if type(para) == str else para.item() for para in parameter]\n\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        subset.set_index('accession', inplace = True)\n\n        print('- Nucleotide k-mer frequency calculation.', end = ' ')\n\n        freq_nt = vectorizer(k = setting[0], convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = setting[1],\n            min_dist = setting[2],\n            n_components = setting[3],\n            random_state = setting[4],\n            metric = setting[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print('Finished.')\n\n        print('- Aminoacid k-mer frequency calculation.', end = ' ')\n\n        freq_aa = vectorizer(k = setting[6], convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = setting[7],\n            min_dist = setting[8],\n            n_components = setting[9],\n            random_state = setting[10],\n            metric = setting[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print('Finished.')\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print('- Running HDBscan for clustering.', end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = setting[12], #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = setting[13], #minimum size that can become a cluster\n            cluster_selection_epsilon = setting[14], #don't seperate clusters with a distance less than value\n            alpha = setting[15], #don't mess with this\n        ).fit(matrix)\n\n        print('Finished.')\n\n        print('- Centroid extraction and alignment creation.', end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['False'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['True']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        align_dict = co.defaultdict(list)\n        msa_dict = co.defaultdict(str)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = setting[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n            mafft_sub = subset.filter(items = match, axis=0)\n\n            fasta = mafft_sub[['genome']].copy()\n\n            fasta.to_csv('genome.fasta', header=None, index=True, sep='\\n', mode='w')\n\n            mafft_cline = MafftCommandline(input='genome.fasta', thread=threads)\n            stdout, stderr = mafft_cline()\n\n            for j in stdout.split('\\n'):\n                if j == '':\n                    pass\n                elif j[0] == '>':\n                    accession = j\n                else:\n                    msa_dict[accession] += j\n\n            alignment = pd.DataFrame.from_dict(msa_dict, orient='index', columns=['alignment'])\n            alignment.index.rename('accession', inplace=True)\n\n            msa_dict.clear()\n\n            align_dict[i] = alignment\n\n        mafft_dict[segment] = pd.concat(align_dict)\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print('Finished.')\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f'- Clustering done in {exec_clust:0.2f} seconds.')\n        diagnostic = co.Counter(clusterlabel)\n        print(f'- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.')\n        print(f'- Mean of inner cluster distance mean {overall_mean/num:0.10f}')\n        print(f'- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.')\n        print(f'- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.')\n        print('Finished.')\n\n    result_cluster = pd.concat(clusters)\n    result_cluster.index.set_names(['segment', 'accession'], inplace=True)\n    result_cluster.reset_index(level = 'segment', inplace=True)  \n    result_cluster.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result_cluster.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',', mode='w')\n\n    result_msa = pd.concat(mafft_dict)\n    result_msa.index.set_names(['segment', 'cluster', 'accession'], inplace=True)\n    result_msa.reset_index(level = ['segment', 'cluster'], inplace=True)  \n    result_msa.sort_values(by=['segment', 'cluster', 'accession', 'alignment'], inplace = True)\n    result_msa.to_csv(outpath + 'alignment.csv', index=True, header=True, sep=',', mode='w')\n\n    print(f'Overall execution time {exec_time:0.2f} seconds.')",
      "start_time": "2021-01-19T18:18:11.807Z"
     },
     {
      "end_time": "2021-01-19T18:27:41.821Z",
      "execution_time": "377ms",
      "outputs": [],
      "source": "def main():\n\n    print('Read input and settings file.', end = ' ')\n\n    infile = '../../A.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n    threads = 8\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    upload.query('curation == \"Pass\"', inplace = True)\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    mafft_dict = co.defaultdict(list)\n\n    exec_time = 0\n    increment = 0\n\n    print('Finished.')\n\n    #segments = [6]\n    for segment in segments:\n\n        print(f'Starting calculations for segment {segment}:')\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        setting = [para if type(para) == str else para.item() for para in parameter]\n\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        subset.set_index('accession', inplace = True)\n\n        print('- Nucleotide k-mer frequency calculation.', end = ' ')\n\n        freq_nt = vectorizer(k = setting[0], convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = setting[1],\n            min_dist = setting[2],\n            n_components = setting[3],\n            random_state = setting[4],\n            metric = setting[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print('Finished.')\n\n        print('- Aminoacid k-mer frequency calculation.', end = ' ')\n\n        freq_aa = vectorizer(k = setting[6], convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = setting[7],\n            min_dist = setting[8],\n            n_components = setting[9],\n            random_state = setting[10],\n            metric = setting[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print('Finished.')\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print('- Running HDBscan for clustering.', end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = setting[12], #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = setting[13], #minimum size that can become a cluster\n            cluster_selection_epsilon = setting[14], #don't seperate clusters with a distance less than value\n            alpha = setting[15], #don't mess with this\n        ).fit(matrix)\n\n        print('Finished.')\n\n        print('- Centroid extraction and alignment creation.', end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['False'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['True']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        align_dict = co.defaultdict(list)\n        msa_dict = co.defaultdict(str)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = setting[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n            mafft_sub = subset.filter(items = match, axis=0)\n\n            fasta = mafft_sub[['genome']].copy()\n\n            fasta.to_csv('genome.fasta', header=None, index=True, sep='\\n', mode='w')\n\n            mafft_cline = MafftCommandline(input='genome.fasta', thread=threads)\n            stdout, stderr = mafft_cline()\n\n            for j in stdout.split('\\n'):\n                if j == '':\n                    pass\n                elif j[0] == '>':\n                    accession = j\n                else:\n                    msa_dict[accession] += j\n\n            alignment = pd.DataFrame.from_dict(msa_dict, orient='index', columns=['alignment'])\n            alignment.index.rename('accession', inplace=True)\n\n            msa_dict.clear()\n\n            align_dict[i] = alignment\n\n        mafft_dict[segment] = pd.concat(align_dict)\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print('Finished.')\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f'- Clustering done in {exec_clust:0.2f} seconds.')\n        diagnostic = co.Counter(clusterlabel)\n        print(f'- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.')\n        print(f'- Mean of inner cluster distance mean {overall_mean/num:0.10f}')\n        print(f'- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.')\n        print(f'- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.')\n        print('Finished.')\n\n    result_cluster = pd.concat(clusters)\n    result_cluster.index.set_names(['segment', 'accession'], inplace=True)\n    result_cluster.reset_index(level = 'segment', inplace=True)  \n    result_cluster.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result_cluster.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',', mode='w')\n\n    result_msa = pd.concat(mafft_dict)\n    result_msa.index.set_names(['segment', 'cluster', 'accession'], inplace=True)\n    result_msa.reset_index(level = ['segment', 'cluster'], inplace=True)  \n    result_msa.sort_values(by=['segment', 'cluster', 'accession', 'alignment'], inplace = True)\n    result_msa.to_csv(outpath + 'alignment.csv', index=True, header=True, sep=',', mode='w')\n\n    print(f'Overall execution time {exec_time:0.2f} seconds.')",
      "start_time": "2021-01-19T18:27:41.444Z"
     },
     {
      "end_time": "2021-01-20T17:39:30.215Z",
      "execution_time": "394ms",
      "outputs": [],
      "source": "def main():\n\n    print('Read input and settings file.', end = ' ')\n\n    infile = '../../A.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n    threads = 8\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    upload.query('curation == \"Pass\"', inplace = True)\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    mafft_dict = co.defaultdict(list)\n\n    exec_time = 0\n    increment = 0\n\n    print('Finished.')\n\n    #segments = [6]\n    for segment in segments:\n\n        print(f'Starting calculations for segment {segment}:')\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        setting = [para if type(para) == str else para.item() for para in parameter]\n\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        subset.set_index('accession', inplace = True)\n\n        print('- Nucleotide k-mer frequency calculation.', end = ' ')\n\n        freq_nt = vectorizer(k = setting[0], convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = setting[1],\n            min_dist = setting[2],\n            n_components = setting[3],\n            random_state = setting[4],\n            metric = setting[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print('Finished.')\n\n        print('- Aminoacid k-mer frequency calculation.', end = ' ')\n\n        freq_aa = vectorizer(k = setting[6], convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = setting[7],\n            min_dist = setting[8],\n            n_components = setting[9],\n            random_state = setting[10],\n            metric = setting[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print('Finished.')\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print('- Running HDBscan for clustering.', end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = setting[12], #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = setting[13], #minimum size that can become a cluster\n            cluster_selection_epsilon = setting[14], #don't seperate clusters with a distance less than value\n            alpha = setting[15], #don't mess with this\n        ).fit(matrix)\n\n        print('Finished.')\n\n        print('- Centroid extraction and alignment.', end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['False'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['True']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        align_dict = co.defaultdict(list)\n        msa_dict = co.defaultdict(str)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = setting[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n            mafft_sub = subset.filter(items = match, axis=0)\n\n            fasta = mafft_sub[['genome']].copy()\n\n            fasta.to_csv('genome.fasta', header=None, index=True, sep='\\n', mode='w')\n\n            mafft_cline = MafftCommandline(input='genome.fasta', thread=threads)\n            stdout, stderr = mafft_cline()\n\n            for j in stdout.split('\\n'):\n                if j == '':\n                    pass\n                elif j[0] == '>':\n                    accession = j\n                else:\n                    msa_dict[accession] += j\n\n            alignment = pd.DataFrame.from_dict(msa_dict, orient='index', columns=['alignment'])\n            alignment.index.rename('accession', inplace=True)\n\n            msa_dict.clear()\n\n            align_dict[i] = alignment\n\n        mafft_dict[segment] = pd.concat(align_dict)\n        mafft_dict[segment]['cluster'] = mafft_dict[segment]['cluster'] + increment\n        \n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print('Finished.')\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f'- Clustering done in {exec_clust:0.2f} seconds.')\n        diagnostic = co.Counter(clusterlabel)\n        print(f'- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.')\n        print(f'- Mean of inner cluster distance mean {overall_mean/num:0.10f}')\n        print(f'- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.')\n        print(f'- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.')\n        print('Finished.')\n\n    result_cluster = pd.concat(clusters)\n    result_cluster.index.set_names(['segment', 'accession'], inplace=True)\n    result_cluster.reset_index(level = 'segment', inplace=True)  \n    result_cluster.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result_cluster.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',', mode='w')\n\n    result_msa = pd.concat(mafft_dict)\n    result_msa.index.set_names(['segment', 'cluster', 'accession'], inplace=True)\n    result_msa.reset_index(level = ['segment', 'cluster'], inplace=True)  \n    result_msa.sort_values(by=['segment', 'cluster', 'accession', 'alignment'], inplace = True)\n    result_msa.to_csv(outpath + 'alignment.csv', index=True, header=True, sep=',', mode='w')\n\n    print(f'Overall execution time {exec_time:0.2f} seconds.')",
      "start_time": "2021-01-20T17:39:29.821Z"
     },
     {
      "end_time": "2021-01-20T17:43:42.780Z",
      "execution_time": "342ms",
      "outputs": [],
      "source": "def main():\n\n    print('Read input and settings file.', end = ' ')\n\n    infile = '../../B.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n    threads = 8\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    upload.query('curation == \"Pass\"', inplace = True)\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    mafft_dict = co.defaultdict(list)\n\n    exec_time = 0\n    increment = 0\n\n    print('Finished.')\n\n    #segments = [6]\n    for segment in segments:\n\n        print(f'Starting calculations for segment {segment}:')\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        setting = [para if type(para) == str else para.item() for para in parameter]\n\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        subset.set_index('accession', inplace = True)\n\n        print('- Nucleotide k-mer frequency calculation.', end = ' ')\n\n        freq_nt = vectorizer(k = setting[0], convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = setting[1],\n            min_dist = setting[2],\n            n_components = setting[3],\n            random_state = setting[4],\n            metric = setting[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print('Finished.')\n\n        print('- Aminoacid k-mer frequency calculation.', end = ' ')\n\n        freq_aa = vectorizer(k = setting[6], convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = setting[7],\n            min_dist = setting[8],\n            n_components = setting[9],\n            random_state = setting[10],\n            metric = setting[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print('Finished.')\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print('- Running HDBscan for clustering.', end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = setting[12], #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = setting[13], #minimum size that can become a cluster\n            cluster_selection_epsilon = setting[14], #don't seperate clusters with a distance less than value\n            alpha = setting[15], #don't mess with this\n        ).fit(matrix)\n\n        print('Finished.')\n\n        print('- Centroid extraction and alignment.', end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['False'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['True']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        align_dict = co.defaultdict(list)\n        msa_dict = co.defaultdict(str)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = setting[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n            mafft_sub = subset.filter(items = match, axis=0)\n\n            fasta = mafft_sub[['genome']].copy()\n\n            fasta.to_csv('genome.fasta', header=None, index=True, sep='\\n', mode='w')\n\n            mafft_cline = MafftCommandline(input='genome.fasta', thread=threads)\n            stdout, stderr = mafft_cline()\n\n            for j in stdout.split('\\n'):\n                if j == '':\n                    pass\n                elif j[0] == '>':\n                    accession = j\n                else:\n                    msa_dict[accession] += j\n\n            alignment = pd.DataFrame.from_dict(msa_dict, orient='index', columns=['alignment'])\n            alignment.index.rename('accession', inplace=True)\n\n            msa_dict.clear()\n\n            align_dict[i] = alignment\n\n        mafft_dict[segment] = pd.concat(align_dict)\n        mafft_dict[segment]['cluster'] = mafft_dict[segment]['cluster'] + increment\n        \n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print('Finished.')\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f'- Clustering done in {exec_clust:0.2f} seconds.')\n        diagnostic = co.Counter(clusterlabel)\n        print(f'- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.')\n        print(f'- Mean of inner cluster distance mean {overall_mean/num:0.10f}')\n        print(f'- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.')\n        print(f'- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.')\n        print('Finished.')\n\n    result_cluster = pd.concat(clusters)\n    result_cluster.index.set_names(['segment', 'accession'], inplace=True)\n    result_cluster.reset_index(level = 'segment', inplace=True)  \n    result_cluster.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result_cluster.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',', mode='w')\n\n    result_msa = pd.concat(mafft_dict)\n    result_msa.index.set_names(['segment', 'cluster', 'accession'], inplace=True)\n    result_msa.reset_index(level = ['segment', 'cluster'], inplace=True)  \n    result_msa.sort_values(by=['segment', 'cluster', 'accession', 'alignment'], inplace = True)\n    result_msa.to_csv(outpath + 'alignment.csv', index=True, header=True, sep=',', mode='w')\n\n    print(f'Overall execution time {exec_time:0.2f} seconds.')",
      "start_time": "2021-01-20T17:43:42.438Z"
     },
     {
      "end_time": "2021-01-21T15:29:44.175Z",
      "execution_time": "5m 18s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment. "
       },
       {
        "ename": "KeyError",
        "evalue": "'cluster'",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
         "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
         "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
         "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
         "\u001b[0;31mKeyError\u001b[0m: 'cluster'",
         "\nThe above exception was the direct cause of the following exception:\n",
         "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-4-7c47e9eae56c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0mmafft_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malign_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0mmafft_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmafft_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mincrement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'centroid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mKeyError\u001b[0m: 'cluster'"
        ]
       }
      ],
      "source": "#def main():\n\nprint('Read input and settings file.', end = ' ')\n\ninfile = '../../B.csv'   \nsetfile = 'Input/settings.csv'\noutpath = 'Output/'\nthreads = 8\n\nsettings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\nupload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\nupload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\nupload.query('curation == \"Pass\"', inplace = True)\nsegments = settings.index.values.tolist()\nclusters = co.defaultdict(list)\nmafft_dict = co.defaultdict(list)\n\nexec_time = 0\nincrement = 0\n\nprint('Finished.')\n\n#segments = [6]\nfor segment in segments:\n\n    print(f'Starting calculations for segment {segment}:')\n\n    start_clust = time.perf_counter()\n    parameter = settings.loc[segment].to_list()\n    setting = [para if type(para) == str else para.item() for para in parameter]\n\n    subset = upload.query('segment == @segment').reset_index()\n\n    sequence = subset[['genome']].copy()\n    accession = subset[['accession']].copy()\n    subtype = subset[['subtype']].copy()\n\n    subset.set_index('accession', inplace = True)\n\n    print('- Nucleotide k-mer frequency calculation.', end = ' ')\n\n    freq_nt = vectorizer(k = setting[0], convert = 0)\n    freq_nt.adjust_to_data(sequence)\n    freq_nt.calculate_frequence(sequence)\n\n    matrix_nt = freq_nt.get_matrix()\n    keys_nt = freq_nt.get_keys()\n\n    del freq_nt\n\n    print('Finished.')\n\n    print('- Running UMAP for dimension reduction.', end = ' ')\n\n    matrix_nt_red = umap.UMAP(\n        n_neighbors = setting[1],\n        min_dist = setting[2],\n        n_components = setting[3],\n        random_state = setting[4],\n        metric = setting[5],\n    ).fit_transform(matrix_nt)\n\n    del matrix_nt\n\n    print('Finished.')\n\n    print('- Aminoacid k-mer frequency calculation.', end = ' ')\n\n    freq_aa = vectorizer(k = setting[6], convert = 1)\n    freq_aa.adjust_to_data(sequence)\n    freq_aa.calculate_frequence(sequence)\n\n    matrix_aa = freq_aa.get_matrix()\n    keys_aa = freq_aa.get_keys()\n\n    del freq_aa\n\n    print('Finished.')\n\n    print('- Running UMAP for dimension reduction.', end = ' ')\n\n    matrix_aa_red = umap.UMAP(\n        n_neighbors = setting[7],\n        min_dist = setting[8],\n        n_components = setting[9],\n        random_state = setting[10],\n        metric = setting[11],\n    ).fit_transform(matrix_aa)\n\n    del matrix_aa\n\n    print('Finished.')\n\n    matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n    print('- Running HDBscan for clustering.', end = ' ')\n\n    matrix_clust = hdbscan.HDBSCAN(\n        min_samples = setting[12], #larger the value the more conservative the clustering (more points will be declared as noise)\n        min_cluster_size = setting[13], #minimum size that can become a cluster\n        cluster_selection_epsilon = setting[14], #don't seperate clusters with a distance less than value\n        alpha = setting[15], #don't mess with this\n    ).fit(matrix)\n\n    print('Finished.')\n\n    print('- Centroid extraction and alignment.', end = ' ')\n\n    clusterlabel = matrix_clust.labels_\n\n    blank = pd.DataFrame(zip(clusterlabel, ['False'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n    clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n    num = clusters[segment]['cluster'].max()+1\n    values = ['True']*num\n    accessions = []\n    exclude = []\n    include = []\n    overall_mean=0\n    subs = co.defaultdict(list)\n\n    align_dict = co.defaultdict(list)\n    msa_dict = co.defaultdict(str)\n\n    for i in range(num):\n\n        query = clusters[segment].query('cluster == @i')\n        match = query.index.values.tolist()\n        sub = matrix.filter(items = match, axis=0)\n        dist = ssd.cdist(sub, sub, metric = setting[16])\n        inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n        accessions.append(inner_mean.idxmin())\n        overall_mean = overall_mean + inner_mean.mean()\n\n        for sub in query['subtype'].tolist():\n            if re.match('^[H][0-9]+N[0-9]+$', sub): \n                subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n            else:\n                subs['X'].append('X0')\n                subs['X'].append('X0')\n\n        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n            exclude.append(2)\n            if 'X' not in subs.keys():\n                include.append(2)\n        elif len(set(subs['H'])) == 1:\n            exclude.append(1)\n            if 'X' not in subs.keys():\n                include.append(1)\n        elif len(set(subs['N'])) == 1:\n            exclude.append(0)\n            if 'X' not in subs.keys():\n                include.append(0)\n\n        subs.clear()\n\n        mafft_sub = subset.filter(items = match, axis=0)\n\n        fasta = mafft_sub[['genome']].copy()\n\n        fasta.to_csv('genome.fasta', header=None, index=True, sep='\\n', mode='w')\n\n        mafft_cline = MafftCommandline(input='genome.fasta', thread=threads)\n        stdout, stderr = mafft_cline()\n\n        for j in stdout.split('\\n'):\n            if j == '':\n                pass\n            elif j[0] == '>':\n                accession = j\n            else:\n                msa_dict[accession] += j\n\n        alignment = pd.DataFrame.from_dict(msa_dict, orient='index', columns=['alignment'])\n        alignment.index.rename('accession', inplace=True)\n\n        msa_dict.clear()\n\n        align_dict[i] = alignment  \n\n    mafft_dict[segment] = pd.concat(align_dict)\n    mafft_dict[segment].index.set_names(['cluster', 'accession'], inplace=True)\n    mafft_dict[segment].reset_index(level = 'cluster', inplace=True)\n    mafft_dict[segment]['cluster'] = mafft_dict[segment]['cluster'] + increment\n\n    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n    clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n    clusters[segment].update(centroids)\n\n    increment += num - 1\n\n    print('Finished.')\n\n    stop_clust = time.perf_counter()\n    exec_clust = stop_clust - start_clust\n    exec_time = exec_time + exec_clust\n\n    print(f'- Clustering done in {exec_clust:0.2f} seconds.')\n    diagnostic = co.Counter(clusterlabel)\n    print(f'- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.')\n    print(f'- Mean of inner cluster distance mean {overall_mean/num:0.10f}')\n    print(f'- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.')\n    print(f'- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.')\n    print('Finished.')\n\nresult_cluster = pd.concat(clusters)\nresult_cluster.index.set_names(['segment', 'accession'], inplace=True)\nresult_cluster.reset_index(level = 'segment', inplace=True)  \nresult_cluster.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\nresult_cluster.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',', mode='w')\n\nresult_msa = pd.concat(mafft_dict)\nresult_msa.index.set_names(['segment', 'cluster', 'accession'], inplace=True)\nresult_msa.reset_index(level = ['segment', 'cluster'], inplace=True)  \nresult_msa.sort_values(by=['segment', 'cluster', 'accession', 'alignment'], inplace = True)\nresult_msa.to_csv(outpath + 'alignment.csv', index=True, header=True, sep=',', mode='w')\n\nprint(f'Overall execution time {exec_time:0.2f} seconds.')",
      "start_time": "2021-01-21T15:24:26.172Z"
     },
     {
      "end_time": "2021-01-21T15:31:38.666Z",
      "execution_time": "334ms",
      "outputs": [],
      "source": "def main():\n\n    print('Read input and settings file.', end = ' ')\n\n    infile = '../../B.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n    threads = 8\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    upload.query('curation == \"Pass\"', inplace = True)\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    mafft_dict = co.defaultdict(list)\n\n    exec_time = 0\n    increment = 0\n\n    print('Finished.')\n\n    #segments = [6]\n    for segment in segments:\n\n        print(f'Starting calculations for segment {segment}:')\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        setting = [para if type(para) == str else para.item() for para in parameter]\n\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        subset.set_index('accession', inplace = True)\n\n        print('- Nucleotide k-mer frequency calculation.', end = ' ')\n\n        freq_nt = vectorizer(k = setting[0], convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = setting[1],\n            min_dist = setting[2],\n            n_components = setting[3],\n            random_state = setting[4],\n            metric = setting[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print('Finished.')\n\n        print('- Aminoacid k-mer frequency calculation.', end = ' ')\n\n        freq_aa = vectorizer(k = setting[6], convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = setting[7],\n            min_dist = setting[8],\n            n_components = setting[9],\n            random_state = setting[10],\n            metric = setting[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print('Finished.')\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print('- Running HDBscan for clustering.', end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = setting[12], #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = setting[13], #minimum size that can become a cluster\n            cluster_selection_epsilon = setting[14], #don't seperate clusters with a distance less than value\n            alpha = setting[15], #don't mess with this\n        ).fit(matrix)\n\n        print('Finished.')\n\n        print('- Centroid extraction and alignment.', end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['False'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['True']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        align_dict = co.defaultdict(list)\n        msa_dict = co.defaultdict(str)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = setting[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n            mafft_sub = subset.filter(items = match, axis=0)\n\n            fasta = mafft_sub[['genome']].copy()\n\n            fasta.to_csv('genome.fasta', header=None, index=True, sep='\\n', mode='w')\n\n            mafft_cline = MafftCommandline(input='genome.fasta', thread=threads)\n            stdout, stderr = mafft_cline()\n\n            for j in stdout.split('\\n'):\n                if j == '':\n                    pass\n                elif j[0] == '>':\n                    accession = j\n                else:\n                    msa_dict[accession] += j\n\n            alignment = pd.DataFrame.from_dict(msa_dict, orient='index', columns=['alignment'])\n            alignment.index.rename('accession', inplace=True)\n\n            msa_dict.clear()\n\n            align_dict[i] = alignment  \n\n        mafft_dict[segment] = pd.concat(align_dict)\n        mafft_dict[segment].index.set_names(['cluster', 'accession'], inplace=True)\n        mafft_dict[segment].reset_index(level = 'cluster', inplace=True)\n        mafft_dict[segment]['cluster'] = mafft_dict[segment]['cluster'] + increment\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print('Finished.')\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f'- Clustering done in {exec_clust:0.2f} seconds.')\n        diagnostic = co.Counter(clusterlabel)\n        print(f'- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.')\n        print(f'- Mean of inner cluster distance mean {overall_mean/num:0.10f}')\n        print(f'- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.')\n        print(f'- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.')\n        print('Finished.')\n\n    result_cluster = pd.concat(clusters)\n    result_cluster.index.set_names(['segment', 'accession'], inplace=True)\n    result_cluster.reset_index(level = 'segment', inplace=True)  \n    result_cluster.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result_cluster.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',', mode='w')\n\n    result_msa = pd.concat(mafft_dict)\n    result_msa.index.set_names(['segment', 'cluster', 'accession'], inplace=True)\n    result_msa.reset_index(level = ['segment', 'cluster'], inplace=True)  \n    result_msa.sort_values(by=['segment', 'cluster', 'accession', 'alignment'], inplace = True)\n    result_msa.to_csv(outpath + 'alignment.csv', index=True, header=True, sep=',', mode='w')\n\n    print(f'Overall execution time {exec_time:0.2f} seconds.')",
      "start_time": "2021-01-21T15:31:38.332Z"
     },
     {
      "end_time": "2021-01-21T16:11:52.982Z",
      "execution_time": "333ms",
      "outputs": [],
      "source": "def main():\n\n    print('Read input and settings file.', end = ' ')\n\n    infile = '../../B.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n    threads = 8\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    upload.query('curation == \"Pass\"', inplace = True)\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    mafft_dict = co.defaultdict(list)\n\n    exec_time = 0\n    increment = 0\n\n    print('Finished.')\n\n    segments = [6]\n    for segment in segments:\n\n        print(f'Starting calculations for segment {segment}:')\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        setting = [para if type(para) == str else para.item() for para in parameter]\n\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        subset.set_index('accession', inplace = True)\n\n        print('- Nucleotide k-mer frequency calculation.', end = ' ')\n\n        freq_nt = vectorizer(k = setting[0], convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = setting[1],\n            min_dist = setting[2],\n            n_components = setting[3],\n            random_state = setting[4],\n            metric = setting[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print('Finished.')\n\n        print('- Aminoacid k-mer frequency calculation.', end = ' ')\n\n        freq_aa = vectorizer(k = setting[6], convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = setting[7],\n            min_dist = setting[8],\n            n_components = setting[9],\n            random_state = setting[10],\n            metric = setting[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print('Finished.')\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print('- Running HDBscan for clustering.', end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = setting[12], #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = setting[13], #minimum size that can become a cluster\n            cluster_selection_epsilon = setting[14], #don't seperate clusters with a distance less than value\n            alpha = setting[15], #don't mess with this\n        ).fit(matrix)\n\n        print('Finished.')\n\n        print('- Centroid extraction and alignment.', end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['False'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['True']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        align_dict = co.defaultdict(list)\n        msa_dict = co.defaultdict(str)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = setting[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n            mafft_sub = subset.filter(items = match, axis=0)\n\n            fasta = mafft_sub[['genome']].copy()\n\n            fasta.to_csv('genome.fasta', header=None, index=True, sep='\\n', mode='w')\n\n            mafft_cline = MafftCommandline(input='genome.fasta', thread=threads)\n            stdout, stderr = mafft_cline()\n\n            for j in stdout.split('\\n'):\n                if j == '':\n                    pass\n                elif j[0] == '>':\n                    accession = j\n                else:\n                    msa_dict[accession] += j\n\n            alignment = pd.DataFrame.from_dict(msa_dict, orient='index', columns=['alignment'])\n            alignment.index.rename('accession', inplace=True)\n\n            msa_dict.clear()\n\n            align_dict[i] = alignment  \n\n        mafft_dict[segment] = pd.concat(align_dict)\n        mafft_dict[segment].index.set_names(['cluster', 'accession'], inplace=True)\n        mafft_dict[segment].reset_index(level = 'cluster', inplace=True)\n        mafft_dict[segment]['cluster'] = mafft_dict[segment]['cluster'] + increment\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print('Finished.')\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f'- Clustering and alignment done in {exec_clust:0.2f} seconds.')\n        diagnostic = co.Counter(clusterlabel)\n        print(f'- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.')\n        print(f'- Mean of inner cluster distance mean {overall_mean/num:0.10f}')\n        print(f'- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.')\n        print(f'- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.')\n        print('Finished.')\n\n    result_cluster = pd.concat(clusters)\n    result_cluster.index.set_names(['segment', 'accession'], inplace=True)\n    result_cluster.reset_index(level = 'segment', inplace=True)  \n    result_cluster.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result_cluster.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',', mode='w')\n\n    result_msa = pd.concat(mafft_dict)\n    result_msa.index.set_names(['segment', 'accession'], inplace=True)\n    result_msa.reset_index(level = ['segment'], inplace=True)  \n    result_msa.sort_values(by=['segment', 'cluster', 'accession', 'alignment'], inplace = True)\n    result_msa.to_csv(outpath + 'alignment.csv', index=True, header=True, sep=',', mode='w')\n\n    print(f'Overall execution time {exec_time:0.2f} seconds.')",
      "start_time": "2021-01-21T16:11:52.649Z"
     },
     {
      "end_time": "2021-01-21T16:19:45.412Z",
      "execution_time": "340ms",
      "outputs": [],
      "source": "def main():\n\n    print('Read input and settings file.', end = ' ')\n\n    infile = '../../A.csv'   \n    setfile = 'Input/settings.csv'\n    outpath = 'Output/'\n    threads = 8\n\n    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n    upload.query('curation == \"Pass\"', inplace = True)\n    segments = settings.index.values.tolist()\n    clusters = co.defaultdict(list)\n    mafft_dict = co.defaultdict(list)\n\n    exec_time = 0\n    increment = 0\n\n    print('Finished.')\n\n    #segments = [6]\n    for segment in segments:\n\n        print(f'Starting calculations for segment {segment}:')\n\n        start_clust = time.perf_counter()\n        parameter = settings.loc[segment].to_list()\n        setting = [para if type(para) == str else para.item() for para in parameter]\n\n        subset = upload.query('segment == @segment').reset_index()\n\n        sequence = subset[['genome']].copy()\n        accession = subset[['accession']].copy()\n        subtype = subset[['subtype']].copy()\n\n        subset.set_index('accession', inplace = True)\n\n        print('- Nucleotide k-mer frequency calculation.', end = ' ')\n\n        freq_nt = vectorizer(k = setting[0], convert = 0)\n        freq_nt.adjust_to_data(sequence)\n        freq_nt.calculate_frequence(sequence)\n\n        matrix_nt = freq_nt.get_matrix()\n        keys_nt = freq_nt.get_keys()\n\n        del freq_nt\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_nt_red = umap.UMAP(\n            n_neighbors = setting[1],\n            min_dist = setting[2],\n            n_components = setting[3],\n            random_state = setting[4],\n            metric = setting[5],\n        ).fit_transform(matrix_nt)\n\n        del matrix_nt\n\n        print('Finished.')\n\n        print('- Aminoacid k-mer frequency calculation.', end = ' ')\n\n        freq_aa = vectorizer(k = setting[6], convert = 1)\n        freq_aa.adjust_to_data(sequence)\n        freq_aa.calculate_frequence(sequence)\n\n        matrix_aa = freq_aa.get_matrix()\n        keys_aa = freq_aa.get_keys()\n\n        del freq_aa\n\n        print('Finished.')\n\n        print('- Running UMAP for dimension reduction.', end = ' ')\n\n        matrix_aa_red = umap.UMAP(\n            n_neighbors = setting[7],\n            min_dist = setting[8],\n            n_components = setting[9],\n            random_state = setting[10],\n            metric = setting[11],\n        ).fit_transform(matrix_aa)\n\n        del matrix_aa\n\n        print('Finished.')\n\n        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n\n        print('- Running HDBscan for clustering.', end = ' ')\n\n        matrix_clust = hdbscan.HDBSCAN(\n            min_samples = setting[12], #larger the value the more conservative the clustering (more points will be declared as noise)\n            min_cluster_size = setting[13], #minimum size that can become a cluster\n            cluster_selection_epsilon = setting[14], #don't seperate clusters with a distance less than value\n            alpha = setting[15], #don't mess with this\n        ).fit(matrix)\n\n        print('Finished.')\n\n        print('- Centroid extraction and alignment.', end = ' ')\n\n        clusterlabel = matrix_clust.labels_\n\n        blank = pd.DataFrame(zip(clusterlabel, ['False'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n\n        num = clusters[segment]['cluster'].max()+1\n        values = ['True']*num\n        accessions = []\n        exclude = []\n        include = []\n        overall_mean=0\n        subs = co.defaultdict(list)\n\n        align_dict = co.defaultdict(list)\n        msa_dict = co.defaultdict(str)\n\n        for i in range(num):\n\n            query = clusters[segment].query('cluster == @i')\n            match = query.index.values.tolist()\n            sub = matrix.filter(items = match, axis=0)\n            dist = ssd.cdist(sub, sub, metric = setting[16])\n            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n            accessions.append(inner_mean.idxmin())\n            overall_mean = overall_mean + inner_mean.mean()\n\n            for sub in query['subtype'].tolist():\n                if re.match('^[H][0-9]+N[0-9]+$', sub): \n                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n                else:\n                    subs['X'].append('X0')\n                    subs['X'].append('X0')\n\n            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n                exclude.append(2)\n                if 'X' not in subs.keys():\n                    include.append(2)\n            elif len(set(subs['H'])) == 1:\n                exclude.append(1)\n                if 'X' not in subs.keys():\n                    include.append(1)\n            elif len(set(subs['N'])) == 1:\n                exclude.append(0)\n                if 'X' not in subs.keys():\n                    include.append(0)\n\n            subs.clear()\n\n            mafft_sub = subset.filter(items = match, axis=0)\n\n            fasta = mafft_sub[['genome']].copy()\n\n            fasta.to_csv('genome.fasta', header=None, index=True, sep='\\n', mode='w')\n\n            mafft_cline = MafftCommandline(input='genome.fasta', thread=threads)\n            stdout, stderr = mafft_cline()\n\n            for j in stdout.split('\\n'):\n                if j == '':\n                    pass\n                elif j[0] == '>':\n                    accession = j\n                else:\n                    msa_dict[accession] += j\n\n            alignment = pd.DataFrame.from_dict(msa_dict, orient='index', columns=['alignment'])\n            alignment.index.rename('accession', inplace=True)\n\n            msa_dict.clear()\n\n            align_dict[i] = alignment  \n\n        mafft_dict[segment] = pd.concat(align_dict)\n        mafft_dict[segment].index.set_names(['cluster', 'accession'], inplace=True)\n        mafft_dict[segment].reset_index(level = 'cluster', inplace=True)\n        mafft_dict[segment]['cluster'] = mafft_dict[segment]['cluster'] + increment\n\n        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n\n        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n        clusters[segment].update(centroids)\n\n        increment += num - 1\n\n        print('Finished.')\n\n        stop_clust = time.perf_counter()\n        exec_clust = stop_clust - start_clust\n        exec_time = exec_time + exec_clust\n\n        print(f'- Clustering and alignment done in {exec_clust:0.2f} seconds.')\n        diagnostic = co.Counter(clusterlabel)\n        print(f'- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.')\n        print(f'- Mean of inner cluster distance mean {overall_mean/num:0.10f}')\n        print(f'- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.')\n        print(f'- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.')\n        print('Finished.')\n\n    result_cluster = pd.concat(clusters)\n    result_cluster.index.set_names(['segment', 'accession'], inplace=True)\n    result_cluster.reset_index(level = 'segment', inplace=True)  \n    result_cluster.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n    result_cluster.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',', mode='w')\n\n    result_msa = pd.concat(mafft_dict)\n    result_msa.index.set_names(['segment', 'accession'], inplace=True)\n    result_msa.reset_index(level = ['segment'], inplace=True)  \n    result_msa.sort_values(by=['segment', 'cluster', 'accession', 'alignment'], inplace = True)\n    result_msa.to_csv(outpath + 'alignment.csv', index=True, header=True, sep=',', mode='w')\n\n    print(f'Overall execution time {exec_time:0.2f} seconds.')",
      "start_time": "2021-01-21T16:19:45.072Z"
     }
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    print('Read input and settings file.', end = ' ')\n",
    "\n",
    "    infile = '../../A.csv'   \n",
    "    setfile = 'Input/settings.csv'\n",
    "    outpath = 'Output/'\n",
    "    threads = 8\n",
    "\n",
    "    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n",
    "    upload = pd.read_csv(infile, sep = ',', na_filter = False, header = None)\n",
    "    upload.columns = ['accession', 'strain', 'segment', 'protein', 'genus', 'subtype', 'date', 'host', 'curation', 'genome']\n",
    "    upload.query('curation == \"Pass\"', inplace = True)\n",
    "    segments = settings.index.values.tolist()\n",
    "    clusters = co.defaultdict(list)\n",
    "    mafft_dict = co.defaultdict(list)\n",
    "\n",
    "    exec_time = 0\n",
    "    increment = 0\n",
    "\n",
    "    print('Finished.')\n",
    "\n",
    "    #segments = [6]\n",
    "    for segment in segments:\n",
    "\n",
    "        print(f'Starting calculations for segment {segment}:')\n",
    "\n",
    "        start_clust = time.perf_counter()\n",
    "        parameter = settings.loc[segment].to_list()\n",
    "        setting = [para if type(para) == str else para.item() for para in parameter]\n",
    "\n",
    "        subset = upload.query('segment == @segment').reset_index()\n",
    "\n",
    "        sequence = subset[['genome']].copy()\n",
    "        accession = subset[['accession']].copy()\n",
    "        subtype = subset[['subtype']].copy()\n",
    "\n",
    "        subset.set_index('accession', inplace = True)\n",
    "\n",
    "        print('- Nucleotide k-mer frequency calculation.', end = ' ')\n",
    "\n",
    "        freq_nt = vectorizer(k = setting[0], convert = 0)\n",
    "        freq_nt.adjust_to_data(sequence)\n",
    "        freq_nt.calculate_frequence(sequence)\n",
    "\n",
    "        matrix_nt = freq_nt.get_matrix()\n",
    "        keys_nt = freq_nt.get_keys()\n",
    "\n",
    "        del freq_nt\n",
    "\n",
    "        print('Finished.')\n",
    "\n",
    "        print('- Running UMAP for dimension reduction.', end = ' ')\n",
    "\n",
    "        matrix_nt_red = umap.UMAP(\n",
    "            n_neighbors = setting[1],\n",
    "            min_dist = setting[2],\n",
    "            n_components = setting[3],\n",
    "            random_state = setting[4],\n",
    "            metric = setting[5],\n",
    "        ).fit_transform(matrix_nt)\n",
    "\n",
    "        del matrix_nt\n",
    "\n",
    "        print('Finished.')\n",
    "\n",
    "        print('- Aminoacid k-mer frequency calculation.', end = ' ')\n",
    "\n",
    "        freq_aa = vectorizer(k = setting[6], convert = 1)\n",
    "        freq_aa.adjust_to_data(sequence)\n",
    "        freq_aa.calculate_frequence(sequence)\n",
    "\n",
    "        matrix_aa = freq_aa.get_matrix()\n",
    "        keys_aa = freq_aa.get_keys()\n",
    "\n",
    "        del freq_aa\n",
    "\n",
    "        print('Finished.')\n",
    "\n",
    "        print('- Running UMAP for dimension reduction.', end = ' ')\n",
    "\n",
    "        matrix_aa_red = umap.UMAP(\n",
    "            n_neighbors = setting[7],\n",
    "            min_dist = setting[8],\n",
    "            n_components = setting[9],\n",
    "            random_state = setting[10],\n",
    "            metric = setting[11],\n",
    "        ).fit_transform(matrix_aa)\n",
    "\n",
    "        del matrix_aa\n",
    "\n",
    "        print('Finished.')\n",
    "\n",
    "        matrix = pd.concat([accession, pd.DataFrame(matrix_aa_red), pd.DataFrame(matrix_nt_red)], axis=1, copy = False, ignore_index = False).set_index('accession')\n",
    "\n",
    "        print('- Running HDBscan for clustering.', end = ' ')\n",
    "\n",
    "        matrix_clust = hdbscan.HDBSCAN(\n",
    "            min_samples = setting[12], #larger the value the more conservative the clustering (more points will be declared as noise)\n",
    "            min_cluster_size = setting[13], #minimum size that can become a cluster\n",
    "            cluster_selection_epsilon = setting[14], #don't seperate clusters with a distance less than value\n",
    "            alpha = setting[15], #don't mess with this\n",
    "        ).fit(matrix)\n",
    "\n",
    "        print('Finished.')\n",
    "\n",
    "        print('- Centroid extraction and alignment.', end = ' ')\n",
    "\n",
    "        clusterlabel = matrix_clust.labels_\n",
    "\n",
    "        blank = pd.DataFrame(zip(clusterlabel, ['False'] * len(clusterlabel)), columns = ['cluster', 'centroid'])\n",
    "        clusters[segment] = pd.concat([blank, subtype, accession], axis=1, copy = False).set_index('accession')\n",
    "\n",
    "        num = clusters[segment]['cluster'].max()+1\n",
    "        values = ['True']*num\n",
    "        accessions = []\n",
    "        exclude = []\n",
    "        include = []\n",
    "        overall_mean=0\n",
    "        subs = co.defaultdict(list)\n",
    "\n",
    "        align_dict = co.defaultdict(list)\n",
    "        msa_dict = co.defaultdict(str)\n",
    "\n",
    "        for i in range(num):\n",
    "\n",
    "            query = clusters[segment].query('cluster == @i')\n",
    "            match = query.index.values.tolist()\n",
    "            sub = matrix.filter(items = match, axis=0)\n",
    "            dist = ssd.cdist(sub, sub, metric = setting[16])\n",
    "            inner_mean = pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean()\n",
    "            accessions.append(inner_mean.idxmin())\n",
    "            overall_mean = overall_mean + inner_mean.mean()\n",
    "\n",
    "            for sub in query['subtype'].tolist():\n",
    "                if re.match('^[H][0-9]+N[0-9]+$', sub): \n",
    "                    subs['H'].append(re.search('[H][0-9]+', sub).group(0))\n",
    "                    subs['N'].append(re.search('[N][0-9]+', sub).group(0))\n",
    "                else:\n",
    "                    subs['X'].append('X0')\n",
    "                    subs['X'].append('X0')\n",
    "\n",
    "            if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n",
    "                exclude.append(2)\n",
    "                if 'X' not in subs.keys():\n",
    "                    include.append(2)\n",
    "            elif len(set(subs['H'])) == 1:\n",
    "                exclude.append(1)\n",
    "                if 'X' not in subs.keys():\n",
    "                    include.append(1)\n",
    "            elif len(set(subs['N'])) == 1:\n",
    "                exclude.append(0)\n",
    "                if 'X' not in subs.keys():\n",
    "                    include.append(0)\n",
    "\n",
    "            subs.clear()\n",
    "\n",
    "            mafft_sub = subset.filter(items = match, axis=0)\n",
    "\n",
    "            fasta = mafft_sub[['genome']].copy()\n",
    "\n",
    "            fasta.to_csv('genome.fasta', header=None, index=True, sep='\\n', mode='w')\n",
    "\n",
    "            mafft_cline = MafftCommandline(input='genome.fasta', thread=threads)\n",
    "            stdout, stderr = mafft_cline()\n",
    "\n",
    "            for j in stdout.split('\\n'):\n",
    "                if j == '':\n",
    "                    pass\n",
    "                elif j[0] == '>':\n",
    "                    accession = j\n",
    "                else:\n",
    "                    msa_dict[accession] += j\n",
    "\n",
    "            alignment = pd.DataFrame.from_dict(msa_dict, orient='index', columns=['alignment'])\n",
    "            alignment.index.rename('accession', inplace=True)\n",
    "\n",
    "            msa_dict.clear()\n",
    "\n",
    "            align_dict[i] = alignment  \n",
    "\n",
    "        mafft_dict[segment] = pd.concat(align_dict)\n",
    "        mafft_dict[segment].index.set_names(['cluster', 'accession'], inplace=True)\n",
    "        mafft_dict[segment].reset_index(level = 'cluster', inplace=True)\n",
    "        mafft_dict[segment]['cluster'] = mafft_dict[segment]['cluster'] + increment\n",
    "\n",
    "        centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n",
    "\n",
    "        clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] = clusters[segment].loc[clusters[segment]['cluster'] != -1, ['cluster']] + increment\n",
    "        clusters[segment].update(centroids)\n",
    "\n",
    "        increment += num - 1\n",
    "\n",
    "        print('Finished.')\n",
    "\n",
    "        stop_clust = time.perf_counter()\n",
    "        exec_clust = stop_clust - start_clust\n",
    "        exec_time = exec_time + exec_clust\n",
    "\n",
    "        print(f'- Clustering and alignment done in {exec_clust:0.2f} seconds.')\n",
    "        diagnostic = co.Counter(clusterlabel)\n",
    "        print(f'- {str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.')\n",
    "        print(f'- Mean of inner cluster distance mean {overall_mean/num:0.10f}')\n",
    "        print(f'- {exclude.count(0) + exclude.count(2)}({include.count(0) + include.count(2)}) clusters containing matching NA types.')\n",
    "        print(f'- {exclude.count(1) + exclude.count(2)}({include.count(1) + include.count(2)}) clusters containing matching HA types.')\n",
    "        print('Finished.')\n",
    "\n",
    "    result_cluster = pd.concat(clusters)\n",
    "    result_cluster.index.set_names(['segment', 'accession'], inplace=True)\n",
    "    result_cluster.reset_index(level = 'segment', inplace=True)  \n",
    "    result_cluster.sort_values(by=['segment', 'cluster', 'subtype'], inplace = True)\n",
    "    result_cluster.to_csv(outpath + 'cluster.csv', index=True, header=True, sep=',', mode='w')\n",
    "\n",
    "    result_msa = pd.concat(mafft_dict)\n",
    "    result_msa.index.set_names(['segment', 'accession'], inplace=True)\n",
    "    result_msa.reset_index(level = ['segment'], inplace=True)  \n",
    "    result_msa.sort_values(by=['segment', 'cluster', 'accession', 'alignment'], inplace = True)\n",
    "    result_msa.to_csv(outpath + 'alignment.csv', index=True, header=True, sep=',', mode='w')\n",
    "\n",
    "    print(f'Overall execution time {exec_time:0.2f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecutionTime": {
     "end_time": "2021-01-21T20:09:51.517851Z",
     "start_time": "2021-01-21T16:19:45.783913Z"
    },
    "provenance": [
     {
      "end_time": "Unknown",
      "execution_time": "Unknown",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nCreating SQL tables. "
       },
       {
        "ename": "IndexError",
        "evalue": "list index out of range",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
         "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-2-6bbd2fe1518b>\", line 72, in process_rows\n    organism = head[4]\nIndexError: list index out of range\n\"\"\"",
         "\nThe above exception was the direct cause of the following exception:\n",
         "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-7-73bda965d2e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
         "\u001b[0;32m<ipython-input-6-653664b12606>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworldfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mintab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accession'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'subtype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'genome'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accession'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m<ipython-input-2-6bbd2fe1518b>\u001b[0m in \u001b[0;36minput_sequences\u001b[0;34m(self, infile, procs)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitertuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mIndexError\u001b[0m: list index out of range"
        ]
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    main()",
      "start_time": "Unknown"
     },
     {
      "end_time": "2021-01-17T17:17:23.299Z",
      "execution_time": "250ms",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nNucleotide k-mer frequency calculation. "
       },
       {
        "ename": "UnboundLocalError",
        "evalue": "local variable 'seq' referenced before assignment",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-4-73bda965d2e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
         "\u001b[0;32m<ipython-input-3-91f2f3134950>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mfreq_nt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mfreq_nt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_to_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mfreq_nt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_frequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m<ipython-input-2-a3ce8d3a10f4>\u001b[0m in \u001b[0;36madjust_to_data\u001b[0;34m(self, infile)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mdel\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_frequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'seq' referenced before assignment"
        ]
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    main()",
      "start_time": "2021-01-17T17:17:23.049Z"
     },
     {
      "end_time": "2021-01-17T17:19:18.598Z",
      "execution_time": "144ms",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nNucleotide k-mer frequency calculation. "
       },
       {
        "ename": "UnboundLocalError",
        "evalue": "local variable 'seq' referenced before assignment",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-7-73bda965d2e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
         "\u001b[0;32m<ipython-input-6-91f2f3134950>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mfreq_nt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mfreq_nt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_to_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mfreq_nt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_frequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m<ipython-input-5-955e0dcf5285>\u001b[0m in \u001b[0;36madjust_to_data\u001b[0;34m(self, infile)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mdel\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_frequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'seq' referenced before assignment"
        ]
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    main()",
      "start_time": "2021-01-17T17:19:18.454Z"
     },
     {
      "end_time": "2021-01-17T17:20:47.706Z",
      "execution_time": "143ms",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nNucleotide k-mer frequency calculation. "
       },
       {
        "ename": "UnboundLocalError",
        "evalue": "local variable 'seq' referenced before assignment",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-10-73bda965d2e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
         "\u001b[0;32m<ipython-input-9-91f2f3134950>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mfreq_nt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mfreq_nt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_to_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mfreq_nt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_frequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m<ipython-input-8-4ba4d11f7e41>\u001b[0m in \u001b[0;36madjust_to_data\u001b[0;34m(self, infile)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mdel\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_frequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'seq' referenced before assignment"
        ]
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    main()",
      "start_time": "2021-01-17T17:20:47.563Z"
     },
     {
      "end_time": "2021-01-17T17:21:26.655Z",
      "execution_time": "153ms",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nNucleotide k-mer frequency calculation. Empty DataFrame\nColumns: [genome]\nIndex: []\n"
       },
       {
        "ename": "UnboundLocalError",
        "evalue": "local variable 'seq' referenced before assignment",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-12-73bda965d2e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
         "\u001b[0;32m<ipython-input-11-57f1a7fa5f04>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mfreq_nt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mfreq_nt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_to_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mfreq_nt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_frequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m<ipython-input-8-4ba4d11f7e41>\u001b[0m in \u001b[0;36madjust_to_data\u001b[0;34m(self, infile)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mdel\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_frequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'seq' referenced before assignment"
        ]
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    main()",
      "start_time": "2021-01-17T17:21:26.502Z"
     },
     {
      "end_time": "2021-01-17T17:26:32.796Z",
      "execution_time": "2m 30s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nNucleotide k-mer frequency calculation.                                                   genome\n0      ATGAATATAAATCCTTATTTTCTCTTCATAGATGTGCCCGTACAGG...\n1      ATGAATATAAATCCGTATTTTCTATTCATAGATGTACCTATACAGG...\n2      CTTTAAGATGAATATAAATCCTTATTTTCTCTTCATAGATGTGCCC...\n3      CTTTAAGATGAATATAAATCCGTATTTTCTATTCATAGATGTACCT...\n4      CTTTAAGATGAATATAAATCCTTATTTTCTCTTCATAGATGTGCCC...\n...                                                  ...\n10376  CTTTAAGATGAATATAAATCCTTATTTTCTCTTCATAGATGTGCCC...\n10377  GATGAATATAAATCCTTATTTTCTCTTCATAGATGTACCCATACAG...\n10378  GATGAATATAAATCCTTATTTTCTCTTCATAGATGTACCCATACAG...\n10379  ATGAATATAAATCCTTATTTTCTCTTCATAGATGTACCCATACAGG...\n10380  CTTTAAGATGAATATAAATCCTTATTTTCTCTTCATAGATGTACCC...\n\n[10381 rows x 1 columns]\nFinished.\nRunning UMAP for dimension reduction. Finished.\nAminoacid k-mer frequency calculation. Finished.\nRunning UMAP for dimension reduction. Finished.\nRunning HDBscan for clustering. Finished.\nCentroid extraction. "
       },
       {
        "ename": "NameError",
        "evalue": "name 'ssd' is not defined",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-4-73bda965d2e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
         "\u001b[0;32m<ipython-input-3-a2ac216f60ef>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mssd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0minner_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0maccessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mNameError\u001b[0m: name 'ssd' is not defined"
        ]
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    main()",
      "start_time": "2021-01-17T17:24:02.779Z"
     },
     {
      "end_time": "2021-01-17T18:11:28.662Z",
      "execution_time": "19m 32s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nNucleotide k-mer frequency calculation. Finished.\nRunning UMAP for dimension reduction. Finished.\nAminoacid k-mer frequency calculation. Finished.\nRunning UMAP for dimension reduction. Finished.\nRunning HDBscan for clustering. Finished.\nCentroid extraction. Finished.\nClustering done in 1168.1290 seconds.\n55999 sequences, 275 unclustered, 1300 cluster.\nMean of inner cluster distance mean 2.7103107300434113e-05\n848(795) clusters containing matching NA types.\n871(808) clusters containing matching HA types.\n"
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    main()",
      "start_time": "2021-01-17T17:51:56.642Z"
     },
     {
      "end_time": "2021-01-17T18:22:09.675Z",
      "execution_time": "14ms",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. "
       },
       {
        "ename": "NameError",
        "evalue": "name 'f' is not defined",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-22-73bda965d2e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
         "\u001b[0;32m<ipython-input-21-d3e207e7a989>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read input and settings file.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0minfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Input/A_HA_sample.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msetfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Input/settings.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mNameError\u001b[0m: name 'f' is not defined"
        ]
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    main()",
      "start_time": "2021-01-17T18:22:09.661Z"
     },
     {
      "end_time": "2021-01-17T18:24:00.728Z",
      "execution_time": "171ms",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\n"
       },
       {
        "ename": "UnboundLocalError",
        "evalue": "local variable 'segment' referenced before assignment",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-24-ec55abb246c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#main()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Maximum memory used: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/memory_profiler.py\u001b[0m in \u001b[0;36mmemory_usage\u001b[0;34m(proc, interval, timeout, timestamps, include_children, multiprocess, max_usage, retval, stream, backend, max_iterations)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Therefore, the whole process hangs indefinitely. Here, we are ensuring that the process gets killed!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 \u001b[0mreturned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m                 \u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# finish timing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m<ipython-input-23-3b727354fed4>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Starting calculations for segment {segment}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mstart_clust\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'segment' referenced before assignment"
        ]
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    memory = memory_usage(main)\n    #main()\n    print(\"Maximum memory used: %s\" % max(memory))",
      "start_time": "2021-01-17T18:24:00.557Z"
     },
     {
      "end_time": "2021-01-17T18:27:11.585Z",
      "execution_time": "2m 52s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 4.\nNucleotide k-mer frequency calculation. Finished.\nRunning UMAP for dimension reduction. Finished.\nAminoacid k-mer frequency calculation. Finished.\nRunning UMAP for dimension reduction. Finished.\nRunning HDBscan for clustering. Finished.\nCentroid extraction. Finished.\nClustering done in 171.7212 seconds.\n10000 sequences, 0 unclustered, 174 cluster.\nMean of inner cluster distance mean 8.321637921018586e-05\n118(104) clusters containing matching NA types.\n171(121) clusters containing matching HA types.\nMaximum memory used: 3453.1796875\n"
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    #main()\n    memory = memory_usage(main)\n    print(\"Maximum memory used: %s\" % max(memory))",
      "start_time": "2021-01-17T18:24:19.692Z"
     },
     {
      "end_time": "2021-01-17T18:56:42.288Z",
      "execution_time": "20m 3s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 4:\nNucleotide k-mer frequency calculation. Finished.\nRunning UMAP for dimension reduction. Finished.\nAminoacid k-mer frequency calculation. Finished.\nRunning UMAP for dimension reduction. Finished.\nRunning HDBscan for clustering. Finished.\nCentroid extraction. Finished.\nClustering done in 1198.7109 seconds.\n56617 sequences, 36 unclustered, 1052 cluster.\nMean of inner cluster distance mean 0.0000974158\n779(692) clusters containing matching NA types.\n1048(787) clusters containing matching HA types.\nMaximum memory used: 16254.1406Mb.\n"
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    #main()\n    memory = memory_usage(main)\n    print(f\"Maximum memory used: {max(memory):0.4f}Mb.\")",
      "start_time": "2021-01-17T18:36:39.564Z"
     },
     {
      "end_time": "2021-01-18T11:20:14.555Z",
      "execution_time": "48ms",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. "
       },
       {
        "ename": "FileNotFoundError",
        "evalue": "[Errno 2] No such file or directory: 'Input/A.csv'",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-26-0bf07cfe1ecf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#main()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/memory_profiler.py\u001b[0m in \u001b[0;36mmemory_usage\u001b[0;34m(proc, interval, timeout, timestamps, include_children, multiprocess, max_usage, retval, stream, backend, max_iterations)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Therefore, the whole process hangs indefinitely. Here, we are ensuring that the process gets killed!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 \u001b[0mreturned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m                 \u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# finish timing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m<ipython-input-25-3d5d076e5859>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msettings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_filter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mupload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_filter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0msegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
         "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
         "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Input/A.csv'"
        ]
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    #main()\n    memory = memory_usage(main)\n    print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-18T11:20:14.507Z"
     },
     {
      "end_time": "2021-01-18T11:42:15.970Z",
      "execution_time": "19m 32s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\n Starting calculations for segment 1:\n Nucleotide k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Aminoacid k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Running HDBscan for clustering. Finished.\n Centroid extraction. Finished.\n Clustering done in 162.44 seconds.\n 10382 sequences, 6 unclustered, 239 cluster.\n Mean of inner cluster distance mean 0.0001108158\n 0(0) clusters containing matching NA types.\n 0(0) clusters containing matching HA types.\n Starting calculations for segment 2:\n Nucleotide k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Aminoacid k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Running HDBscan for clustering. Finished.\n Centroid extraction. Finished.\n Clustering done in 154.35 seconds.\n 10406 sequences, 12 unclustered, 263 cluster.\n Mean of inner cluster distance mean 0.0000472150\n 0(0) clusters containing matching NA types.\n 0(0) clusters containing matching HA types.\n Starting calculations for segment 3:\n Nucleotide k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Aminoacid k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Running HDBscan for clustering. Finished.\n Centroid extraction. Finished.\n Clustering done in 139.47 seconds.\n 10397 sequences, 7 unclustered, 235 cluster.\n Mean of inner cluster distance mean 0.0001054200\n 0(0) clusters containing matching NA types.\n 0(0) clusters containing matching HA types.\n Starting calculations for segment 4:\n Nucleotide k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Aminoacid k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Running HDBscan for clustering. Finished.\n Centroid extraction. Finished.\n Clustering done in 151.33 seconds.\n 10512 sequences, 11 unclustered, 244 cluster.\n Mean of inner cluster distance mean 0.0000740418\n 0(0) clusters containing matching NA types.\n 0(0) clusters containing matching HA types.\n Starting calculations for segment 5:\n Nucleotide k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Aminoacid k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Running HDBscan for clustering. Finished.\n Centroid extraction. Finished.\n Clustering done in 145.29 seconds.\n 10390 sequences, 18 unclustered, 251 cluster.\n Mean of inner cluster distance mean 0.0001167966\n 0(0) clusters containing matching NA types.\n 0(0) clusters containing matching HA types.\n Starting calculations for segment 6:\n Nucleotide k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Aminoacid k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Running HDBscan for clustering. Finished.\n Centroid extraction. Finished.\n Clustering done in 144.38 seconds.\n 10496 sequences, 20 unclustered, 256 cluster.\n Mean of inner cluster distance mean 0.0001162096\n 0(0) clusters containing matching NA types.\n 0(0) clusters containing matching HA types.\n Starting calculations for segment 7:\n Nucleotide k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Aminoacid k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Running HDBscan for clustering. Finished.\n Centroid extraction. Finished.\n Clustering done in 137.91 seconds.\n 10402 sequences, 37 unclustered, 245 cluster.\n Mean of inner cluster distance mean 0.0001648957\n 0(0) clusters containing matching NA types.\n 0(0) clusters containing matching HA types.\n Starting calculations for segment 8:\n Nucleotide k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Aminoacid k-mer frequency calculation. Finished.\n Running UMAP for dimension reduction. Finished.\n Running HDBscan for clustering. Finished.\n Centroid extraction. Finished.\n Clustering done in 135.61 seconds.\n 10405 sequences, 26 unclustered, 242 cluster.\n Mean of inner cluster distance mean 0.0001719148\n 0(0) clusters containing matching NA types.\n 0(0) clusters containing matching HA types.\nMaximum memory used: 1.90 Gb.\n"
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    #main()\n    memory = memory_usage(main)\n    print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-18T11:22:44.408Z"
     },
     {
      "end_time": "2021-01-18T14:07:10.322Z",
      "execution_time": "19m 37s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 163.20 seconds.\n- 10381 sequences, 13 unclustered, 232 cluster.\n- Mean of inner cluster distance mean 0.0001164629\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nStarting calculations for segment 2:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 156.37 seconds.\n- 10405 sequences, 12 unclustered, 263 cluster.\n- Mean of inner cluster distance mean 0.0000434237\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nStarting calculations for segment 3:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. "
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": "/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\nfailed. This is likely due to too small an eigengap. Consider\nadding some noise or jitter to your data.\n\nFalling back to random initialisation!\n  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 137.21 seconds.\n- 10396 sequences, 16 unclustered, 231 cluster.\n- Mean of inner cluster distance mean 0.0000524843\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nStarting calculations for segment 4:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 149.73 seconds.\n- 10511 sequences, 13 unclustered, 245 cluster.\n- Mean of inner cluster distance mean 0.0000552752\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nStarting calculations for segment 5:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 146.05 seconds.\n- 10389 sequences, 15 unclustered, 252 cluster.\n- Mean of inner cluster distance mean 0.0000610103\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nStarting calculations for segment 6:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 147.72 seconds.\n- 10495 sequences, 14 unclustered, 253 cluster.\n- Mean of inner cluster distance mean 0.0000657352\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nStarting calculations for segment 7:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 140.08 seconds.\n- 10401 sequences, 29 unclustered, 246 cluster.\n- Mean of inner cluster distance mean 0.0000506483\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nStarting calculations for segment 8:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 136.12 seconds.\n- 10403 sequences, 46 unclustered, 247 cluster.\n- Mean of inner cluster distance mean 0.0001609608\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nOverall execution time 1176.48 seconds.\nMaximum memory used: 1.94 Gb.\n"
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    #main()\n    memory = memory_usage(main)\n    print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-18T13:47:32.843Z"
     },
     {
      "end_time": "2021-01-18T15:52:37.477Z",
      "execution_time": "2m 35s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. "
       },
       {
        "ename": "KeyError",
        "evalue": "'cluster'",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
         "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
         "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
         "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
         "\u001b[0;31mKeyError\u001b[0m: 'cluster'",
         "\nThe above exception was the direct cause of the following exception:\n",
         "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-113-0bf07cfe1ecf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#main()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/memory_profiler.py\u001b[0m in \u001b[0;36mmemory_usage\u001b[0;34m(proc, interval, timeout, timestamps, include_children, multiprocess, max_usage, retval, stream, backend, max_iterations)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Therefore, the whole process hangs indefinitely. Here, we are ensuring that the process gets killed!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 \u001b[0mreturned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m                 \u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# finish timing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m<ipython-input-112-d39057b236fc>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'centroid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mnew_clust\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cluster != -1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mincrement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mnew_clust\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_clust\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mclusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mKeyError\u001b[0m: 'cluster'"
        ]
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    #main()\n    memory = memory_usage(main)\n    print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-18T15:50:02.368Z"
     },
     {
      "end_time": "2021-01-18T16:02:07.075Z",
      "execution_time": "2m 47s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 155.62 seconds.\n- 10381 sequences, 13 unclustered, 232 cluster.\n- Mean of inner cluster distance mean 0.0001164629\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 2:\n- Nucleotide k-mer frequency calculation. "
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": "Process MemTimer-3:\n  File \"/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n    self.run()\nTraceback (most recent call last):\n"
       },
       {
        "ename": "KeyboardInterrupt",
        "evalue": "",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-126-0bf07cfe1ecf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#main()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/memory_profiler.py\u001b[0m in \u001b[0;36mmemory_usage\u001b[0;34m(proc, interval, timeout, timestamps, include_children, multiprocess, max_usage, retval, stream, backend, max_iterations)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Therefore, the whole process hangs indefinitely. Here, we are ensuring that the process gets killed!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 \u001b[0mreturned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m                 \u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# finish timing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m<ipython-input-125-de25d41a961d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mfreq_nt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mfreq_nt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_to_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mfreq_nt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_frequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mmatrix_nt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfreq_nt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m<ipython-input-2-b2ad2e68375b>\u001b[0m in \u001b[0;36mcalculate_frequence\u001b[0;34m(self, infile)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'^[ACGT]*$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                         \u001b[0mkmer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkmer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
        ]
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": "  File \"/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/memory_profiler.py\", line 225, in run\n    stop = self.pipe.poll(self.interval)\n  File \"/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n    return self._poll(timeout)\n  File \"/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n    r = wait([self], timeout)\n  File \"/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n    ready = selector.select(timeout)\n  File \"/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/selectors.py\", line 376, in select\n    fd_event_list = self._poll.poll(timeout)\nKeyboardInterrupt\n"
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    #main()\n    memory = memory_usage(main)\n    print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-18T15:59:20.274Z"
     },
     {
      "end_time": "2021-01-18T17:14:23.775Z",
      "execution_time": "19m 21s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 163.33 seconds.\n- 10381 sequences, 13 unclustered, 232 cluster.\n- Mean of inner cluster distance mean 0.0001164629\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 2:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 155.19 seconds.\n- 10405 sequences, 12 unclustered, 263 cluster.\n- Mean of inner cluster distance mean 0.0000434237\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 3:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. "
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": "/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\nfailed. This is likely due to too small an eigengap. Consider\nadding some noise or jitter to your data.\n\nFalling back to random initialisation!\n  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 136.42 seconds.\n- 10396 sequences, 16 unclustered, 231 cluster.\n- Mean of inner cluster distance mean 0.0000524843\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 4:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 146.01 seconds.\n- 10511 sequences, 13 unclustered, 245 cluster.\n- Mean of inner cluster distance mean 0.0000552752\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 5:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 144.96 seconds.\n- 10389 sequences, 15 unclustered, 252 cluster.\n- Mean of inner cluster distance mean 0.0000610103\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 6:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 144.69 seconds.\n- 10495 sequences, 14 unclustered, 253 cluster.\n- Mean of inner cluster distance mean 0.0000657352\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 7:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 134.64 seconds.\n- 10401 sequences, 29 unclustered, 246 cluster.\n- Mean of inner cluster distance mean 0.0000506483\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 8:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 134.43 seconds.\n- 10403 sequences, 46 unclustered, 247 cluster.\n- Mean of inner cluster distance mean 0.0001609608\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nOverall execution time 1159.66 seconds.\nMaximum memory used: 1.94 Gb.\n"
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    #main()\n    memory = memory_usage(main)\n    print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-18T16:55:03.111Z"
     },
     {
      "end_time": "2021-01-18T17:47:16.749Z",
      "execution_time": "19m 10s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 163.14 seconds.\n- 10381 sequences, 13 unclustered, 232 cluster.\n- Mean of inner cluster distance mean 0.0001164629\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 2:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 153.85 seconds.\n- 10405 sequences, 12 unclustered, 263 cluster.\n- Mean of inner cluster distance mean 0.0000434237\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 3:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. "
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": "/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\nfailed. This is likely due to too small an eigengap. Consider\nadding some noise or jitter to your data.\n\nFalling back to random initialisation!\n  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 133.67 seconds.\n- 10396 sequences, 16 unclustered, 231 cluster.\n- Mean of inner cluster distance mean 0.0000524843\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 4:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 145.48 seconds.\n- 10511 sequences, 13 unclustered, 245 cluster.\n- Mean of inner cluster distance mean 0.0000552752\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 5:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 144.89 seconds.\n- 10389 sequences, 15 unclustered, 252 cluster.\n- Mean of inner cluster distance mean 0.0000610103\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 6:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 142.81 seconds.\n- 10495 sequences, 14 unclustered, 253 cluster.\n- Mean of inner cluster distance mean 0.0000657352\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 7:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 133.56 seconds.\n- 10401 sequences, 29 unclustered, 246 cluster.\n- Mean of inner cluster distance mean 0.0000506483\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 8:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 131.43 seconds.\n- 10403 sequences, 46 unclustered, 247 cluster.\n- Mean of inner cluster distance mean 0.0001609608\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nOverall execution time 1148.83 seconds.\nMaximum memory used: 1.95 Gb.\n"
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    #main()\n    memory = memory_usage(main)\n    print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-18T17:28:06.919Z"
     },
     {
      "end_time": "2021-01-18T20:28:46.966Z",
      "execution_time": "2h 39m 11s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. "
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": "/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\nfailed. This is likely due to too small an eigengap. Consider\nadding some noise or jitter to your data.\n\nFalling back to random initialisation!\n  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\nfailed. This is likely due to too small an eigengap. Consider\nadding some noise or jitter to your data.\n\nFalling back to random initialisation!\n  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 1166.79 seconds.\n- 55979 sequences, 55 unclustered, 874 cluster.\n- Mean of inner cluster distance mean 0.0000685445\n- 558(516) clusters containing matching NA types.\n- 572(522) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 2:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 1294.37 seconds.\n- 55933 sequences, 52 unclustered, 862 cluster.\n- Mean of inner cluster distance mean 0.0000667975\n- 586(549) clusters containing matching NA types.\n- 601(563) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 3:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. "
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": "/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\nfailed. This is likely due to too small an eigengap. Consider\nadding some noise or jitter to your data.\n\nFalling back to random initialisation!\n  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 1344.59 seconds.\n- 56021 sequences, 53 unclustered, 923 cluster.\n- Mean of inner cluster distance mean 0.0001168338\n- 634(584) clusters containing matching NA types.\n- 646(594) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 4:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 1150.09 seconds.\n- 56600 sequences, 41 unclustered, 842 cluster.\n- Mean of inner cluster distance mean 0.0000675273\n- 630(556) clusters containing matching NA types.\n- 839(623) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 5:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. "
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": "/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\nfailed. This is likely due to too small an eigengap. Consider\nadding some noise or jitter to your data.\n\nFalling back to random initialisation!\n  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 1131.26 seconds.\n- 56087 sequences, 53 unclustered, 882 cluster.\n- Mean of inner cluster distance mean 0.0000889324\n- 619(574) clusters containing matching NA types.\n- 633(584) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 6:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 1091.69 seconds.\n- 56529 sequences, 81 unclustered, 909 cluster.\n- Mean of inner cluster distance mean 0.0000839112\n- 903(675) clusters containing matching NA types.\n- 689(618) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 7:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 1148.25 seconds.\n- 56081 sequences, 137 unclustered, 889 cluster.\n- Mean of inner cluster distance mean 0.0001458667\n- 621(575) clusters containing matching NA types.\n- 641(594) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 8:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 1218.37 seconds.\n- 56174 sequences, 136 unclustered, 912 cluster.\n- Mean of inner cluster distance mean 0.0002149102\n- 630(576) clusters containing matching NA types.\n- 649(591) clusters containing matching HA types.\nFinished.\nOverall execution time 9545.40 seconds.\nMaximum memory used: 19.22 Gb.\n"
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    #main()\n    memory = memory_usage(main)\n    print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-18T17:49:36.174Z"
     },
     {
      "end_time": "2021-01-19T13:36:27.134Z",
      "execution_time": "20m 1s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. "
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": "/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\nfailed. This is likely due to too small an eigengap. Consider\nadding some noise or jitter to your data.\n\nFalling back to random initialisation!\n  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 1196.37 seconds.\n- 55436 sequences, 41 unclustered, 881 cluster.\n- Mean of inner cluster distance mean 0.0000639726\n- 558(516) clusters containing matching NA types.\n- 576(526) clusters containing matching HA types.\nFinished.\nOverall execution time 1196.37 seconds.\nMaximum memory used: 13.16 Gb.\n"
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    #main()\n    memory = memory_usage(main)\n    print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-19T13:16:26.113Z"
     },
     {
      "end_time": "2021-01-19T15:33:16.596Z",
      "execution_time": "18m 54s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 156.24 seconds.\n- 10326 sequences, 7 unclustered, 236 cluster.\n- Mean of inner cluster distance mean 0.0001498887\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 2:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 151.02 seconds.\n- 10360 sequences, 7 unclustered, 258 cluster.\n- Mean of inner cluster distance mean 0.0000465008\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 3:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 131.79 seconds.\n- 10272 sequences, 12 unclustered, 230 cluster.\n- Mean of inner cluster distance mean 0.0000481188\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 4:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. "
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": "/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\nfailed. This is likely due to too small an eigengap. Consider\nadding some noise or jitter to your data.\n\nFalling back to random initialisation!\n  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 145.77 seconds.\n- 10482 sequences, 9 unclustered, 245 cluster.\n- Mean of inner cluster distance mean 0.0000517155\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 5:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 141.69 seconds.\n- 10184 sequences, 24 unclustered, 247 cluster.\n- Mean of inner cluster distance mean 0.0000660574\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 6:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 142.85 seconds.\n- 10417 sequences, 10 unclustered, 251 cluster.\n- Mean of inner cluster distance mean 0.0000574508\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 7:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 132.16 seconds.\n- 10254 sequences, 31 unclustered, 242 cluster.\n- Mean of inner cluster distance mean 0.0001082707\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 8:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 131.17 seconds.\n- 10325 sequences, 32 unclustered, 240 cluster.\n- Mean of inner cluster distance mean 0.0000626106\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nOverall execution time 1132.68 seconds.\nMaximum memory used: 1.94 Gb.\n"
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    #main()\n    memory = memory_usage(main)\n    print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-19T15:14:22.866Z"
     },
     {
      "end_time": "2021-01-19T16:45:16.662Z",
      "execution_time": "16m 6s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 6:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. "
       },
       {
        "ename": "ValueError",
        "evalue": "Min samples and Min cluster size must be positive integers",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-10-0bf07cfe1ecf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#main()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/memory_profiler.py\u001b[0m in \u001b[0;36mmemory_usage\u001b[0;34m(proc, interval, timeout, timestamps, include_children, multiprocess, max_usage, retval, stream, backend, max_iterations)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Therefore, the whole process hangs indefinitely. Here, we are ensuring that the process gets killed!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 \u001b[0mreturned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m                 \u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# finish timing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m<ipython-input-9-454cfc183c89>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mcluster_selection_epsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#don't seperate clusters with a distance less than value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#don't mess with this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         ).fit(matrix)\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/hdbscan/hdbscan_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    917\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condensed_tree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_single_linkage_tree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m          self._min_spanning_tree) = hdbscan(X, **kwargs)\n\u001b[0m\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/hdbscan/hdbscan_.py\u001b[0m in \u001b[0;36mhdbscan\u001b[0;34m(X, min_cluster_size, min_samples, alpha, cluster_selection_epsilon, metric, p, leaf_size, algorithm, memory, approx_min_span_tree, gen_min_span_tree, core_dist_n_jobs, cluster_selection_method, allow_single_cluster, match_reference_implementation, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmin_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmin_cluster_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         raise ValueError('Min samples and Min cluster size must be positive'\n\u001b[0m\u001b[1;32m    491\u001b[0m                          ' integers')\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mValueError\u001b[0m: Min samples and Min cluster size must be positive integers"
        ]
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    main()\n    #memory = memory_usage(main)\n    #print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-19T16:29:10.728Z"
     },
     {
      "end_time": "2021-01-19T16:49:16.273Z",
      "execution_time": "2m 10s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 6:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 128.78 seconds.\n- 10417 sequences, 5 unclustered, 257 cluster.\n- Mean of inner cluster distance mean 0.0000449730\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nOverall execution time 128.78 seconds.\n"
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    main()\n    #memory = memory_usage(main)\n    #print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-19T16:47:06.624Z"
     },
     {
      "end_time": "2021-01-19T17:06:32.198Z",
      "execution_time": "16m 21s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 6:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 977.08 seconds.\n- 55075 sequences, 25 unclustered, 940 cluster.\n- Mean of inner cluster distance mean 0.0000845859\n- 936(709) clusters containing matching NA types.\n- 729(652) clusters containing matching HA types.\nFinished.\nOverall execution time 977.08 seconds.\n"
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    main()\n    #memory = memory_usage(main)\n    #print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-19T16:50:10.872Z"
     },
     {
      "end_time": "2021-01-19T17:32:42.200Z",
      "execution_time": "2m 37s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 6:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. "
       },
       {
        "ename": "NameError",
        "evalue": "name 'MafftCommandline' is not defined",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-6-f8a01154f920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#memory = memory_usage(main)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m<ipython-input-5-6ff0629711ea>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mfasta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'genome.fasta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mmafft_cline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMafftCommandline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'genome.fasta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmafft_cline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;31m#align = AlignIO.read(StringIO(stdout), 'fasta')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mNameError\u001b[0m: name 'MafftCommandline' is not defined"
        ]
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    main()\n    #memory = memory_usage(main)\n    #print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-19T17:30:04.972Z"
     },
     {
      "end_time": "2021-01-19T17:36:29.443Z",
      "execution_time": "3m 2s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 6:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 181.63 seconds.\n- 10417 sequences, 12 unclustered, 249 cluster.\n- Mean of inner cluster distance mean 0.0000511611\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\n"
       },
       {
        "ename": "TypeError",
        "evalue": "cannot concatenate object of type '<class 'collections.defaultdict'>'; only Series and DataFrame objs are valid",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-10-f8a01154f920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#memory = memory_usage(main)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m<ipython-input-9-fddd55fd6c2a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mresult_cluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'cluster.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0mresult_msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmafft_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0mresult_msa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'segment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cluster'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accession'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mresult_msa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'segment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    357\u001b[0m                     \u001b[0;34m\"only Series and DataFrame objs are valid\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 )\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'collections.defaultdict'>'; only Series and DataFrame objs are valid"
        ]
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    main()\n    #memory = memory_usage(main)\n    #print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-19T17:33:26.966Z"
     },
     {
      "end_time": "2021-01-19T17:46:13.470Z",
      "execution_time": "3m 2s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 6:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction. Finished.\n- Clustering done in 181.32 seconds.\n- 10417 sequences, 12 unclustered, 249 cluster.\n- Mean of inner cluster distance mean 0.0000511611\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nOverall execution time 181.32 seconds.\n"
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    main()\n    #memory = memory_usage(main)\n    #print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-19T17:43:11.289Z"
     },
     {
      "end_time": "2021-01-19T22:22:32.009Z",
      "execution_time": "3h 54m 49s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. "
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": "/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\nfailed. This is likely due to too small an eigengap. Consider\nadding some noise or jitter to your data.\n\nFalling back to random initialisation!\n  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment creation. Finished.\n- Clustering done in 1884.32 seconds.\n- 55436 sequences, 41 unclustered, 881 cluster.\n- Mean of inner cluster distance mean 0.0000639726\n- 558(516) clusters containing matching NA types.\n- 576(526) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 2:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment creation. Finished.\n- Clustering done in 1982.62 seconds.\n- 55292 sequences, 38 unclustered, 885 cluster.\n- Mean of inner cluster distance mean 0.0000689872\n- 603(564) clusters containing matching NA types.\n- 616(576) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 3:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. "
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": "/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\nfailed. This is likely due to too small an eigengap. Consider\nadding some noise or jitter to your data.\n\nFalling back to random initialisation!\n  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\nfailed. This is likely due to too small an eigengap. Consider\nadding some noise or jitter to your data.\n\nFalling back to random initialisation!\n  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\nfailed. This is likely due to too small an eigengap. Consider\nadding some noise or jitter to your data.\n\nFalling back to random initialisation!\n  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment creation. Finished.\n- Clustering done in 1942.33 seconds.\n- 55351 sequences, 40 unclustered, 882 cluster.\n- Mean of inner cluster distance mean 0.0000759190\n- 613(562) clusters containing matching NA types.\n- 618(567) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 4:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment creation. Finished.\n- Clustering done in 1613.63 seconds.\n- 55281 sequences, 34 unclustered, 817 cluster.\n- Mean of inner cluster distance mean 0.0000723253\n- 622(548) clusters containing matching NA types.\n- 815(605) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 5:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. "
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": "/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\nfailed. This is likely due to too small an eigengap. Consider\nadding some noise or jitter to your data.\n\nFalling back to random initialisation!\n  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment creation. Finished.\n- Clustering done in 1704.05 seconds.\n- 55541 sequences, 59 unclustered, 905 cluster.\n- Mean of inner cluster distance mean 0.0001031753\n- 633(583) clusters containing matching NA types.\n- 648(594) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 6:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment creation. Finished.\n- Clustering done in 1607.97 seconds.\n- 55075 sequences, 83 unclustered, 920 cluster.\n- Mean of inner cluster distance mean 0.0000566989\n- 916(683) clusters containing matching NA types.\n- 700(623) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 7:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment creation. Finished.\n- Clustering done in 1669.35 seconds.\n- 55620 sequences, 119 unclustered, 888 cluster.\n- Mean of inner cluster distance mean 0.0001389241\n- 611(567) clusters containing matching NA types.\n- 635(588) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 8:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment creation. Finished.\n- Clustering done in 1667.30 seconds.\n- 55563 sequences, 154 unclustered, 893 cluster.\n- Mean of inner cluster distance mean 0.0002085449\n- 617(565) clusters containing matching NA types.\n- 636(579) clusters containing matching HA types.\nFinished.\nOverall execution time 14071.57 seconds.\n"
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    main()\n    #memory = memory_usage(main)\n    #print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-19T18:27:42.877Z"
     },
     {
      "end_time": "2021-01-20T17:49:14.899Z",
      "execution_time": "5m 32s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment. "
       },
       {
        "ename": "KeyError",
        "evalue": "'cluster'",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
         "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
         "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
         "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
         "\u001b[0;31mKeyError\u001b[0m: 'cluster'",
         "\nThe above exception was the direct cause of the following exception:\n",
         "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-4-f8a01154f920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#memory = memory_usage(main)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m<ipython-input-3-139b022f598e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mmafft_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malign_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mmafft_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmafft_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mincrement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'centroid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mKeyError\u001b[0m: 'cluster'"
        ]
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    main()\n    #memory = memory_usage(main)\n    #print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-20T17:43:42.889Z"
     },
     {
      "end_time": "2021-01-21T15:29:44.177Z",
      "execution_time": "21h 46m 1s",
      "outputs": [],
      "source": "if __name__ == \"__main__\":\n\n    main()\n    #memory = memory_usage(main)\n    #print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-20T17:43:42.889Z"
     },
     {
      "end_time": "2021-01-21T16:10:11.070Z",
      "execution_time": "38m 24s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment. Finished.\n- Clustering done in 311.58 seconds.\n- 10326 sequences, 7 unclustered, 236 cluster.\n- Mean of inner cluster distance mean 0.0001498887\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 2:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment. Finished.\n- Clustering done in 327.11 seconds.\n- 10360 sequences, 7 unclustered, 258 cluster.\n- Mean of inner cluster distance mean 0.0000465008\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 3:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment. Finished.\n- Clustering done in 291.27 seconds.\n- 10272 sequences, 12 unclustered, 230 cluster.\n- Mean of inner cluster distance mean 0.0000481188\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 4:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. "
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": "/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\nfailed. This is likely due to too small an eigengap. Consider\nadding some noise or jitter to your data.\n\nFalling back to random initialisation!\n  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment. Finished.\n- Clustering done in 294.60 seconds.\n- 10482 sequences, 9 unclustered, 245 cluster.\n- Mean of inner cluster distance mean 0.0000517155\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 5:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment. Finished.\n- Clustering done in 291.15 seconds.\n- 10184 sequences, 24 unclustered, 247 cluster.\n- Mean of inner cluster distance mean 0.0000660574\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 6:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment. Finished.\n- Clustering done in 281.15 seconds.\n- 10417 sequences, 10 unclustered, 251 cluster.\n- Mean of inner cluster distance mean 0.0000574508\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 7:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment. Finished.\n- Clustering done in 257.21 seconds.\n- 10254 sequences, 31 unclustered, 242 cluster.\n- Mean of inner cluster distance mean 0.0001082707\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 8:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment. Finished.\n- Clustering done in 249.08 seconds.\n- 10325 sequences, 32 unclustered, 240 cluster.\n- Mean of inner cluster distance mean 0.0000626106\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\n"
       },
       {
        "ename": "ValueError",
        "evalue": "Length of names must match number of levels in MultiIndex.",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-18-f8a01154f920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#memory = memory_usage(main)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m<ipython-input-17-79a95a7b0bc7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mresult_msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmafft_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0mresult_msa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'segment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cluster'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accession'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0mresult_msa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'segment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mresult_msa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'segment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cluster'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accession'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'alignment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mset_names\u001b[0;34m(self, names, level, inplace)\u001b[0m\n\u001b[1;32m   1318\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shallow_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m         \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;32m/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_set_names\u001b[0;34m(self, names, level, validate)\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m                 raise ValueError(\n\u001b[0;32m-> 1350\u001b[0;31m                     \u001b[0;34m\"Length of names must match number of levels in MultiIndex.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m                 )\n\u001b[1;32m   1352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mValueError\u001b[0m: Length of names must match number of levels in MultiIndex."
        ]
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    main()\n    #memory = memory_usage(main)\n    #print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-21T15:31:46.803Z"
     },
     {
      "end_time": "2021-01-21T16:16:34.245Z",
      "execution_time": "4m 41s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 6:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment. Finished.\n- Clustering and alignment done in 279.82 seconds.\n- 10417 sequences, 10 unclustered, 251 cluster.\n- Mean of inner cluster distance mean 0.0000574508\n- 0(0) clusters containing matching NA types.\n- 0(0) clusters containing matching HA types.\nFinished.\nOverall execution time 279.82 seconds.\n"
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    main()\n    #memory = memory_usage(main)\n    #print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-21T16:11:53.353Z"
     },
     {
      "end_time": "2021-01-21T20:09:51.517Z",
      "execution_time": "3h 50m 6s",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Read input and settings file. Finished.\nStarting calculations for segment 1:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. "
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": "/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\nfailed. This is likely due to too small an eigengap. Consider\nadding some noise or jitter to your data.\n\nFalling back to random initialisation!\n  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment. Finished.\n- Clustering and alignment done in 1831.45 seconds.\n- 55436 sequences, 41 unclustered, 881 cluster.\n- Mean of inner cluster distance mean 0.0000639726\n- 558(516) clusters containing matching NA types.\n- 576(526) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 2:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment. Finished.\n- Clustering and alignment done in 1912.56 seconds.\n- 55292 sequences, 38 unclustered, 885 cluster.\n- Mean of inner cluster distance mean 0.0000689872\n- 603(564) clusters containing matching NA types.\n- 616(576) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 3:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. "
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": "/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\nfailed. This is likely due to too small an eigengap. Consider\nadding some noise or jitter to your data.\n\nFalling back to random initialisation!\n  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\nfailed. This is likely due to too small an eigengap. Consider\nadding some noise or jitter to your data.\n\nFalling back to random initialisation!\n  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\nfailed. This is likely due to too small an eigengap. Consider\nadding some noise or jitter to your data.\n\nFalling back to random initialisation!\n  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment. Finished.\n- Clustering and alignment done in 1915.32 seconds.\n- 55351 sequences, 40 unclustered, 882 cluster.\n- Mean of inner cluster distance mean 0.0000759190\n- 613(562) clusters containing matching NA types.\n- 618(567) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 4:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment. Finished.\n- Clustering and alignment done in 1587.13 seconds.\n- 55281 sequences, 34 unclustered, 817 cluster.\n- Mean of inner cluster distance mean 0.0000723253\n- 622(548) clusters containing matching NA types.\n- 815(605) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 5:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. "
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": "/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\nfailed. This is likely due to too small an eigengap. Consider\nadding some noise or jitter to your data.\n\nFalling back to random initialisation!\n  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n"
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": "Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment. Finished.\n- Clustering and alignment done in 1679.24 seconds.\n- 55541 sequences, 59 unclustered, 905 cluster.\n- Mean of inner cluster distance mean 0.0001031753\n- 633(583) clusters containing matching NA types.\n- 648(594) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 6:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment. Finished.\n- Clustering and alignment done in 1574.45 seconds.\n- 55075 sequences, 83 unclustered, 920 cluster.\n- Mean of inner cluster distance mean 0.0000566989\n- 916(683) clusters containing matching NA types.\n- 700(623) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 7:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment. Finished.\n- Clustering and alignment done in 1637.48 seconds.\n- 55620 sequences, 119 unclustered, 888 cluster.\n- Mean of inner cluster distance mean 0.0001389241\n- 611(567) clusters containing matching NA types.\n- 635(588) clusters containing matching HA types.\nFinished.\nStarting calculations for segment 8:\n- Nucleotide k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Aminoacid k-mer frequency calculation. Finished.\n- Running UMAP for dimension reduction. Finished.\n- Running HDBscan for clustering. Finished.\n- Centroid extraction and alignment. Finished.\n- Clustering and alignment done in 1651.02 seconds.\n- 55563 sequences, 154 unclustered, 893 cluster.\n- Mean of inner cluster distance mean 0.0002085449\n- 617(565) clusters containing matching NA types.\n- 636(579) clusters containing matching HA types.\nFinished.\nOverall execution time 13788.65 seconds.\n"
       }
      ],
      "source": "if __name__ == \"__main__\":\n\n    main()\n    #memory = memory_usage(main)\n    #print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")",
      "start_time": "2021-01-21T16:19:45.783Z"
     }
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read input and settings file. Finished.\n",
      "Starting calculations for segment 1:\n",
      "- Nucleotide k-mer frequency calculation. Finished.\n",
      "- Running UMAP for dimension reduction. Finished.\n",
      "- Aminoacid k-mer frequency calculation. Finished.\n",
      "- Running UMAP for dimension reduction. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "- Running HDBscan for clustering. Finished.\n",
      "- Centroid extraction and alignment. Finished.\n",
      "- Clustering and alignment done in 1831.45 seconds.\n",
      "- 55436 sequences, 41 unclustered, 881 cluster.\n",
      "- Mean of inner cluster distance mean 0.0000639726\n",
      "- 558(516) clusters containing matching NA types.\n",
      "- 576(526) clusters containing matching HA types.\n",
      "Finished.\n",
      "Starting calculations for segment 2:\n",
      "- Nucleotide k-mer frequency calculation. Finished.\n",
      "- Running UMAP for dimension reduction. Finished.\n",
      "- Aminoacid k-mer frequency calculation. Finished.\n",
      "- Running UMAP for dimension reduction. Finished.\n",
      "- Running HDBscan for clustering. Finished.\n",
      "- Centroid extraction and alignment. Finished.\n",
      "- Clustering and alignment done in 1912.56 seconds.\n",
      "- 55292 sequences, 38 unclustered, 885 cluster.\n",
      "- Mean of inner cluster distance mean 0.0000689872\n",
      "- 603(564) clusters containing matching NA types.\n",
      "- 616(576) clusters containing matching HA types.\n",
      "Finished.\n",
      "Starting calculations for segment 3:\n",
      "- Nucleotide k-mer frequency calculation. Finished.\n",
      "- Running UMAP for dimension reduction. Finished.\n",
      "- Aminoacid k-mer frequency calculation. Finished.\n",
      "- Running UMAP for dimension reduction. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n",
      "/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n",
      "/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "- Running HDBscan for clustering. Finished.\n",
      "- Centroid extraction and alignment. Finished.\n",
      "- Clustering and alignment done in 1915.32 seconds.\n",
      "- 55351 sequences, 40 unclustered, 882 cluster.\n",
      "- Mean of inner cluster distance mean 0.0000759190\n",
      "- 613(562) clusters containing matching NA types.\n",
      "- 618(567) clusters containing matching HA types.\n",
      "Finished.\n",
      "Starting calculations for segment 4:\n",
      "- Nucleotide k-mer frequency calculation. Finished.\n",
      "- Running UMAP for dimension reduction. Finished.\n",
      "- Aminoacid k-mer frequency calculation. Finished.\n",
      "- Running UMAP for dimension reduction. Finished.\n",
      "- Running HDBscan for clustering. Finished.\n",
      "- Centroid extraction and alignment. Finished.\n",
      "- Clustering and alignment done in 1587.13 seconds.\n",
      "- 55281 sequences, 34 unclustered, 817 cluster.\n",
      "- Mean of inner cluster distance mean 0.0000723253\n",
      "- 622(548) clusters containing matching NA types.\n",
      "- 815(605) clusters containing matching HA types.\n",
      "Finished.\n",
      "Starting calculations for segment 5:\n",
      "- Nucleotide k-mer frequency calculation. Finished.\n",
      "- Running UMAP for dimension reduction. Finished.\n",
      "- Aminoacid k-mer frequency calculation. Finished.\n",
      "- Running UMAP for dimension reduction. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahenoch/miniconda3/envs/masterthesis/lib/python3.6/site-packages/umap/spectral.py:253: UserWarning: WARNING: spectral initialisation failed! The eigenvector solver\n",
      "failed. This is likely due to too small an eigengap. Consider\n",
      "adding some noise or jitter to your data.\n",
      "\n",
      "Falling back to random initialisation!\n",
      "  \"WARNING: spectral initialisation failed! The eigenvector solver\\n\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "- Running HDBscan for clustering. Finished.\n",
      "- Centroid extraction and alignment. Finished.\n",
      "- Clustering and alignment done in 1679.24 seconds.\n",
      "- 55541 sequences, 59 unclustered, 905 cluster.\n",
      "- Mean of inner cluster distance mean 0.0001031753\n",
      "- 633(583) clusters containing matching NA types.\n",
      "- 648(594) clusters containing matching HA types.\n",
      "Finished.\n",
      "Starting calculations for segment 6:\n",
      "- Nucleotide k-mer frequency calculation. Finished.\n",
      "- Running UMAP for dimension reduction. Finished.\n",
      "- Aminoacid k-mer frequency calculation. Finished.\n",
      "- Running UMAP for dimension reduction. Finished.\n",
      "- Running HDBscan for clustering. Finished.\n",
      "- Centroid extraction and alignment. Finished.\n",
      "- Clustering and alignment done in 1574.45 seconds.\n",
      "- 55075 sequences, 83 unclustered, 920 cluster.\n",
      "- Mean of inner cluster distance mean 0.0000566989\n",
      "- 916(683) clusters containing matching NA types.\n",
      "- 700(623) clusters containing matching HA types.\n",
      "Finished.\n",
      "Starting calculations for segment 7:\n",
      "- Nucleotide k-mer frequency calculation. Finished.\n",
      "- Running UMAP for dimension reduction. Finished.\n",
      "- Aminoacid k-mer frequency calculation. Finished.\n",
      "- Running UMAP for dimension reduction. Finished.\n",
      "- Running HDBscan for clustering. Finished.\n",
      "- Centroid extraction and alignment. Finished.\n",
      "- Clustering and alignment done in 1637.48 seconds.\n",
      "- 55620 sequences, 119 unclustered, 888 cluster.\n",
      "- Mean of inner cluster distance mean 0.0001389241\n",
      "- 611(567) clusters containing matching NA types.\n",
      "- 635(588) clusters containing matching HA types.\n",
      "Finished.\n",
      "Starting calculations for segment 8:\n",
      "- Nucleotide k-mer frequency calculation. Finished.\n",
      "- Running UMAP for dimension reduction. Finished.\n",
      "- Aminoacid k-mer frequency calculation. Finished.\n",
      "- Running UMAP for dimension reduction. Finished.\n",
      "- Running HDBscan for clustering. Finished.\n",
      "- Centroid extraction and alignment. Finished.\n",
      "- Clustering and alignment done in 1651.02 seconds.\n",
      "- 55563 sequences, 154 unclustered, 893 cluster.\n",
      "- Mean of inner cluster distance mean 0.0002085449\n",
      "- 617(565) clusters containing matching NA types.\n",
      "- 636(579) clusters containing matching HA types.\n",
      "Finished.\n",
      "Overall execution time 13788.65 seconds.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    main()\n",
    "    #memory = memory_usage(main)\n",
    "    #print(f\"Maximum memory used: {max(memory)/1000:0.2f} Gb.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "provenance": [
     {
      "end_time": "Unknown",
      "execution_time": "Unknown",
      "outputs": [],
      "source": "#wie viele H's? 18! N11",
      "start_time": "Unknown"
     }
    ]
   },
   "outputs": [],
   "source": [
    "#wie viele H's? 18! N11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecutionTime": {
     "end_time": "2021-01-22T10:58:53.984236Z",
     "start_time": "2021-01-22T10:58:50.214869Z"
    },
    "provenance": [
     {
      "end_time": "2021-01-21T15:30:40.813Z",
      "execution_time": "10ms",
      "outputs": [
       {
        "data": {
         "text/plain": "defaultdict(list,\n            {1:                                                        alignment\n                 accession                                                   \n             0   >MH362869  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n                 >MH583310  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n                 >MH245376  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n                 >CY262163  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n                 >CY256698  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n             ...                                                          ...\n             234 >CY202431  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n                 >CY200695  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n                 >CY202055  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n                 >CY202063  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n                 >CY202071  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n             \n             [10319 rows x 1 columns]})"
        },
        "execution_count": 7,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "mafft_dict",
      "start_time": "2021-01-21T15:30:40.803Z"
     },
     {
      "end_time": "2021-01-21T15:30:51.356Z",
      "execution_time": "15ms",
      "outputs": [
       {
        "data": {
         "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>alignment</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>accession</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">0</th>\n      <th>&gt;MH362869</th>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>&gt;MH583310</th>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>&gt;MH245376</th>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY262163</th>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY256698</th>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">234</th>\n      <th>&gt;CY202431</th>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY200695</th>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY202055</th>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY202063</th>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY202071</th>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10319 rows  1 columns</p>\n</div>",
         "text/plain": "                                                       alignment\n    accession                                                   \n0   >MH362869  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n    >MH583310  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n    >MH245376  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n    >CY262163  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n    >CY256698  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n...                                                          ...\n234 >CY202431  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n    >CY200695  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n    >CY202055  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n    >CY202063  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n    >CY202071  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n\n[10319 rows x 1 columns]"
        },
        "execution_count": 8,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "mafft_dict[1]",
      "start_time": "2021-01-21T15:30:51.341Z"
     },
     {
      "end_time": "2021-01-21T15:30:57.357Z",
      "execution_time": "15ms",
      "outputs": [
       {
        "data": {
         "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>alignment</th>\n    </tr>\n    <tr>\n      <th>cluster</th>\n      <th>accession</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">0</th>\n      <th>&gt;MH362869</th>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>&gt;MH583310</th>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>&gt;MH245376</th>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY262163</th>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY256698</th>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">234</th>\n      <th>&gt;CY202431</th>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY200695</th>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY202055</th>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY202063</th>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY202071</th>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10319 rows  1 columns</p>\n</div>",
         "text/plain": "                                                           alignment\ncluster accession                                                   \n0       >MH362869  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n        >MH583310  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n        >MH245376  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n        >CY262163  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n        >CY256698  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n...                                                              ...\n234     >CY202431  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n        >CY200695  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n        >CY202055  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n        >CY202063  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n        >CY202071  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n\n[10319 rows x 1 columns]"
        },
        "execution_count": 10,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "mafft_dict[1]",
      "start_time": "2021-01-21T15:30:57.342Z"
     },
     {
      "end_time": "2021-01-21T15:31:04.019Z",
      "execution_time": "12ms",
      "outputs": [
       {
        "data": {
         "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cluster</th>\n      <th>alignment</th>\n    </tr>\n    <tr>\n      <th>accession</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>&gt;MH362869</th>\n      <td>0</td>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>&gt;MH583310</th>\n      <td>0</td>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>&gt;MH245376</th>\n      <td>0</td>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY262163</th>\n      <td>0</td>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY256698</th>\n      <td>0</td>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY202431</th>\n      <td>234</td>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY200695</th>\n      <td>234</td>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY202055</th>\n      <td>234</td>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY202063</th>\n      <td>234</td>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY202071</th>\n      <td>234</td>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10319 rows  2 columns</p>\n</div>",
         "text/plain": "           cluster                                          alignment\naccession                                                            \n>MH362869        0  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n>MH583310        0  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n>MH245376        0  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n>CY262163        0  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n>CY256698        0  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n...            ...                                                ...\n>CY202431      234  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n>CY200695      234  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n>CY202055      234  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n>CY202063      234  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n>CY202071      234  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n\n[10319 rows x 2 columns]"
        },
        "execution_count": 12,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "mafft_dict[1]",
      "start_time": "2021-01-21T15:31:04.007Z"
     },
     {
      "end_time": "2021-01-21T15:31:10.467Z",
      "execution_time": "11ms",
      "outputs": [
       {
        "data": {
         "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cluster</th>\n      <th>alignment</th>\n    </tr>\n    <tr>\n      <th>accession</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>&gt;MH362869</th>\n      <td>0</td>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>&gt;MH583310</th>\n      <td>0</td>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>&gt;MH245376</th>\n      <td>0</td>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY262163</th>\n      <td>0</td>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY256698</th>\n      <td>0</td>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY202431</th>\n      <td>234</td>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY200695</th>\n      <td>234</td>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY202055</th>\n      <td>234</td>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY202063</th>\n      <td>234</td>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY202071</th>\n      <td>234</td>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10319 rows  2 columns</p>\n</div>",
         "text/plain": "           cluster                                          alignment\naccession                                                            \n>MH362869        0  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n>MH583310        0  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n>MH245376        0  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n>CY262163        0  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n>CY256698        0  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n...            ...                                                ...\n>CY202431      234  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n>CY200695      234  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n>CY202055      234  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n>CY202063      234  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n>CY202071      234  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n\n[10319 rows x 2 columns]"
        },
        "execution_count": 14,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "mafft_dict[1]",
      "start_time": "2021-01-21T15:31:10.456Z"
     },
     {
      "end_time": "2021-01-21T15:31:15.939Z",
      "execution_time": "11ms",
      "outputs": [
       {
        "data": {
         "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cluster</th>\n      <th>alignment</th>\n    </tr>\n    <tr>\n      <th>accession</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>&gt;MH362869</th>\n      <td>100</td>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>&gt;MH583310</th>\n      <td>100</td>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>&gt;MH245376</th>\n      <td>100</td>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY262163</th>\n      <td>100</td>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY256698</th>\n      <td>100</td>\n      <td>ctttaagatgaatataaatccgtattttctcttcatagatgtacct...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY202431</th>\n      <td>334</td>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY200695</th>\n      <td>334</td>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY202055</th>\n      <td>334</td>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY202063</th>\n      <td>334</td>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY202071</th>\n      <td>334</td>\n      <td>atgaatataaatccgtattttctattcatagatgtacctatacagg...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10319 rows  2 columns</p>\n</div>",
         "text/plain": "           cluster                                          alignment\naccession                                                            \n>MH362869      100  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n>MH583310      100  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n>MH245376      100  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n>CY262163      100  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n>CY256698      100  ctttaagatgaatataaatccgtattttctcttcatagatgtacct...\n...            ...                                                ...\n>CY202431      334  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n>CY200695      334  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n>CY202055      334  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n>CY202063      334  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n>CY202071      334  atgaatataaatccgtattttctattcatagatgtacctatacagg...\n\n[10319 rows x 2 columns]"
        },
        "execution_count": 16,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "mafft_dict[1]",
      "start_time": "2021-01-21T15:31:15.928Z"
     },
     {
      "end_time": "2021-01-21T22:25:53.186Z",
      "execution_time": "3.39s",
      "outputs": [
       {
        "data": {
         "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>segment</th>\n      <th>cluster</th>\n      <th>alignment</th>\n    </tr>\n    <tr>\n      <th>accession</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>&gt;MK265637</th>\n      <td>1</td>\n      <td>0</td>\n      <td>tcaaatatattcaatatggagagaataaaagagctgagagacctaa...</td>\n    </tr>\n    <tr>\n      <th>&gt;MK265655</th>\n      <td>1</td>\n      <td>0</td>\n      <td>tcaaatatattcaatatggagagaataaaagagctgagagacctaa...</td>\n    </tr>\n    <tr>\n      <th>&gt;MK364024</th>\n      <td>1</td>\n      <td>0</td>\n      <td>tcaaatatattcaatatggagagaataaaagagctgagagacctaa...</td>\n    </tr>\n    <tr>\n      <th>&gt;MK364444</th>\n      <td>1</td>\n      <td>0</td>\n      <td>tcaaatatattcaatatggagagaataaaagagctgagagacctaa...</td>\n    </tr>\n    <tr>\n      <th>&gt;MK364640</th>\n      <td>1</td>\n      <td>0</td>\n      <td>tcaaatatattcaatatggagagaataaaagagctgagagacctaa...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>&gt;MH598129</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>------------gtgacaaaaacataatggattccaacactgtgtc...</td>\n    </tr>\n    <tr>\n      <th>&gt;MH620640</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>agcaaaagcagggtgacaaaaacataatggattccaacactgtgtc...</td>\n    </tr>\n    <tr>\n      <th>&gt;MK902671</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>--------------------------atggattccaacactgtgtc...</td>\n    </tr>\n    <tr>\n      <th>&gt;MN055190</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>agcaaaagcagggtgacaaaaacataatggattccaacactgtgtc...</td>\n    </tr>\n    <tr>\n      <th>&gt;U96739</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>------------gtgacaaagacgtaatggactccaacactgtgtc...</td>\n    </tr>\n  </tbody>\n</table>\n<p>442591 rows  3 columns</p>\n</div>",
         "text/plain": "           segment  cluster                                          alignment\naccession                                                                     \n>MK265637        1        0  tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK265655        1        0  tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK364024        1        0  tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK364444        1        0  tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK364640        1        0  tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n...            ...      ...                                                ...\n>MH598129        8     7055  ------------gtgacaaaaacataatggattccaacactgtgtc...\n>MH620640        8     7055  agcaaaagcagggtgacaaaaacataatggattccaacactgtgtc...\n>MK902671        8     7055  --------------------------atggattccaacactgtgtc...\n>MN055190        8     7055  agcaaaagcagggtgacaaaaacataatggattccaacactgtgtc...\n>U96739          8     7055  ------------gtgacaaagacgtaatggactccaacactgtgtc...\n\n[442591 rows x 3 columns]"
        },
        "execution_count": 6,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "pd.read_csv('Output/alignment.csv', sep = ',', na_filter = False, header = 0, index_col = 0)",
      "start_time": "2021-01-21T22:25:49.796Z"
     },
     {
      "end_time": "2021-01-21T22:26:17.902Z",
      "execution_time": "3.38s",
      "outputs": [],
      "source": "alignment = pd.read_csv('Output/alignment.csv', sep = ',', na_filter = False, header = 0, index_col = 0)",
      "start_time": "2021-01-21T22:26:14.520Z"
     },
     {
      "end_time": "2021-01-21T22:27:00.690Z",
      "execution_time": "3.50s",
      "outputs": [],
      "source": "alignment = pd.read_csv('Output/alignment.csv', sep = ',', na_filter = False, header = 0, index_col = 0)\ncluster = pd.read_csv('Output/cluster.csv', sep = ',', na_filter = False, header = 0, index_col = 0)",
      "start_time": "2021-01-21T22:26:57.189Z"
     },
     {
      "end_time": "2021-01-21T22:37:30.587Z",
      "execution_time": "3.53s",
      "outputs": [],
      "source": "alignment = pd.read_csv('Output/alignment.csv', sep = ',', na_filter = False, header = 0, index_col = 0)\ncluster = pd.read_csv('Output/cluster.csv', sep = ',', na_filter = False, header = 0, index_col = 0)",
      "start_time": "2021-01-21T22:37:27.053Z"
     },
     {
      "end_time": "2021-01-22T10:58:19.832Z",
      "execution_time": "8ms",
      "outputs": [
       {
        "ename": "NameError",
        "evalue": "name 'pd' is not defined",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-2-df650467374c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malignment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output/alignment.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_filter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output/cluster.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_filter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
         "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
        ]
       }
      ],
      "source": "alignment = pd.read_csv('Output/alignment.csv', sep = ',', na_filter = False, header = 0, index_col = 0)\ncluster = pd.read_csv('Output/cluster.csv', sep = ',', na_filter = False, header = 0, index_col = 0)",
      "start_time": "2021-01-22T10:58:19.824Z"
     },
     {
      "end_time": "2021-01-22T10:58:40.270Z",
      "execution_time": "4.39s",
      "outputs": [],
      "source": "alignment = pd.read_csv('Output/alignment.csv', sep = ',', na_filter = False, header = 0, index_col = 0)\ncluster = pd.read_csv('Output/cluster.csv', sep = ',', na_filter = False, header = 0, index_col = 0)",
      "start_time": "2021-01-22T10:58:35.882Z"
     },
     {
      "end_time": "2021-01-22T10:58:53.984Z",
      "execution_time": "3.77s",
      "outputs": [],
      "source": "alignment = pd.read_csv('Output/alignment.csv', sep = ',', na_filter = False, header = 0, index_col = 0)\ncluster = pd.read_csv('Output/cluster.csv', sep = ',', na_filter = False, header = 0, index_col = 0)",
      "start_time": "2021-01-22T10:58:50.214Z"
     }
    ]
   },
   "outputs": [],
   "source": [
    "alignment = pd.read_csv('Output/alignment.csv', sep = ',', na_filter = False, header = 0, index_col = 0)\n",
    "cluster = pd.read_csv('Output/cluster.csv', sep = ',', na_filter = False, header = 0, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecutionTime": {
     "end_time": "2021-01-21T22:37:31.374814Z",
     "start_time": "2021-01-21T22:37:31.355885Z"
    },
    "provenance": [
     {
      "end_time": "2021-01-21T22:27:50.637Z",
      "execution_time": "10ms",
      "outputs": [
       {
        "data": {
         "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>segment</th>\n      <th>cluster</th>\n      <th>alignment</th>\n    </tr>\n    <tr>\n      <th>accession</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>&gt;MK265637</th>\n      <td>1</td>\n      <td>0</td>\n      <td>tcaaatatattcaatatggagagaataaaagagctgagagacctaa...</td>\n    </tr>\n    <tr>\n      <th>&gt;MK265655</th>\n      <td>1</td>\n      <td>0</td>\n      <td>tcaaatatattcaatatggagagaataaaagagctgagagacctaa...</td>\n    </tr>\n    <tr>\n      <th>&gt;MK364024</th>\n      <td>1</td>\n      <td>0</td>\n      <td>tcaaatatattcaatatggagagaataaaagagctgagagacctaa...</td>\n    </tr>\n    <tr>\n      <th>&gt;MK364444</th>\n      <td>1</td>\n      <td>0</td>\n      <td>tcaaatatattcaatatggagagaataaaagagctgagagacctaa...</td>\n    </tr>\n    <tr>\n      <th>&gt;MK364640</th>\n      <td>1</td>\n      <td>0</td>\n      <td>tcaaatatattcaatatggagagaataaaagagctgagagacctaa...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>&gt;MH598129</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>------------gtgacaaaaacataatggattccaacactgtgtc...</td>\n    </tr>\n    <tr>\n      <th>&gt;MH620640</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>agcaaaagcagggtgacaaaaacataatggattccaacactgtgtc...</td>\n    </tr>\n    <tr>\n      <th>&gt;MK902671</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>--------------------------atggattccaacactgtgtc...</td>\n    </tr>\n    <tr>\n      <th>&gt;MN055190</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>agcaaaagcagggtgacaaaaacataatggattccaacactgtgtc...</td>\n    </tr>\n    <tr>\n      <th>&gt;U96739</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>------------gtgacaaagacgtaatggactccaacactgtgtc...</td>\n    </tr>\n  </tbody>\n</table>\n<p>442591 rows  3 columns</p>\n</div>",
         "text/plain": "           segment  cluster                                          alignment\naccession                                                                     \n>MK265637        1        0  tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK265655        1        0  tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK364024        1        0  tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK364444        1        0  tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK364640        1        0  tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n...            ...      ...                                                ...\n>MH598129        8     7055  ------------gtgacaaaaacataatggattccaacactgtgtc...\n>MH620640        8     7055  agcaaaagcagggtgacaaaaacataatggattccaacactgtgtc...\n>MK902671        8     7055  --------------------------atggattccaacactgtgtc...\n>MN055190        8     7055  agcaaaagcagggtgacaaaaacataatggattccaacactgtgtc...\n>U96739          8     7055  ------------gtgacaaagacgtaatggactccaacactgtgtc...\n\n[442591 rows x 3 columns]"
        },
        "execution_count": 11,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "alignment",
      "start_time": "2021-01-21T22:27:50.627Z"
     },
     {
      "end_time": "2021-01-21T22:37:31.374Z",
      "execution_time": "19ms",
      "outputs": [
       {
        "data": {
         "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>segment</th>\n      <th>cluster</th>\n      <th>alignment</th>\n    </tr>\n    <tr>\n      <th>accession</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>&gt;MK265637</th>\n      <td>1</td>\n      <td>0</td>\n      <td>tcaaatatattcaatatggagagaataaaagagctgagagacctaa...</td>\n    </tr>\n    <tr>\n      <th>&gt;MK265655</th>\n      <td>1</td>\n      <td>0</td>\n      <td>tcaaatatattcaatatggagagaataaaagagctgagagacctaa...</td>\n    </tr>\n    <tr>\n      <th>&gt;MK364024</th>\n      <td>1</td>\n      <td>0</td>\n      <td>tcaaatatattcaatatggagagaataaaagagctgagagacctaa...</td>\n    </tr>\n    <tr>\n      <th>&gt;MK364444</th>\n      <td>1</td>\n      <td>0</td>\n      <td>tcaaatatattcaatatggagagaataaaagagctgagagacctaa...</td>\n    </tr>\n    <tr>\n      <th>&gt;MK364640</th>\n      <td>1</td>\n      <td>0</td>\n      <td>tcaaatatattcaatatggagagaataaaagagctgagagacctaa...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>&gt;MH598129</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>------------gtgacaaaaacataatggattccaacactgtgtc...</td>\n    </tr>\n    <tr>\n      <th>&gt;MH620640</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>agcaaaagcagggtgacaaaaacataatggattccaacactgtgtc...</td>\n    </tr>\n    <tr>\n      <th>&gt;MK902671</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>--------------------------atggattccaacactgtgtc...</td>\n    </tr>\n    <tr>\n      <th>&gt;MN055190</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>agcaaaagcagggtgacaaaaacataatggattccaacactgtgtc...</td>\n    </tr>\n    <tr>\n      <th>&gt;U96739</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>------------gtgacaaagacgtaatggactccaacactgtgtc...</td>\n    </tr>\n  </tbody>\n</table>\n<p>442591 rows  3 columns</p>\n</div>",
         "text/plain": "           segment  cluster                                          alignment\naccession                                                                     \n>MK265637        1        0  tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK265655        1        0  tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK364024        1        0  tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK364444        1        0  tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK364640        1        0  tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n...            ...      ...                                                ...\n>MH598129        8     7055  ------------gtgacaaaaacataatggattccaacactgtgtc...\n>MH620640        8     7055  agcaaaagcagggtgacaaaaacataatggattccaacactgtgtc...\n>MK902671        8     7055  --------------------------atggattccaacactgtgtc...\n>MN055190        8     7055  agcaaaagcagggtgacaaaaacataatggattccaacactgtgtc...\n>U96739          8     7055  ------------gtgacaaagacgtaatggactccaacactgtgtc...\n\n[442591 rows x 3 columns]"
        },
        "execution_count": 4,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "alignment",
      "start_time": "2021-01-21T22:37:31.355Z"
     }
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>cluster</th>\n",
       "      <th>alignment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accession</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&gt;MK265637</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tcaaatatattcaatatggagagaataaaagagctgagagacctaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;MK265655</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tcaaatatattcaatatggagagaataaaagagctgagagacctaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;MK364024</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tcaaatatattcaatatggagagaataaaagagctgagagacctaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;MK364444</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tcaaatatattcaatatggagagaataaaagagctgagagacctaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;MK364640</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tcaaatatattcaatatggagagaataaaagagctgagagacctaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;MH598129</th>\n",
       "      <td>8</td>\n",
       "      <td>7055</td>\n",
       "      <td>------------gtgacaaaaacataatggattccaacactgtgtc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;MH620640</th>\n",
       "      <td>8</td>\n",
       "      <td>7055</td>\n",
       "      <td>agcaaaagcagggtgacaaaaacataatggattccaacactgtgtc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;MK902671</th>\n",
       "      <td>8</td>\n",
       "      <td>7055</td>\n",
       "      <td>--------------------------atggattccaacactgtgtc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;MN055190</th>\n",
       "      <td>8</td>\n",
       "      <td>7055</td>\n",
       "      <td>agcaaaagcagggtgacaaaaacataatggattccaacactgtgtc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;U96739</th>\n",
       "      <td>8</td>\n",
       "      <td>7055</td>\n",
       "      <td>------------gtgacaaagacgtaatggactccaacactgtgtc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442591 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           segment  cluster                                          alignment\n",
       "accession                                                                     \n",
       ">MK265637        1        0  tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n",
       ">MK265655        1        0  tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n",
       ">MK364024        1        0  tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n",
       ">MK364444        1        0  tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n",
       ">MK364640        1        0  tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n",
       "...            ...      ...                                                ...\n",
       ">MH598129        8     7055  ------------gtgacaaaaacataatggattccaacactgtgtc...\n",
       ">MH620640        8     7055  agcaaaagcagggtgacaaaaacataatggattccaacactgtgtc...\n",
       ">MK902671        8     7055  --------------------------atggattccaacactgtgtc...\n",
       ">MN055190        8     7055  agcaaaagcagggtgacaaaaacataatggattccaacactgtgtc...\n",
       ">U96739          8     7055  ------------gtgacaaagacgtaatggactccaacactgtgtc...\n",
       "\n",
       "[442591 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecutionTime": {
     "end_time": "2021-01-22T10:58:56.359139Z",
     "start_time": "2021-01-22T10:58:56.341850Z"
    },
    "provenance": [
     {
      "end_time": "2021-01-21T22:27:56.916Z",
      "execution_time": "16ms",
      "outputs": [
       {
        "data": {
         "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>segment</th>\n      <th>cluster</th>\n      <th>centroid</th>\n      <th>subtype</th>\n    </tr>\n    <tr>\n      <th>accession</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>&gt;KF918700</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>H1N1</td>\n    </tr>\n    <tr>\n      <th>&gt;HQ263280</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>H1N1</td>\n    </tr>\n    <tr>\n      <th>&gt;CY064994</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>H1N1</td>\n    </tr>\n    <tr>\n      <th>&gt;LN846491</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>H1N1</td>\n    </tr>\n    <tr>\n      <th>&gt;CY065595</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>H1N1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY102078</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>False</td>\n      <td>mixed</td>\n    </tr>\n    <tr>\n      <th>&gt;CY136447</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>False</td>\n      <td>mixed</td>\n    </tr>\n    <tr>\n      <th>&gt;CY116805</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>False</td>\n      <td>mixed</td>\n    </tr>\n    <tr>\n      <th>&gt;CY181173</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>False</td>\n      <td>mixed</td>\n    </tr>\n    <tr>\n      <th>&gt;CY177616</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>False</td>\n      <td>mixed</td>\n    </tr>\n  </tbody>\n</table>\n<p>443159 rows  4 columns</p>\n</div>",
         "text/plain": "           segment  cluster  centroid subtype\naccession                                    \n>KF918700        1       -1     False    H1N1\n>HQ263280        1       -1     False    H1N1\n>CY064994        1       -1     False    H1N1\n>LN846491        1       -1     False    H1N1\n>CY065595        1       -1     False    H1N1\n...            ...      ...       ...     ...\n>CY102078        8     7055     False   mixed\n>CY136447        8     7055     False   mixed\n>CY116805        8     7055     False   mixed\n>CY181173        8     7055     False   mixed\n>CY177616        8     7055     False   mixed\n\n[443159 rows x 4 columns]"
        },
        "execution_count": 12,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "cluster",
      "start_time": "2021-01-21T22:27:56.900Z"
     },
     {
      "end_time": "2021-01-21T22:37:31.956Z",
      "execution_time": "14ms",
      "outputs": [
       {
        "data": {
         "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>segment</th>\n      <th>cluster</th>\n      <th>centroid</th>\n      <th>subtype</th>\n    </tr>\n    <tr>\n      <th>accession</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>&gt;KF918700</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>H1N1</td>\n    </tr>\n    <tr>\n      <th>&gt;HQ263280</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>H1N1</td>\n    </tr>\n    <tr>\n      <th>&gt;CY064994</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>H1N1</td>\n    </tr>\n    <tr>\n      <th>&gt;LN846491</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>H1N1</td>\n    </tr>\n    <tr>\n      <th>&gt;CY065595</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>H1N1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY102078</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>False</td>\n      <td>mixed</td>\n    </tr>\n    <tr>\n      <th>&gt;CY136447</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>False</td>\n      <td>mixed</td>\n    </tr>\n    <tr>\n      <th>&gt;CY116805</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>False</td>\n      <td>mixed</td>\n    </tr>\n    <tr>\n      <th>&gt;CY181173</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>False</td>\n      <td>mixed</td>\n    </tr>\n    <tr>\n      <th>&gt;CY177616</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>False</td>\n      <td>mixed</td>\n    </tr>\n  </tbody>\n</table>\n<p>443159 rows  4 columns</p>\n</div>",
         "text/plain": "           segment  cluster  centroid subtype\naccession                                    \n>KF918700        1       -1     False    H1N1\n>HQ263280        1       -1     False    H1N1\n>CY064994        1       -1     False    H1N1\n>LN846491        1       -1     False    H1N1\n>CY065595        1       -1     False    H1N1\n...            ...      ...       ...     ...\n>CY102078        8     7055     False   mixed\n>CY136447        8     7055     False   mixed\n>CY116805        8     7055     False   mixed\n>CY181173        8     7055     False   mixed\n>CY177616        8     7055     False   mixed\n\n[443159 rows x 4 columns]"
        },
        "execution_count": 5,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "cluster",
      "start_time": "2021-01-21T22:37:31.942Z"
     },
     {
      "end_time": "2021-01-22T10:58:56.359Z",
      "execution_time": "18ms",
      "outputs": [
       {
        "data": {
         "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>segment</th>\n      <th>cluster</th>\n      <th>centroid</th>\n      <th>subtype</th>\n    </tr>\n    <tr>\n      <th>accession</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>&gt;KF918700</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>H1N1</td>\n    </tr>\n    <tr>\n      <th>&gt;HQ263280</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>H1N1</td>\n    </tr>\n    <tr>\n      <th>&gt;CY064994</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>H1N1</td>\n    </tr>\n    <tr>\n      <th>&gt;LN846491</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>H1N1</td>\n    </tr>\n    <tr>\n      <th>&gt;CY065595</th>\n      <td>1</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>H1N1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY102078</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>False</td>\n      <td>mixed</td>\n    </tr>\n    <tr>\n      <th>&gt;CY136447</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>False</td>\n      <td>mixed</td>\n    </tr>\n    <tr>\n      <th>&gt;CY116805</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>False</td>\n      <td>mixed</td>\n    </tr>\n    <tr>\n      <th>&gt;CY181173</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>False</td>\n      <td>mixed</td>\n    </tr>\n    <tr>\n      <th>&gt;CY177616</th>\n      <td>8</td>\n      <td>7055</td>\n      <td>False</td>\n      <td>mixed</td>\n    </tr>\n  </tbody>\n</table>\n<p>443159 rows  4 columns</p>\n</div>",
         "text/plain": "           segment  cluster  centroid subtype\naccession                                    \n>KF918700        1       -1     False    H1N1\n>HQ263280        1       -1     False    H1N1\n>CY064994        1       -1     False    H1N1\n>LN846491        1       -1     False    H1N1\n>CY065595        1       -1     False    H1N1\n...            ...      ...       ...     ...\n>CY102078        8     7055     False   mixed\n>CY136447        8     7055     False   mixed\n>CY116805        8     7055     False   mixed\n>CY181173        8     7055     False   mixed\n>CY177616        8     7055     False   mixed\n\n[443159 rows x 4 columns]"
        },
        "execution_count": 7,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "cluster",
      "start_time": "2021-01-22T10:58:56.341Z"
     }
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>cluster</th>\n",
       "      <th>centroid</th>\n",
       "      <th>subtype</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accession</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&gt;KF918700</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>H1N1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;HQ263280</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>H1N1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;CY064994</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>H1N1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;LN846491</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>H1N1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;CY065595</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>H1N1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;CY102078</th>\n",
       "      <td>8</td>\n",
       "      <td>7055</td>\n",
       "      <td>False</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;CY136447</th>\n",
       "      <td>8</td>\n",
       "      <td>7055</td>\n",
       "      <td>False</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;CY116805</th>\n",
       "      <td>8</td>\n",
       "      <td>7055</td>\n",
       "      <td>False</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;CY181173</th>\n",
       "      <td>8</td>\n",
       "      <td>7055</td>\n",
       "      <td>False</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;CY177616</th>\n",
       "      <td>8</td>\n",
       "      <td>7055</td>\n",
       "      <td>False</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>443159 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           segment  cluster  centroid subtype\n",
       "accession                                    \n",
       ">KF918700        1       -1     False    H1N1\n",
       ">HQ263280        1       -1     False    H1N1\n",
       ">CY064994        1       -1     False    H1N1\n",
       ">LN846491        1       -1     False    H1N1\n",
       ">CY065595        1       -1     False    H1N1\n",
       "...            ...      ...       ...     ...\n",
       ">CY102078        8     7055     False   mixed\n",
       ">CY136447        8     7055     False   mixed\n",
       ">CY116805        8     7055     False   mixed\n",
       ">CY181173        8     7055     False   mixed\n",
       ">CY177616        8     7055     False   mixed\n",
       "\n",
       "[443159 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecutionTime": {
     "end_time": "2021-01-22T11:04:26.082957Z",
     "start_time": "2021-01-22T11:04:26.043022Z"
    },
    "provenance": [
     {
      "end_time": "2021-01-21T22:29:44.253Z",
      "execution_time": "35ms",
      "outputs": [
       {
        "data": {
         "text/plain": "accession\n>MK364444    H1N1\n>MK265655    H1N1\n>MK855778    H1N1\n>MK265637    H1N1\n>MK364640    H1N1\n>MK557056    H1N1\n>MK631071    H1N1\n>MK557104    H1N1\n>MK364024    H1N1\n>MN003999    H1N1\n>MK398930    H1N1\n>MK999711    H1N1\n>MK716007    H1N1\n>MK999724    H1N1\n>MK999732    H1N1\n>MN004119    H1N1\n>MK398978    H1N1\n>MK475204    H1N1\n>MK623722    H1N1\n>MK676657    H1N1\n>MK623770    H1N1\n>MK631487    H1N1\n>MK623786    H1N1\n>MN230052    H1N1\n>MK631663    H1N1\n>MK773450    H1N1\nName: subtype, dtype: object"
        },
        "execution_count": 13,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "cluster.query('cluster == 0')['subtype']",
      "start_time": "2021-01-21T22:29:44.218Z"
     },
     {
      "end_time": "2021-01-21T22:30:13.049Z",
      "execution_time": "43ms",
      "outputs": [
       {
        "data": {
         "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>segment</th>\n      <th>cluster</th>\n      <th>centroid</th>\n      <th>subtype</th>\n    </tr>\n    <tr>\n      <th>accession</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>&gt;KX006018</th>\n      <td>4</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>H1N1</td>\n    </tr>\n    <tr>\n      <th>&gt;KY487123</th>\n      <td>4</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>H1N1</td>\n    </tr>\n    <tr>\n      <th>&gt;KX915716</th>\n      <td>4</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>H1N1</td>\n    </tr>\n    <tr>\n      <th>&gt;CY129622</th>\n      <td>4</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>H1N1</td>\n    </tr>\n    <tr>\n      <th>&gt;CY065872</th>\n      <td>4</td>\n      <td>-1</td>\n      <td>False</td>\n      <td>H1N1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>&gt;CY264673</th>\n      <td>4</td>\n      <td>3457</td>\n      <td>False</td>\n      <td>H3N2</td>\n    </tr>\n    <tr>\n      <th>&gt;KM064263</th>\n      <td>4</td>\n      <td>3457</td>\n      <td>False</td>\n      <td>H3N2</td>\n    </tr>\n    <tr>\n      <th>&gt;CY264697</th>\n      <td>4</td>\n      <td>3457</td>\n      <td>False</td>\n      <td>H3N2</td>\n    </tr>\n    <tr>\n      <th>&gt;CY264681</th>\n      <td>4</td>\n      <td>3457</td>\n      <td>False</td>\n      <td>H3N2</td>\n    </tr>\n    <tr>\n      <th>&gt;KM064507</th>\n      <td>4</td>\n      <td>3457</td>\n      <td>False</td>\n      <td>H3N2</td>\n    </tr>\n  </tbody>\n</table>\n<p>55281 rows  4 columns</p>\n</div>",
         "text/plain": "           segment  cluster  centroid subtype\naccession                                    \n>KX006018        4       -1     False    H1N1\n>KY487123        4       -1     False    H1N1\n>KX915716        4       -1     False    H1N1\n>CY129622        4       -1     False    H1N1\n>CY065872        4       -1     False    H1N1\n...            ...      ...       ...     ...\n>CY264673        4     3457     False    H3N2\n>KM064263        4     3457     False    H3N2\n>CY264697        4     3457     False    H3N2\n>CY264681        4     3457     False    H3N2\n>KM064507        4     3457     False    H3N2\n\n[55281 rows x 4 columns]"
        },
        "execution_count": 14,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "cluster.query('segment == 4')#['subtype']",
      "start_time": "2021-01-21T22:30:13.006Z"
     },
     {
      "end_time": "2021-01-21T22:31:59.155Z",
      "execution_time": "46ms",
      "outputs": [
       {
        "data": {
         "text/plain": "-1"
        },
        "execution_count": 15,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "cluster.query('segment == 4')['cluster'].min()#['subtype']",
      "start_time": "2021-01-21T22:31:59.109Z"
     },
     {
      "end_time": "2021-01-21T22:32:21.402Z",
      "execution_time": "3ms",
      "outputs": [
       {
        "ename": "SyntaxError",
        "evalue": "invalid syntax (<ipython-input-16-63cac45a5326>, line 1)",
        "output_type": "error",
        "traceback": [
         "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-63cac45a5326>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    cluster.query('segment == 4 & cluster != -1)['cluster'].min()#['subtype']\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
        ]
       }
      ],
      "source": "cluster.query('segment == 4 & cluster != -1)['cluster'].min()#['subtype']",
      "start_time": "2021-01-21T22:32:21.399Z"
     },
     {
      "end_time": "2021-01-21T22:32:25.398Z",
      "execution_time": "39ms",
      "outputs": [
       {
        "data": {
         "text/plain": "2642"
        },
        "execution_count": 17,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "cluster.query('segment == 4 & cluster != -1')['cluster'].min()#['subtype']",
      "start_time": "2021-01-21T22:32:25.359Z"
     },
     {
      "end_time": "2021-01-21T22:32:43.158Z",
      "execution_time": "36ms",
      "outputs": [
       {
        "data": {
         "text/plain": "3457"
        },
        "execution_count": 18,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "cluster.query('segment == 4 & cluster != -1')['cluster'].max()",
      "start_time": "2021-01-21T22:32:43.122Z"
     },
     {
      "end_time": "2021-01-21T22:32:59.816Z",
      "execution_time": "36ms",
      "outputs": [
       {
        "data": {
         "text/plain": "2642"
        },
        "execution_count": 19,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "cluster.query('segment == 4 & cluster != -1')['cluster'].min() ",
      "start_time": "2021-01-21T22:32:59.780Z"
     },
     {
      "end_time": "2021-01-21T22:37:32.803Z",
      "execution_time": "40ms",
      "outputs": [
       {
        "data": {
         "text/plain": "2642"
        },
        "execution_count": 6,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "cluster.query('segment == 4 & cluster != -1')['cluster'].min() ",
      "start_time": "2021-01-21T22:37:32.763Z"
     },
     {
      "end_time": "2021-01-22T11:04:26.082Z",
      "execution_time": "39ms",
      "outputs": [
       {
        "data": {
         "text/plain": "3457"
        },
        "execution_count": 10,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "cluster.query('segment == 4 & cluster != -1')['cluster'].max() ",
      "start_time": "2021-01-22T11:04:26.043Z"
     }
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3457"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.query('segment == 4 & cluster != -1')['cluster'].max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecutionTime": {
     "end_time": "2021-01-22T11:04:35.956232Z",
     "start_time": "2021-01-22T11:04:35.916332Z"
    },
    "provenance": [
     {
      "end_time": "2021-01-21T22:33:21.105Z",
      "execution_time": "34ms",
      "outputs": [
       {
        "data": {
         "text/plain": "2642"
        },
        "execution_count": 20,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "cluster.query('segment == 4 & cluster == 2642')['cluster'].min() ",
      "start_time": "2021-01-21T22:33:21.071Z"
     },
     {
      "end_time": "2021-01-21T22:33:30.323Z",
      "execution_time": "35ms",
      "outputs": [
       {
        "data": {
         "text/plain": "accession\n>CY220423    H3N2\n>CY224886    H3N2\n>CY234192    H3N2\n>CY238899    H3N2\n>CY239920    H3N2\n             ... \n>CY230482    H3N2\n>CY228821    H3N2\n>CY239721    H3N2\n>CY228829    H3N2\n>CY230874    H3N2\nName: subtype, Length: 190, dtype: object"
        },
        "execution_count": 21,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "cluster.query('segment == 4 & cluster == 2642')['subtype']",
      "start_time": "2021-01-21T22:33:30.288Z"
     },
     {
      "end_time": "2021-01-21T22:33:37.356Z",
      "execution_time": "36ms",
      "outputs": [
       {
        "data": {
         "text/plain": "accession\n>CY101258     H3N2\n>CY102404     H3N2\n>CY102364     H3N2\n>CY102380     H3N2\n>CY102396     H3N2\n>CY102439     H3N2\n>CY102447     H3N2\n>CY102455     H3N2\n>CY102476     H3N2\n>CY102484     H3N2\n>CY102492     H3N2\n>CY102500     H3N2\n>CY102508     H3N2\n>CY102516     H3N2\n>CY102574     H3N2\n>CY102348     H3N2\n>CY102356     H3N2\n>CY102423     H3N8\n>CY102524     H3N8\n>CY102300     H3N8\n>CY102372     H3N8\n>CY102388     H3N8\n>CY102431     H3N8\n>CY102549     H3N8\n>CY102558     H3N8\n>CY102566     H3N8\n>CY102582     H3N8\n>CY101266    mixed\n>CY102412    mixed\n>CY127525    mixed\n>CY101275    mixed\n>CY102464    mixed\n>CY101284    mixed\n>CY102540    mixed\nName: subtype, dtype: object"
        },
        "execution_count": 22,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "cluster.query('segment == 4 & cluster == 2643')['subtype']",
      "start_time": "2021-01-21T22:33:37.320Z"
     },
     {
      "end_time": "2021-01-21T22:37:34.427Z",
      "execution_time": "34ms",
      "outputs": [
       {
        "data": {
         "text/plain": "accession\n>CY101258     H3N2\n>CY102404     H3N2\n>CY102364     H3N2\n>CY102380     H3N2\n>CY102396     H3N2\n>CY102439     H3N2\n>CY102447     H3N2\n>CY102455     H3N2\n>CY102476     H3N2\n>CY102484     H3N2\n>CY102492     H3N2\n>CY102500     H3N2\n>CY102508     H3N2\n>CY102516     H3N2\n>CY102574     H3N2\n>CY102348     H3N2\n>CY102356     H3N2\n>CY102423     H3N8\n>CY102524     H3N8\n>CY102300     H3N8\n>CY102372     H3N8\n>CY102388     H3N8\n>CY102431     H3N8\n>CY102549     H3N8\n>CY102558     H3N8\n>CY102566     H3N8\n>CY102582     H3N8\n>CY101266    mixed\n>CY102412    mixed\n>CY127525    mixed\n>CY101275    mixed\n>CY102464    mixed\n>CY101284    mixed\n>CY102540    mixed\nName: subtype, dtype: object"
        },
        "execution_count": 7,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "cluster.query('segment == 4 & cluster == 2643')['subtype']",
      "start_time": "2021-01-21T22:37:34.393Z"
     },
     {
      "end_time": "2021-01-22T10:58:14.576Z",
      "execution_time": "42ms",
      "outputs": [
       {
        "ename": "NameError",
        "evalue": "name 'cluster' is not defined",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-1-f60c9587300b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'segment == 4 & cluster == 26460'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subtype'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
         "\u001b[0;31mNameError\u001b[0m: name 'cluster' is not defined"
        ]
       }
      ],
      "source": "cluster.query('segment == 4 & cluster == 26460')['subtype']",
      "start_time": "2021-01-22T10:58:14.534Z"
     },
     {
      "end_time": "2021-01-22T10:58:44.515Z",
      "execution_time": "44ms",
      "outputs": [
       {
        "data": {
         "text/plain": "Series([], Name: subtype, dtype: object)"
        },
        "execution_count": 5,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "cluster.query('segment == 4 & cluster == 26460')['subtype']",
      "start_time": "2021-01-22T10:58:44.471Z"
     },
     {
      "end_time": "2021-01-22T10:59:05.637Z",
      "execution_time": "41ms",
      "outputs": [
       {
        "data": {
         "text/plain": "Series([], Name: subtype, dtype: object)"
        },
        "execution_count": 8,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "cluster.query('segment == 4 & cluster == 26460')['subtype']",
      "start_time": "2021-01-22T10:59:05.596Z"
     },
     {
      "end_time": "2021-01-22T10:59:12.718Z",
      "execution_time": "37ms",
      "outputs": [
       {
        "data": {
         "text/plain": "accession\n>MF613821    H10N4\n>MF046534    H10N4\n>MF046332    H10N4\n>MF046223    H10N4\n>CY241030    H10N5\n>MF046303    H10N5\n>MF613859    H10N5\n>MF046454    H10N5\n>MF046181    H10N5\n>MF046290    H10N5\n>MG599650    H10N5\n>MF046538    H10N5\n>MF046312    H10N5\n>MF046417    H10N5\n>MF613707    H10N5\n>MF613854    H10N5\n>MG599670    H10N5\n>MF046288    H10N5\n>CY241925    mixed\nName: subtype, dtype: object"
        },
        "execution_count": 9,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "cluster.query('segment == 4 & cluster == 2670')['subtype']",
      "start_time": "2021-01-22T10:59:12.681Z"
     },
     {
      "end_time": "2021-01-22T11:04:30.793Z",
      "execution_time": "37ms",
      "outputs": [
       {
        "data": {
         "text/plain": "accession\n>MT303224    H1N1\n>MT167385    H1N1\n>MT058055    H1N1\n>MT058151    H1N1\n>MT167521    H1N1\n>MT244443    H1N1\n>MT105931    H1N1\n>MT167825    H1N1\n>MT058341    H1N1\n>MT058535    H1N1\n>MT168040    H1N1\n>MT244831    H1N1\n>MT167073    H1N1\nName: subtype, dtype: object"
        },
        "execution_count": 11,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "cluster.query('segment == 4 & cluster == 3200')['subtype']",
      "start_time": "2021-01-22T11:04:30.756Z"
     },
     {
      "end_time": "2021-01-22T11:04:35.956Z",
      "execution_time": "40ms",
      "outputs": [
       {
        "data": {
         "text/plain": "accession\n>CY053174    H1N1\n>CY053190    H1N1\n>CY053198    H1N1\n>CY053230    H1N1\n>CY053222    H1N1\n             ... \n>CY051463    H1N1\n>CY051455    H1N1\n>CY051447    H1N1\n>CY051471    H1N1\n>CY051487    H1N1\nName: subtype, Length: 186, dtype: object"
        },
        "execution_count": 12,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "cluster.query('segment == 4 & cluster == 3210')['subtype']",
      "start_time": "2021-01-22T11:04:35.916Z"
     }
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accession\n",
       ">CY053174    H1N1\n",
       ">CY053190    H1N1\n",
       ">CY053198    H1N1\n",
       ">CY053230    H1N1\n",
       ">CY053222    H1N1\n",
       "             ... \n",
       ">CY051463    H1N1\n",
       ">CY051455    H1N1\n",
       ">CY051447    H1N1\n",
       ">CY051471    H1N1\n",
       ">CY051487    H1N1\n",
       "Name: subtype, Length: 186, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.query('segment == 4 & cluster == 3210')['subtype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecutionTime": {
     "end_time": "2021-01-21T22:37:37.364104Z",
     "start_time": "2021-01-21T22:37:37.330323Z"
    },
    "provenance": [
     {
      "end_time": "2021-01-21T22:27:22.902Z",
      "execution_time": "38ms",
      "outputs": [
       {
        "data": {
         "text/plain": "accession\n>MK265637    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK265655    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK364024    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK364444    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK364640    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK398930    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK398978    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK475204    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK557056    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK557104    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK623722    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK623770    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK623786    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK631071    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK631487    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK631663    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK676657    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK716007    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK773450    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK855778    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK999711    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK999724    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MK999732    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MN003999    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MN004119    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\n>MN230052    tcaaatatattcaatatggagagaataaaagagctgagagacctaa...\nName: alignment, dtype: object"
        },
        "execution_count": 10,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "alignment.query('cluster == 0')['alignment']",
      "start_time": "2021-01-21T22:27:22.864Z"
     },
     {
      "end_time": "2021-01-21T22:37:22.216Z",
      "execution_time": "96ms",
      "outputs": [
       {
        "ename": "NameError",
        "evalue": "name 'alignment' is not defined",
        "output_type": "error",
        "traceback": [
         "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
         "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
         "\u001b[0;32m<ipython-input-2-fe084354993d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malignment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cluster == 20'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alignment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
         "\u001b[0;31mNameError\u001b[0m: name 'alignment' is not defined"
        ]
       }
      ],
      "source": "alignment.query('cluster == 20')['alignment']",
      "start_time": "2021-01-21T22:37:22.120Z"
     },
     {
      "end_time": "2021-01-21T22:37:37.364Z",
      "execution_time": "34ms",
      "outputs": [
       {
        "data": {
         "text/plain": "accession\n>CY212951    tcaattatattcagcatggaaagaataaaagaactacggaatctaa...\n>CY213159    tcaattatattcagcatggaaagaataaaagaactacggaatctaa...\n>CY213951    tcaattatattcagcatggaaagaataaaagaactacggaatctaa...\n>CY214159    tcaattatattcagcatggaaagaataaaagaactacggaatctaa...\n>CY214583    tcaattatattcagcatggaaagaataaaagaactacggaatctaa...\n                                   ...                        \n>MG928474    tcaattatattcagcatggaaagaataaaagaactacggaatctaa...\n>MG928482    tcaattatattcagcatggaaagaataaaagaactacggaatctaa...\n>MH079590    tcaattatattcagcatggaaagaataaaagaactacggaatctaa...\n>MN571974    ---------------atggaaagaataaaagaactacggaatctaa...\n>MN572942    ---attatattcagcatggaaagaataaaagaactacggaatctaa...\nName: alignment, Length: 74, dtype: object"
        },
        "execution_count": 8,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": "alignment.query('cluster == 20')['alignment']",
      "start_time": "2021-01-21T22:37:37.330Z"
     }
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accession\n",
       ">CY212951    tcaattatattcagcatggaaagaataaaagaactacggaatctaa...\n",
       ">CY213159    tcaattatattcagcatggaaagaataaaagaactacggaatctaa...\n",
       ">CY213951    tcaattatattcagcatggaaagaataaaagaactacggaatctaa...\n",
       ">CY214159    tcaattatattcagcatggaaagaataaaagaactacggaatctaa...\n",
       ">CY214583    tcaattatattcagcatggaaagaataaaagaactacggaatctaa...\n",
       "                                   ...                        \n",
       ">MG928474    tcaattatattcagcatggaaagaataaaagaactacggaatctaa...\n",
       ">MG928482    tcaattatattcagcatggaaagaataaaagaactacggaatctaa...\n",
       ">MH079590    tcaattatattcagcatggaaagaataaaagaactacggaatctaa...\n",
       ">MN571974    ---------------atggaaagaataaaagaactacggaatctaa...\n",
       ">MN572942    ---attatattcagcatggaaagaataaaagaactacggaatctaa...\n",
       "Name: alignment, Length: 74, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignment.query('cluster == 20')['alignment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "provenance": [
     {
      "end_time": "Unknown",
      "execution_time": "Unknown",
      "outputs": [],
      "source": "",
      "start_time": "Unknown"
     }
    ]
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
