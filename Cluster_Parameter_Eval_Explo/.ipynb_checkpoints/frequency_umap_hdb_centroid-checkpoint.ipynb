{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools as ft\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "import re\n",
    "import csv\n",
    "import collections as co\n",
    "import itertools as it\n",
    "import umap\n",
    "import hdbscan\n",
    "import time \n",
    "#import progressbar as pb\n",
    "import scipy.spatial.distance as ssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vectorizer(object):\n",
    "    \n",
    "    #def __init__(self, procs = 8, k = 7, convert = 0, row = 0, index = [], exist = co.defaultdict(int)):\n",
    "    def __init__(self, k = 7, convert = 0):\n",
    "    \n",
    "        self.k = k\n",
    "        self.convert = convert\n",
    "        self.index = [] \n",
    "        #self.index = index\n",
    "        self.exist = co.defaultdict(int) \n",
    "        #self.exist = exist\n",
    "        self.keys = list(self.exist.keys())\n",
    "        self.col = len(self.keys)\n",
    "        self.row = 0\n",
    "        #self.row = row\n",
    "        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n",
    "        self.amino = co.defaultdict(str, {\n",
    "            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n",
    "            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n",
    "            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n",
    "            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n",
    "            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n",
    "            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n",
    "            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n",
    "            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n",
    "            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n",
    "            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n",
    "            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n",
    "            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n",
    "            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n",
    "            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n",
    "            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n",
    "            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n",
    "        })\n",
    "                \n",
    "    def translate(self, read):\n",
    "    \n",
    "        chain = ''\n",
    "\n",
    "        for i in range(len(read) - 2):\n",
    "            trip = read[i:i+3]\n",
    "            chain += self.amino[trip]\n",
    "\n",
    "        return(chain)\n",
    "    \n",
    "    \n",
    "    def adjust_to_data(self, infile):\n",
    "    \n",
    "        #widgets = ['Data adjustment:    ', pb.AnimatedMarker()] \n",
    "        #bar = pb.ProgressBar(widgets=widgets).start() \n",
    "        data = pd.read_csv(infile, chunksize = 10000, sep = ';', na_filter = False, header = None)\n",
    "        self.row = 0\n",
    "        #t = 0\n",
    "        \n",
    "        for split in data:\n",
    "\n",
    "            for info, read in split.itertuples(index=False, name=None):\n",
    "                \n",
    "                #name = info\n",
    "                name = (info.split('|')[0][1:], info.split('|')[5])\n",
    "\n",
    "                self.index.append(name)\n",
    "                del name\n",
    "                \n",
    "                if self.convert == 1:\n",
    "                    #seq = self.translate(re.sub('[^ACGT]+', '', read))\n",
    "                    seq = self.translate(read)\n",
    "                    del read\n",
    "                    \n",
    "                    num = len(seq) - self.k + 1\n",
    "                    \n",
    "                    for i in range(num):\n",
    "                        kmer = seq[i:i+self.k]\n",
    "                        self.exist[kmer] = 0\n",
    "                    \n",
    "                else:\n",
    "                    #seq = re.sub('[^ACGT]+', '', read)\n",
    "                    seq = read\n",
    "                    del read\n",
    "\n",
    "                    num = len(seq) - self.k + 1\n",
    "\n",
    "                    if re.match('^[ACGT]*$', seq): \n",
    "                        for i in range(num):\n",
    "                            kmer = seq[i:i+self.k]\n",
    "                            self.exist[kmer] = 0\n",
    "                    else:\n",
    "                        for i in range(num):\n",
    "                            kmer = seq[i:i+self.k]\n",
    "                            if re.match('^[ACGT]*$', kmer): \n",
    "                                self.exist[kmer] = 0\n",
    "\n",
    "                #t = t + 1\n",
    "                self.row = self.row + 1\n",
    "                #bar.update(t)\n",
    "            \n",
    "        self.keys = list(self.exist.keys())\n",
    "        self.col = len(self.keys)\n",
    "        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n",
    "        \n",
    "        #bar.finish()\n",
    "        del seq\n",
    "    \n",
    "    def calculate_frequence(self, infile):\n",
    "        \n",
    "        #widgets = [' [', pb.Timer(format= 'Vector calculation: %(elapsed)s'), '] ', pb.Bar('*'),' (', pb.ETA(), ') ', ] \n",
    "        #widgets = [pb.Timer(format= 'Vector calculation: '), pb.Bar('#'),' (', pb.ETA(), ')'] \n",
    "        #bar = pb.ProgressBar(max_value=self.row, widgets=widgets).start() \n",
    "        n = 0\n",
    "        #t = 0\n",
    "        data = pd.read_csv(infile, chunksize = 10000, sep = ';', na_filter = False, header = None)\n",
    "        \n",
    "        for split in data:\n",
    "\n",
    "            for info, read in split.itertuples(index=False, name=None):\n",
    "\n",
    "                if self.convert == 1:\n",
    "                    #seq = self.translate(re.sub('[^ACGT]+', '', read))\n",
    "                    seq = self.translate(read)\n",
    "                    del read\n",
    "                \n",
    "                    counts = self.exist.copy()\n",
    "                    num = len(seq) - self.k + 1\n",
    "\n",
    "                    for i in range(num):\n",
    "                        kmer = seq[i:i+self.k]\n",
    "                        counts[kmer] += 1\n",
    "                            \n",
    "                else:\n",
    "                    #seq = re.sub('[^ACGT]+', '', read)\n",
    "                    seq = read\n",
    "                    del read\n",
    "                \n",
    "                    counts = self.exist.copy()\n",
    "                    num = len(seq) - self.k + 1\n",
    "\n",
    "                    if re.match('^[ACGT]*$', seq): \n",
    "                        for i in range(num):\n",
    "                            kmer = seq[i:i+self.k]\n",
    "                            counts[kmer] += 1\n",
    "                    else:\n",
    "                        for i in range(num):\n",
    "                            kmer = seq[i:i+self.k]\n",
    "                            if re.match('^[ACGT]*$', kmer): \n",
    "                                counts[kmer] += 1\n",
    "\n",
    "                vector = np.array(list(counts.values()), dtype = \"float32\")/num\n",
    "                self.matrix[n] = vector\n",
    "                \n",
    "                n = n + 1\n",
    "                #t = t + 1\n",
    "                #bar.update(t)\n",
    "                \n",
    "                counts.clear()\n",
    "                del vector\n",
    "                del seq\n",
    "                del counts\n",
    "\n",
    "        #bar.finish()\n",
    "            \n",
    "    def get_index(self):\n",
    "        \n",
    "        return(self.index)\n",
    "    \n",
    "    \n",
    "    def get_keys(self):\n",
    "        \n",
    "        return(self.keys)\n",
    "    \n",
    "    \n",
    "    def get_matrix(self):\n",
    "        \n",
    "        return(self.matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    infile = '../../../Desktop/Masterthesis_V5/A_HA.csv'   \n",
    "    outfile = 'output.csv'\n",
    "\n",
    "    #infile = sys.argv[1]\n",
    "    #outfile = sys.argv[2]\n",
    "\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    print(\"Nucleotide k-mer frequency calculation.\", end = ' ')\n",
    "\n",
    "    freq_nt = vectorizer(k = 7, convert = 0)\n",
    "    freq_nt.adjust_to_data(infile)\n",
    "    freq_nt.calculate_frequence(infile)\n",
    "\n",
    "    matrix_nt = freq_nt.get_matrix()\n",
    "    index_nt = freq_nt.get_index()   \n",
    "    keys_nt = freq_nt.get_keys()\n",
    "\n",
    "    del freq_nt\n",
    "\n",
    "    print(\"Finished.\")\n",
    "\n",
    "    print(\"Running UMAP for dimension reduction.\", end = ' ')\n",
    "\n",
    "    matrix_nt_red = umap.UMAP(\n",
    "        n_neighbors = 60,\n",
    "        min_dist = 0.1,\n",
    "        n_components = 20,\n",
    "        random_state = 42,\n",
    "        metric = 'cosine',\n",
    "    ).fit_transform(matrix_nt)\n",
    "\n",
    "    del matrix_nt\n",
    "\n",
    "    print(\"Finished.\")\n",
    "\n",
    "    print(\"Aminoacid k-mer frequency calculation.\", end = ' ')\n",
    "\n",
    "    freq_aa = vectorizer(k = 5, convert = 1)\n",
    "    freq_aa.adjust_to_data(infile)\n",
    "    freq_aa.calculate_frequence(infile)\n",
    "\n",
    "    matrix_aa = freq_aa.get_matrix()\n",
    "    index_aa = freq_aa.get_index()\n",
    "    keys_aa = freq_aa.get_keys()\n",
    "\n",
    "    del freq_aa\n",
    "\n",
    "    print(\"Finished.\")\n",
    "\n",
    "    print(\"Running UMAP for dimension reduction.\", end = ' ')\n",
    "\n",
    "    matrix_aa_red = umap.UMAP(\n",
    "        n_neighbors = 20,\n",
    "        min_dist = 0.0,\n",
    "        n_components = 20,\n",
    "        random_state = 42,\n",
    "        metric = 'cosine',\n",
    "    ).fit_transform(matrix_aa)\n",
    "\n",
    "    del matrix_aa\n",
    "\n",
    "    print(\"Finished.\")\n",
    "\n",
    "    matrix_aa_ind = pd.DataFrame(matrix_aa_red, index = index_aa)\n",
    "    matrix_nt_ind = pd.DataFrame(matrix_nt_red, index = index_nt)\n",
    "\n",
    "    matrix = pd.concat([matrix_nt_ind, matrix_aa_ind], axis=1, copy = False, ignore_index = True) #falsches Ergebnis? checken ob ignore_index = Fehler\n",
    "\n",
    "    print(\"Running HDBscan for clustering.\", end = ' ')\n",
    "\n",
    "    #end whitespace als bessere alternative\n",
    "    #link in teams\n",
    "\n",
    "    matrix_clust = hdbscan.HDBSCAN(\n",
    "        min_samples=1, #larger the value the more conservative the clustering (more points will be declared as noise)\n",
    "        min_cluster_size=5, #minimum size that can become a cluster\n",
    "        cluster_selection_epsilon=0.75, #don't seperate clusters with a distance less than value\n",
    "        alpha=1.0, #don't mess with this\n",
    "    ).fit(matrix)\n",
    "\n",
    "    print(\"Finished.\")\n",
    "\n",
    "    print(\"Centroid extraction.\", end = ' ')\n",
    "\n",
    "    clusterlabel = matrix_clust.labels_\n",
    "\n",
    "    index = pd.MultiIndex.from_tuples(index_nt, names=[\"accession\", \"subtype\"])\n",
    "\n",
    "    clusters = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), index = index, columns = ['cluster', 'centroid'])\n",
    "\n",
    "    num = clusters['cluster'].max()+1\n",
    "    values = ['true']*num\n",
    "    accessions = []\n",
    "\n",
    "    sanity = []\n",
    "    for i in range(num):\n",
    "\n",
    "        query = clusters[clusters.cluster == i]\n",
    "        match = query.index.values.tolist()\n",
    "        sub = matrix.filter(items = match, axis=0)\n",
    "        dist = ssd.cdist(sub, sub, metric = 'cosine')\n",
    "        accessions.append(pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean().idxmin())\n",
    "\n",
    "        subs = {'H': [], 'N': []} \n",
    "        for x, y in match: \n",
    "            if re.match('^[H][0-9]+N[0-9]+$', y): \n",
    "                subs['H'].append(re.search('[H][0-9]+', y).group(0))\n",
    "                subs['N'].append(re.search('[N][0-9]+', y).group(0))\n",
    "\n",
    "        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n",
    "            sanity.append(2)\n",
    "        elif len(set(subs['H'])) == 1:\n",
    "            sanity.append(1)\n",
    "        elif len(set(subs['N'])) == 1:\n",
    "            sanity.append(0)\n",
    "        else:\n",
    "            sanity.append(3)\n",
    "\n",
    "    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n",
    "\n",
    "    #result = pd.concat([clusters, centroids], axis=1, copy = False).fillna('false')\n",
    "    clusters.update(centroids)\n",
    "\n",
    "    clusters.to_csv(outfile, index=True, header=True, sep='\\t')\n",
    "\n",
    "    stop = time.perf_counter()\n",
    "\n",
    "    print(\"Finished.\")\n",
    "    print(f\"Clustering done in {stop - start:0.4f} seconds.\")\n",
    "    diagnostic = co.Counter(clusterlabel)\n",
    "    print(f\"{str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n",
    "\n",
    "    N = sanity.count(0) + sanity.count(2)\n",
    "    H = sanity.count(1) + sanity.count(2)\n",
    "    X = sanity.count(3)\n",
    "\n",
    "    if len(sanity) == N:\n",
    "        print(\"NAs matching in all clusters.\")\n",
    "    elif len(sanity) == H:\n",
    "        print(\"HAs matching in all clusters.\")\n",
    "    elif X >= H and X >= N:\n",
    "        print(\"HAs and NAs mostly don't match in the cluster\")\n",
    "    else:\n",
    "        if N >= H:\n",
    "            print(f\"Most NAs matching in the clusters with {len(sanity) - N} exceptions.\")\n",
    "        else:\n",
    "            print(f\"Most HAs matching in the clusters with {len(sanity) - H} exceptions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nucleotide k-mer frequency calculation. Finished.\n",
      "Running UMAP for dimension reduction. "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
