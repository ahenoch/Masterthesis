{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools as ft\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "import re\n",
    "import csv\n",
    "import collections as co\n",
    "import itertools as it\n",
    "import umap\n",
    "import hdbscan\n",
    "import time \n",
    "#import progressbar as pb\n",
    "import scipy.spatial.distance as ssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wrapper(object):\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vectorizer(object):\n",
    "    \n",
    "    #def __init__(self, procs = 8, k = 7, convert = 0, row = 0, index = [], exist = co.defaultdict(int)):\n",
    "    def __init__(self, k = 7, convert = 0):\n",
    "    \n",
    "        self.k = k\n",
    "        self.convert = convert\n",
    "        self.index = [] \n",
    "        #self.index = index\n",
    "        self.exist = co.defaultdict(int) \n",
    "        #self.exist = exist\n",
    "        self.keys = list(self.exist.keys())\n",
    "        self.col = len(self.keys)\n",
    "        self.row = 0\n",
    "        #self.row = row\n",
    "        self.matrix = np.empty((self.row, self.col, ),dtype = \"float32\")\n",
    "        self.amino = co.defaultdict(str, {\n",
    "            'AAA':'K', 'AAC':'N', 'AAG':'K', 'AAT':'N',\n",
    "            'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n",
    "            'AGA':'R', 'AGC':'S', 'AGG':'R', 'AGT':'S',\n",
    "            'ATA':'I', 'ATC':'I', 'ATG':'M', 'ATT':'I',\n",
    "            'CAA':'Q', 'CAC':'H', 'CAG':'Q', 'CAT':'H',\n",
    "            'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n",
    "            'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n",
    "            'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n",
    "            'GAA':'E', 'GAC':'D', 'GAG':'E', 'GAT':'D',\n",
    "            'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n",
    "            'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n",
    "            'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',    \n",
    "            'TAA':'Y', 'TAC':'*', 'TAG':'*', 'TAT':'Y',\n",
    "            'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n",
    "            'TGA':'*', 'TGC':'C', 'TGG':'W', 'TGT':'C',\n",
    "            'TTA':'L', 'TTC':'F', 'TTG':'L', 'TTT':'F'\n",
    "        })\n",
    "                \n",
    "    def translate(self, read):\n",
    "    \n",
    "        chain = ''\n",
    "\n",
    "        for i in range(len(read) - 2):\n",
    "            trip = read[i:i+3]\n",
    "            chain += self.amino[trip]\n",
    "\n",
    "        return(chain)\n",
    "    \n",
    "    \n",
    "    def adjust_to_data(self, infile):\n",
    "    \n",
    "        #widgets = ['Data adjustment:    ', pb.AnimatedMarker()] \n",
    "        #bar = pb.ProgressBar(widgets=widgets).start() \n",
    "        data = pd.read_csv(infile, chunksize = 10000, sep = ';', na_filter = False, header = None)\n",
    "        self.row = 0\n",
    "        #t = 0\n",
    "        \n",
    "        for chunk in data:\n",
    "\n",
    "            for info, read in chunk.itertuples(index=False, name=None):\n",
    "                \n",
    "                #name = info\n",
    "                name = (info.split('|')[0][1:], info.split('|')[5])\n",
    "\n",
    "                self.index.append(name)\n",
    "                del name\n",
    "                \n",
    "                if self.convert == 1:\n",
    "                    #seq = self.translate(re.sub('[^ACGT]+', '', read))\n",
    "                    seq = self.translate(read)\n",
    "                    del read\n",
    "                    \n",
    "                    num = len(seq) - self.k + 1\n",
    "                    \n",
    "                    for i in range(num):\n",
    "                        kmer = seq[i:i+self.k]\n",
    "                        self.exist[kmer] = 0\n",
    "                    \n",
    "                else:\n",
    "                    #seq = re.sub('[^ACGT]+', '', read)\n",
    "                    seq = read\n",
    "                    del read\n",
    "\n",
    "                    num = len(seq) - self.k + 1\n",
    "\n",
    "                    if re.match('^[ACGT]*$', seq): \n",
    "                        for i in range(num):\n",
    "                            kmer = seq[i:i+self.k]\n",
    "                            self.exist[kmer] = 0\n",
    "                    else:\n",
    "                        for i in range(num):\n",
    "                            kmer = seq[i:i+self.k]\n",
    "                            if re.match('^[ACGT]*$', kmer): \n",
    "                                self.exist[kmer] = 0\n",
    "\n",
    "                #t = t + 1\n",
    "                self.row = self.row + 1\n",
    "                #bar.update(t)\n",
    "            \n",
    "        self.keys = list(self.exist.keys())\n",
    "        self.col = len(self.keys)\n",
    "        self.matrix = np.empty((self.row, self.col, ), dtype=\"float32\")\n",
    "        \n",
    "        #bar.finish()\n",
    "        del seq\n",
    "    \n",
    "    def calculate_frequence(self, infile):\n",
    "        \n",
    "        #widgets = [' [', pb.Timer(format= 'Vector calculation: %(elapsed)s'), '] ', pb.Bar('*'),' (', pb.ETA(), ') ', ] \n",
    "        #widgets = [pb.Timer(format= 'Vector calculation: '), pb.Bar('#'),' (', pb.ETA(), ')'] \n",
    "        #bar = pb.ProgressBar(max_value=self.row, widgets=widgets).start() \n",
    "        n = 0\n",
    "        #t = 0\n",
    "        data = pd.read_csv(infile, chunksize = 10000, sep = ';', na_filter = False, header = None)\n",
    "        \n",
    "        for chunk in data:\n",
    "\n",
    "            for info, read in chunk.itertuples(index=False, name=None):\n",
    "\n",
    "                if self.convert == 1:\n",
    "                    #seq = self.translate(re.sub('[^ACGT]+', '', read))\n",
    "                    seq = self.translate(read)\n",
    "                    del read\n",
    "                \n",
    "                    counts = self.exist.copy()\n",
    "                    num = len(seq) - self.k + 1\n",
    "\n",
    "                    for i in range(num):\n",
    "                        kmer = seq[i:i+self.k]\n",
    "                        counts[kmer] += 1\n",
    "                            \n",
    "                else:\n",
    "                    #seq = re.sub('[^ACGT]+', '', read)\n",
    "                    seq = read\n",
    "                    del read\n",
    "                \n",
    "                    counts = self.exist.copy()\n",
    "                    num = len(seq) - self.k + 1\n",
    "\n",
    "                    if re.match('^[ACGT]*$', seq): \n",
    "                        for i in range(num):\n",
    "                            kmer = seq[i:i+self.k]\n",
    "                            counts[kmer] += 1\n",
    "                    else:\n",
    "                        for i in range(num):\n",
    "                            kmer = seq[i:i+self.k]\n",
    "                            if re.match('^[ACGT]*$', kmer): \n",
    "                                counts[kmer] += 1\n",
    "\n",
    "                vector = np.array(list(counts.values()), dtype = \"float32\")/num\n",
    "                self.matrix[n] = vector\n",
    "                \n",
    "                n = n + 1\n",
    "                #t = t + 1\n",
    "                #bar.update(t)\n",
    "                \n",
    "                counts.clear()\n",
    "                del vector\n",
    "                del seq\n",
    "                del counts\n",
    "\n",
    "        #bar.finish()\n",
    "            \n",
    "    def get_index(self):\n",
    "        \n",
    "        return(self.index)\n",
    "    \n",
    "    \n",
    "    def get_keys(self):\n",
    "        \n",
    "        return(self.keys)\n",
    "    \n",
    "    \n",
    "    def get_matrix(self):\n",
    "        \n",
    "        return(self.matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class extractor(object):\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    print(\"Welcome. Read input and settings file.\", end = ' ')\n",
    "    #error checkup?\n",
    "    \n",
    "    infile = '../../../Desktop/Masterthesis_V5/A_HA.csv'   \n",
    "    outfile = 'output.csv'\n",
    "    setfile = 'settings.csv'\n",
    "\n",
    "    settings = pd.read_csv(setfile, sep = ',', na_filter = False, index_col = 0)\n",
    "    parameter = settings.loc[4].to_list()\n",
    "    \n",
    "    print(\"Finished.\")\n",
    "    \n",
    "    #infile = sys.argv[1]\n",
    "    #outfile = sys.argv[2]\n",
    "\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    print(\"Nucleotide k-mer frequency calculation.\", end = ' ')\n",
    "\n",
    "    freq_nt = vectorizer(k = parameter[0].item(), convert = 0)\n",
    "    freq_nt.adjust_to_data(infile)\n",
    "    freq_nt.calculate_frequence(infile)\n",
    "\n",
    "    matrix_nt = freq_nt.get_matrix()\n",
    "    index_nt = freq_nt.get_index()   \n",
    "    keys_nt = freq_nt.get_keys()\n",
    "\n",
    "    del freq_nt\n",
    "\n",
    "    print(\"Finished.\")\n",
    "\n",
    "    print(\"Running UMAP for dimension reduction.\", end = ' ')\n",
    "\n",
    "    matrix_nt_red = umap.UMAP(\n",
    "        n_neighbors = parameter[1].item(),\n",
    "        min_dist = parameter[2].item(),\n",
    "        n_components = parameter[3].item(),\n",
    "        random_state = parameter[4].item(),\n",
    "        metric = parameter[5],\n",
    "    ).fit_transform(matrix_nt)\n",
    "\n",
    "    del matrix_nt\n",
    "\n",
    "    print(\"Finished.\")\n",
    "\n",
    "    print(\"Aminoacid k-mer frequency calculation.\", end = ' ')\n",
    "\n",
    "    freq_aa = vectorizer(k = parameter[6].item(), convert = 1)\n",
    "    freq_aa.adjust_to_data(infile)\n",
    "    freq_aa.calculate_frequence(infile)\n",
    "\n",
    "    matrix_aa = freq_aa.get_matrix()\n",
    "    index_aa = freq_aa.get_index()\n",
    "    keys_aa = freq_aa.get_keys()\n",
    "\n",
    "    del freq_aa\n",
    "\n",
    "    print(\"Finished.\")\n",
    "\n",
    "    print(\"Running UMAP for dimension reduction.\", end = ' ')\n",
    "\n",
    "    matrix_aa_red = umap.UMAP(\n",
    "        n_neighbors = parameter[7].item(),\n",
    "        min_dist = parameter[8].item(),\n",
    "        n_components = parameter[9].item(),\n",
    "        random_state = parameter[10].item(),\n",
    "        metric = parameter[11],\n",
    "    ).fit_transform(matrix_aa)\n",
    "\n",
    "    del matrix_aa\n",
    "\n",
    "    print(\"Finished.\")\n",
    "\n",
    "    matrix_aa_ind = pd.DataFrame(matrix_aa_red, index = index_aa)\n",
    "    matrix_nt_ind = pd.DataFrame(matrix_nt_red, index = index_nt)\n",
    "\n",
    "    matrix = pd.concat([matrix_nt_ind, matrix_aa_ind], axis=1, copy = False, ignore_index = True) #falsches Ergebnis? checken ob ignore_index = Fehler\n",
    "\n",
    "    print(\"Running HDBscan for clustering.\", end = ' ')\n",
    "\n",
    "    #end whitespace als bessere alternative\n",
    "    #link in teams\n",
    "\n",
    "    matrix_clust = hdbscan.HDBSCAN(\n",
    "        min_samples = parameter[12].item(), #larger the value the more conservative the clustering (more points will be declared as noise)\n",
    "        min_cluster_size = parameter[13].item(), #minimum size that can become a cluster\n",
    "        cluster_selection_epsilon = parameter[14].item(), #don't seperate clusters with a distance less than value\n",
    "        alpha = parameter[15].item(), #don't mess with this\n",
    "    ).fit(matrix)\n",
    "\n",
    "    print(\"Finished.\")\n",
    "\n",
    "    print(\"Centroid extraction.\", end = ' ')\n",
    "\n",
    "    clusterlabel = matrix_clust.labels_\n",
    "\n",
    "    index = pd.MultiIndex.from_tuples(index_nt, names=[\"accession\", \"subtype\"])\n",
    "\n",
    "    clusters = pd.DataFrame(zip(clusterlabel, ['false'] * len(clusterlabel)), index = index, columns = ['cluster', 'centroid'])\n",
    "\n",
    "    num = clusters['cluster'].max()+1\n",
    "    values = ['true']*num\n",
    "    accessions = []\n",
    "\n",
    "    #mixed = []\n",
    "    #res = [i for i in x if i != 'X']\n",
    "    #'X aus der liste löschen und nochmal schauen um zu sehen, ob ansonsten alle gleich'\n",
    "    #2. print ausgabe sowas wie: ignoring mixed and nulls result in: \n",
    "    \n",
    "    sanity = []\n",
    "    for i in range(num):\n",
    "\n",
    "        query = clusters[clusters.cluster == i]\n",
    "        match = query.index.values.tolist()\n",
    "        sub = matrix.filter(items = match, axis=0)\n",
    "        dist = ssd.cdist(sub, sub, metric = parameter[16])\n",
    "        accessions.append(pd.DataFrame(dist, columns = match, index = match, dtype = 'float32').mean().idxmin())\n",
    "\n",
    "        subs = {'H': [], 'N': []} \n",
    "        for x, y in match: \n",
    "            if re.match('^[H][0-9]+N[0-9]+$', y): \n",
    "                subs['H'].append(re.search('[H][0-9]+', y).group(0))\n",
    "                subs['N'].append(re.search('[N][0-9]+', y).group(0))\n",
    "            else: #mixed types sind nicht zwingend falsch, schwierig zu bewerten ob sie beachtet werden oder nicht\n",
    "                subs['H'].append('X')\n",
    "                subs['N'].append('X')\n",
    "\n",
    "        if len(set(subs['H'])) == 1 and len(set(subs['N'])) == 1:\n",
    "            sanity.append(2)\n",
    "        elif len(set(subs['H'])) == 1:\n",
    "            sanity.append(1)\n",
    "        elif len(set(subs['N'])) == 1:\n",
    "            sanity.append(0)\n",
    "\n",
    "    centroids = pd.DataFrame(values, columns=['centroid'], index = accessions)\n",
    "\n",
    "    #result = pd.concat([clusters, centroids], axis=1, copy = False).fillna('false')\n",
    "    clusters.update(centroids)\n",
    "\n",
    "    clusters.reset_index(level=['subtype']).sort_values(by=['cluster', 'subtype']).to_csv(outfile, index=True, header=True, sep=',')\n",
    "\n",
    "    stop = time.perf_counter()\n",
    "\n",
    "    print(\"Finished.\")\n",
    "    print(f\"Clustering done in {stop - start:0.4f} seconds.\")\n",
    "    diagnostic = co.Counter(clusterlabel)\n",
    "    print(f\"{str(len(clusterlabel))} sequences, {str(diagnostic[-1])} unclustered, {str(len(set(diagnostic)))} cluster.\")\n",
    "\n",
    "    N = sanity.count(0) + sanity.count(2)\n",
    "    H = sanity.count(1) + sanity.count(2)\n",
    "    \n",
    "    print(f\"{N} clusters containing matching NA types.\")\n",
    "    print(f\"{H} clusters containing matching HA types.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome. Read input and settings file. Finished.\n",
      "Nucleotide k-mer frequency calculation. Finished.\n",
      "Running UMAP for dimension reduction. Finished.\n",
      "Aminoacid k-mer frequency calculation. Finished.\n",
      "Running UMAP for dimension reduction. Finished.\n",
      "Running HDBscan for clustering. Finished.\n",
      "Centroid extraction. Finished.\n",
      "Clustering done in 1093.8409 seconds.\n",
      "56600 sequences, 31 unclustered, 826 cluster.\n",
      "555 clusters containing matching NA types.\n",
      "617 clusters containing matching HA types.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
