\chapter{Materials and Methods} \label{chap:Materials_and_Methods}

The tools used in this project were installed with the Conda package distribution system version 2-2.4.0 \autocite{anaconda_software_distribution_anaconda_2020}. With Conda, Python packages containing e.~g.~ full software tools can be managed by local environments for simple access without the necessity of a complex system-wide installation. By creation of an environment similar to the one used in this project, with conda environment creation from YAML file, the results can be easily recreated on any modern UNIX-like operating system that has Conda installed. 

\begin{lstlisting}[language=sh]
git clone https://github.com/ahenoch/Masterthesis.git
cd Masterthesis
conda env create -f Environment.yml
\end{lstlisting}  

The YAML file containing the informations for installation like e.~g.~ the used tools versions is present in the \href{https://github.com/ahenoch/Masterthesis.git}{Projects GitHub Repository} an can be made available by e.~g.~ cloning the repository (the important packages and their related versions are also listed in \autoref{tab:Package_Version}).

\begin{table}[!hbt]
    \centering
    \caption[Package Version]{\textbf{Package Version.} The packages that need to be installed by Conda in a specific version for the pipeline to work as expected are listed in this table. Other related packages necessary for execution of the listed ones are meanwhile installed automatically by Conda.}
    \label{tab:Package_Version}
    \pgfplotstabletypeset[
        every head row/.style={
            before row={
                \toprule
            },
            after row={
                \midrule
            },
        },
        every last row/.style={
            after row={
                \bottomrule
            },
        },
        begin table=\begin{tabular*}{.5\textwidth},
        end table=\end{tabular*},
        columns={0,1,2},
        columns/0/.style={string type, multicolumn names=l,column name=\textbf{Name}, column type=@{\extracolsep{\fill}\hspace{6pt}}l},
        columns/1/.style={string type, multicolumn names=l,column name=\textbf{Version}, column type=l},
        columns/2/.style={string type, multicolumn names=l,column name=\textbf{Channel}, column type=l}
    ]
    {Graphics/Packages.csv}
\end{table}

Since its file size exceeds the limits of GitHub, the FASTA file containing all the known high quality sequences of the \gls{IAV}, that is used in this project must be manually retrieved in the latest version \footnote{GenBank Genome Sequence/Annotation Update >= 05/2021} from the \href{https://www.fludb.org/brc/home.spg?decorator=influenza}{Influenza Research Database}.

\begin{table}[!hbt]
    \centering
    \caption[Search Parameter for FASTA file]{\textbf{Search Parameter for FASTA file.} The parameters to use on the nucleotide sequence search interface of the \href{https://www.fludb.org/brc/home.spg?decorator=influenza}{Influenza Research Database}. All paremeters have to be precisely as listed for a exact replication of the FASTA file used in this project.}
    \label{tab:Search}
    \pgfplotstabletypeset[
        every head row/.style={
            before row={
                \toprule
            },
            after row={
                \midrule
            },
        },
        every last row/.style={
            after row={
                %... & ... & ... & ... & ... & ... & ... & ...\\
                \bottomrule
            },
        },
        begin table=\begin{tabular*}{.5\textwidth},
        end table=\end{tabular*},
        columns={0,1},
        columns/0/.style={string type, multicolumn names=l,column name=\textbf{Field}, column type=@{\extracolsep{\fill}\hspace{6pt}}l},
        columns/1/.style={string type, multicolumn names=l,column name=\textbf{Parameter}, column type=l},
    ]
    {Graphics/search.csv}
\end{table}

The FASTA file can be retrieved by navigating from \textit{SEARCH DATA} to \textit{Search Sequences} and then to \textit{Nucleotide Sequences}. On the following page the parameters given in \autoref{tab:Search} have to be used to request the correct file. Following the search request \textit{Select all X segments} have to be checked and after \textit{Download}, \textit{Segment FASTA} has to be checked in \textit{Specify Download Type} setting and \textit{Custom format - select fields from list} in \textit{Format for FASTA file definition line}. Accession Number, Strain Name, Segment, Protein Symbol, Type, SubType, Date, Host Species, Curation Flag have then to be added in the following order. After downloading the FASTA file it has to be placed as \textit{A.fasta} in the local root of the \href{https://github.com/ahenoch/Masterthesis.git}{Projects GitHub Repository}. The version used for the proposed results was acquired at 08/11/2020 \footnote{GenBank Genome Sequence/Annotation Update <= 11/2020 }. Newer versions might change the results slightly.

% \begin{enumerate}[noitemsep]
%     \item \textit{SEARCH DATA}
%     \item \textit{Search Sequences}
%     \item \textit{Nucleotide Sequences}
%     \item \textit{Data Type:} Genome Segments, \textit{Virus Type:} A, \textit{Complete Genome:} Complete Genome Only, \textit{Select Segments:} All, \textit{Complete:} All
%     \item \textit{Search}
%     \item \textit{Select all X segments}
%     \item \textit{Download}
%     \item \textit{Specify Download Type:} Segment FASTA
%     \item \textit{Format for FASTA file definition line:}  Custom format - select fields from list
%     \item \textbf{add in the following order:} Accession Number, Strain Name, Segment, Protein Symbol, Type, SubType, Date, Host Species, Curation Flag
%     \item save as A.fasta in the cloned Masterthesis folder
% \end{enumerate}
%or from the \href{https://github.com/ahenoch/Masterthesis.git}{Projects GitHub Repository}. Using the manually retrieved updated version of the FASTA file might change the recreated results slightly.

To access the Jupyter Notebooks holding the cluster and analysis pipeline, as well as recreate the results, the IPYNB Files in the \href{https://github.com/ahenoch/Masterthesis.git}{Projects GitHub Repository} have to be opened and started in a Jupyter Lab server \autocite{kluyver_jupyter_2016}.

\begin{lstlisting}[language=sh]
conda activate Masterthesis
jupyter lab
\end{lstlisting}  

The raw pipeline clusters \gls{IAV} genomes and saves the results as CSV files and colored \gls{HDBSCAN} clustertrees using ETE3 version 3.1.2 \autocite{huerta-cepas_ete_2016}. It is designed to function as a clustering tool, without the need of a running Jupyter Lab server and with easier modification and faster execution in mind (\autoref{fig:Vectorization_Pipeline} and \autoref{fig:Clustering_Pipeline}). 

\begin{lstlisting}[language=sh]
conda activate Masterthesis
python3 Clustering.py -i A.fasta -o PCA_raw -p 50
\end{lstlisting}  

All settings available to the present day are listed on the next page.

\begin{leftbar}
    \textbf{Clustering.py}
    \begin{nstabbing}
        \qquad\=\qquad\qquad\qquad\qquad\quad\=\kill
    
        -i \> -{}-{}infile \> [path to input file (e.~g.~ A.fasta)]\\
        
        -o \> -{}-{}outfolder \> [path to input file (default: Results)]\\
        
        -s \> -{}-{}segments \> [segments to run the pipeline on (default: 1 2 3 4 5 6 7 8)]\\
        
        -c \> -{}-{}custom\_header \> [if using FASTA with a custom header, every part of it has\\
        
        \> \> to be declared (default: accession strain segment protein\\
        
        \> \> genus subtype date host curation genome)]\\
        
        -m \> -{}-{}metric \> [metric to use in the pipeline (default: cosine)]\\
        
        -mc \> -{}-{}min\_clust \> [min\_cluster\_size parameter for HDBSCAN (default: 2)]\\
        
        -ms \> -{}-{}min\_sample \> [min\_samples parameter for HDBSCAN (default: 1)]\\
        
        -n \> -{}-{}neigbors \> [n\_neighbors parameter for UMAP (default: 100)]\\
        
        -u \> -{}-{}umap \> [n\_components parameter for UMAP (optional)]\\
        
        -p \> -{}-{}pca \> [n\_components parameter for PCA (optional)]
    \end{nstabbing}
\end{leftbar}

\begin{figure}[!hbt]
    \centering
    \includegraphics[width=\textwidth]{Graphics/Vectorization.pdf}
    \caption[Clustering Pipeline]{\textbf{Vectorization Pipeline.} The vectorization pipeline of the proposed clustering tool. The FASTA file is translated to vectors containing the k-mer frequencies of the specific sequence (\autoref{sec:Frequency}). As shown in pathway \textsf{\textbf{1}}, by normalization with L1-norm and \gls{PCA} a low complexity representation of the vectors is obtained for clustering (\autoref{sec:Normalization} and \autoref{sec:PCA}). Pathway \textsf{\textbf{2}} describes additional execution of \gls{UMAP} that can be used after \gls{PCA} as intermediate instead of final step (\autoref{sec:UMAP}).}
    \label{fig:Vectorization_Pipeline}
\end{figure}

\begin{figure}[!hbt]
    \centering
    \includegraphics[width=\textwidth]{Graphics/Clustering.pdf}
    \caption[Clustering Pipeline]{\textbf{Clustering Pipeline.} Following the vectorization pipeline (\autoref{fig:Vectorization_Pipeline}) normalization is used again with L2-norm as preparation for \gls{HDBSCAN} (\autoref{sec:Normalization} and \autoref{sec:HDBSCAN}) Final hybrid clustering (\autoref{sec:HDBSCAN}) is prepared either with the Kneedle Algorithm (pathway \textsf{\textbf{4}} and \autoref{sec:Kneedle}) or DBCV exploration (pathway \textsf{\textbf{3}} and \autoref{sec:HDBSCAN}).}
    \label{fig:Clustering_Pipeline}
\end{figure}

The tool takes around one hour to cluster all eight segments of \gls{IAV} and create the output in form of tables and clustertree graphics with the suggested settings. 

\input{Thesis/0201_Frequency}

\input{Thesis/0202_Normalization}

\input{Thesis/0203_PCA}

\input{Thesis/0204_UMAP}

\input{Thesis/0205_HDBSCAN}

\input{Thesis/0206_Kneedle}

\input{Thesis/0207_Biopython}